{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"about/","title":"# whoami","text":""},{"location":"about/#whoami","title":"# whoami","text":"<p>Especialista em DevOps com mais de 15 anos de experi\u00eancia em automa\u00e7\u00e3o, padroniza\u00e7\u00e3o e otimiza\u00e7\u00e3o de ambientes em nuvem. Trabalho com foco em infraestrutura como c\u00f3digo e automa\u00e7\u00f5es. Gerenciando pipelines CI/CD, promovendo autonomia para os times de desenvolvimento, sempre com aten\u00e7\u00e3o \u00e0 governan\u00e7a, seguran\u00e7a e custo, seguindo princ\u00edpios de boas pr\u00e1ticas. </p> <p>Yoga Buddy, Linux Fanboy, Mexican Food Chef, PsyTrance Vibes.. PLUR is the answer.. </p> <p>Aqui compartilho pr\u00e1ticas, aprendizados e ideias sobre Automa\u00e7\u00e3o, DevOps, Cloud Native Tools e Seguran\u00e7a.</p> <p>Certifications:</p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <code>#BornToBeRoot #OpenSourceSoul #CloudRider #AutomateLife #ScriptJunkie</code>"},{"location":"articles/","title":"Articles","text":""},{"location":"articles/#articles","title":"Articles","text":""},{"location":"articles/downdetector/","title":"Index","text":""},{"location":"blog/","title":"Blog","text":""},{"location":"blog/#blog","title":"Blog","text":""},{"location":"blog/2020/05/26/hello_world_again_one_more_time_now_in_that_platform_/","title":"Hello World Again, one more time, now in that platform !","text":""},{"location":"blog/2020/05/26/hello_world_again_one_more_time_now_in_that_platform_/#hello-world-again-one-more-time-now-in-that-platform","title":"Hello World Again, one more time, now in that platform !","text":"<p>Bem vindo ao Blog/Wiki CringerLabs, este tem o objetivo de dividir o conhecimento de estudos/aprendizados com o mundo, nada fora do normal para quem \u00e9 apaixonado por OpenSource. Mesmo que a ferramenta seja OpenSource ou n\u00e3o, pretendo compartilhar o que consegui e como consegui para que voc\u00eas consigam testar e assim n\u00f3s possamos trocar experiencias. </p> <p>Pretendo manter o portal atualizado com dicas, how-tos, sugest\u00f5es e arquitetura de ambientes. Dentre eles pretendo falar de Infraestrutura, Conectividade, Virtualiza\u00e7\u00e3o(todas as que utilizo), Cloud(conceitos e ferramentas), dicas de ambientes e testes em laborat\u00f3rio.</p> <p>Karlipe Gomes</p>"},{"location":"blog/2020/05/27/security_linux__part_i__iptables/","title":"Security Linux \u2013 Part I \u2013 IPTABLES","text":""},{"location":"blog/2020/05/27/security_linux__part_i__iptables/#security-linux-part-i-iptables","title":"Security Linux \u2013 Part I \u2013 IPTABLES","text":"<p>Garantir um ambiente seguro, acima de tudo, \u00e9 um dos maiores desafios do sysadmin independente de qual seja o seu ambiente. Nessa s\u00e9rie de posts iremos falar das principais ferramentas nativas do ambiente like RHEL. |,,/_ Segue abaixo os t\u00f3picos que iremos abordar neste e nos pr\u00f3ximos posts.</p> <ul> <li>Part I: Iptables</li> <li>Part II: acl</li> <li>Part III: selinux</li> <li>Part IV: tcpwrappers</li> <li>Part V: cgroups</li> </ul>"},{"location":"blog/2020/05/27/security_linux__part_i__iptables/#iptables","title":"IPTABLES","text":"<p>Ferramenta conhecida por controlar o m\u00f3dulo \u201cnetfilter\u201d, \u00e9 usada para cria\u00e7\u00e3o de regras de Firewall, NAT e Logs. Regras estas podendo ser de certa forma bastante simples, como o bloqueio/libera\u00e7\u00e3o da porta TCP/80 do http, ou complexas, podendo ter scripts que prometam bloquear qualquer ataque DDoS.</p> <ol> <li>http://www.inetbase.com/scripts/ddos/install.sh</li> </ol> <p>N\u00e3o creio que escrever um post muito complexo de iptables ir\u00e1 render muito, pelo simples fato de existem milhares de fontes mais completas. Por isso esse post ser\u00e1 muito superficial com poucos detalhes, tentando definir usabilidade e curiosidades do comando.</p> <p>Comandos Salvar as configura\u00e7\u00f5es correntes em arquivo </p><pre><code>iptables-save &gt; arquivo.txt\n</code></pre><p></p> <p>Restaurar para a configura\u00e7\u00e3o corrente, as op\u00e7\u00f5es existentes no arquivo fonte </p><pre><code>iptables-restore &lt; arquivo.txt\n</code></pre><p></p> <p>Realiza o mesmo procedimento que o \u2018iptables-save\u2019, com o acrescimo de exportar as configura\u00e7\u00f5es em modo XML. O que para algumas pessoas pode facilitar a visualiza\u00e7\u00e3o das regras. </p><pre><code>iptables-xml\n</code></pre><p></p> <p>iptables-multi - \u00c9 apenas um \u2018atalho\u2019 para os outros comandos. por exemplo: </p><pre><code>iptables-multi main -L #(ter\u00e1 o mesmo efeito do comando iptables -L)\n</code></pre> Para simular outros subcomandos basta utilizar conforme abaixo. <pre><code>iptables-multi main -L #  iptables -L\niptables-multi save &gt; arquivo # iptables-save &gt; arquivo\niptables-multi restore &lt; arquivo # iptables-restore &lt; arquivo \niptables-multi xml arquivo &gt; arquivo-2 # iptables-xml arquivo &gt; arquivo-2\n</code></pre><p></p> <p>Principal Arquivo Qualquer configura\u00e7\u00e3o que seja feita em atua\u00e7\u00e3o corrente, n\u00e3o sera reexecutada ap\u00f3s um possivel boot a n\u00e3o ser que esteja setada no seguinte arquivo \u2018/etc/sysconfig/iptables\u2019.</p> <p>Servi\u00e7o Assim como qualquer outro service o iptables pode ser gerenciado atrav\u00e9s do comando \u2018service\u2019. Ex: Restarta o servi\u00e7o </p><pre><code>service iptables restart\n</code></pre><p></p> <p>Para o service </p><pre><code>service iptables stop\n</code></pre><p></p> <p>Outras op\u00e7\u00f5es </p><pre><code>service iptables\nUsage: iptables {start|stop|reload|restart|condrestart|status|panic|save}\n</code></pre><p></p> <p>Podendo tamb\u00e9m ser desativado para que n\u00e3o inicie junto ao boot. </p><pre><code>chkconfig iptables off\n</code></pre><p></p> <p>PS: Para n\u00e3o ser redundante a posts excelentes, n\u00e3o irei citar exemplos se criar regras de Firewall/NAT. Segue abaixo excelentes fontes que podem descrever muito melhor e de linguagem mais simples tais exemplos. Estas fontes foram justamente onde aprendi.</p> <p>Fonte:</p> <ol> <li>guiafoca</li> <li>vivaolinux</li> <li>wikipedia/Netfilter</li> <li>man iptables</li> <li>netfilteriptables</li> </ol>"},{"location":"blog/2020/05/28/dica_do_sysadmin__gerenciamento_de_pacotes_i/","title":"Dica do SysAdmin \u2013 Gerenciamento de Pacotes I","text":""},{"location":"blog/2020/05/28/dica_do_sysadmin__gerenciamento_de_pacotes_i/#dica-do-sysadmin-gerenciamento-de-pacotes-i","title":"Dica do SysAdmin \u2013 Gerenciamento de Pacotes I","text":"<p>Todo SysAdmin que se preze j\u00e1 executou e conhece o comando yum.  Mas o interessante \u00e9: ser\u00e1 que conhece alguma das op\u00e7\u00f5es e sub-comandos mais \u00fateis?!</p> <p>Irei explicar abaixo e dar exemplos de como o comando yum pode facilitar a sua vida.</p>"},{"location":"blog/2020/05/28/dica_do_sysadmin__gerenciamento_de_pacotes_i/#1-yum-provides","title":"1. yum provides","text":"<p>Quantas vezes voc\u00ea queria instalar um comando e n\u00e3o sabia o nome dele?!</p> <p>A op\u00e7\u00e3o \u201cprovides\u201d existe justamente para te ajudar nessa parte mais dif\u00edcil, que \u00e9 lembrar o nome do pacote respons\u00e1vel por essa feature. Seguindo o padr\u00e3o acima voc\u00ea pode verificar qual o nome do pacote. Segue abaixo exemplo do bin\u00e1rio \u201cdig\u201c.</p> <pre><code># yum provides \u201c*bin/dig\u201d\n32:bind-utils-9.8.2-0.17.rc1.el6_4.6.x86_64 : Utilities for querying DNS name servers\nRepo        : base\nMatched from:\nFilename    : /usr/bin/dig\n</code></pre>"},{"location":"blog/2020/05/28/dica_do_sysadmin__gerenciamento_de_pacotes_i/#2-yum-info-yum-groupinfo","title":"2. yum info , yum groupinfo","text":"<p>Este pr\u00f3ximo exemplo ir\u00e1 facilitar na instala\u00e7\u00e3o, caso voc\u00ea n\u00e3o tenha certeza de qual pacote tem que instalar. A op\u00e7\u00e3o \u201cinfo\u201d vai exibir as informa\u00e7\u00f5es completas do pacote conforme exemplifica\u00e7\u00e3o abaixo, ainda utilizando o \u201cbind-utils\u201d.</p> <pre><code># yum info bind-utils\nAvailable Packages\nName        : bind-utils\nArch        : x86_64\nEpoch       : 32\nVersion     : 9.8.2\nRelease     : 0.23.rc1.el6_5.1\nSize        : 182 k\nRepo        : updates\nSummary     : Utilities for querying DNS name servers\nURL         : http://www.isc.org/products/BIND/\nLicense     : ISC\nDescription : Bind-utils contains a collection of utilities for querying DNS\n            : (Domain Name System) name servers to find out information about\n            : Internet hosts. These tools will provide you with the IP\n            : addresses for given host names, as well as other information\n            : about registered domains and network addresses.\n            :\n            : You should install bind-utils if you need to get information from\n            : DNS name servers.\n</code></pre> <p>A mesma consulta pode ser feita para grupos com a op\u00e7\u00e3o \u201cgroupinfo\u201d, ele listar\u00e1 al\u00e9m de informa\u00e7\u00f5es b\u00e1sicas, qual a principal feature e suas depend\u00eancias, por exemplo:</p> <pre><code># yum groupinfo webserver\nGroup: Web Server\n Description: Allows the system to act as a web server, and run Perl and Python web applications.\n Mandatory Packages:\n   httpd\n Default Packages:\n   crypto-utils\n   httpd-manual\n   mod_perl\n   mod_ssl\n   mod_wsgi\n   webalizer\n Optional Packages:\n   Pound\n   certmonger\n   cherokee\n   libmemcached\n   memcached\n   mod_auth_kerb\n   mod_auth_mysql\n   mod_auth_pgsql\n   mod_authz_ldap\n   mod_fcgid\n   mod_nss\n   mod_revocator\n   mod_security\n   moin\n   perl-CGI\n   perl-CGI-Session\n   perl-Cache-Memcached\n   plone\n   python-memcached\n   squid\n   zope\n</code></pre>"},{"location":"blog/2020/05/28/dica_do_sysadmin__gerenciamento_de_pacotes_i/#3-yum-localinstall","title":"3. yum localinstall","text":"<p>Para uma administra\u00e7\u00e3o de instala\u00e7\u00e3o de pacotes mais centralizada, podemos instalar um pacote \u201c.rpm\u201d atrav\u00e9s dessa op\u00e7\u00e3o. Esta facilidade nos proporciona ainda um ambiente com menos stress nas instala\u00e7\u00f5es, pois desta forma o comando yum ir\u00e1 resolver todas as depend\u00eancias do pacote.</p> <pre><code># yum localinstall rpmforge-release.rpm \nResolving Dependencies\n\u2013&gt; Running transaction check\n\u2014&gt; Package rpmforge-release.x86_64 0:0.5.3-1.el6.rf will be installed\n\u2013&gt; Finished Dependency Resolution\n\nDependencies Resolved\n=====================================================================\n Package             Arch      Version              Repository            Size\n=====================================================================\nInstalling:\n rpmforge-release    x86_64    0.5.3-1.el6.rf       /rpmforge-release     13 k\n\nTransaction Summary\n=====================================================================\nInstall       1 Package(s)\n\nTotal size: 13 k\nInstalled size: 13 k\nIs this ok [y/N]: y\nRunning Transaction\n  Installing : rpmforge-release-0.5.3-1.el6.rf.x86_64                      1/1\n  Verifying  : rpmforge-release-0.5.3-1.el6.rf.x86_64                      1/1\n\nInstalled:\n  rpmforge-release.x86_64 0:0.5.3-1.el6.rf\n\nComplete!\n</code></pre>"},{"location":"blog/2020/05/28/dica_do_sysadmin__gerenciamento_de_pacotes_i/#4-yum-history","title":"4. yum history","text":"<p>Por \u00faltimo e n\u00e3o menos importante, n\u00e3o mesmo. Este sub-comando te d\u00e1 algumas das mais \u00fateis op\u00e7\u00f5es, exemplo:  Se voc\u00ea digitar apenas \u201cyum history\u201d, ele ir\u00e1 te listar as \u00faltimas instala\u00e7\u00f5es realizadas atrav\u00e9s do yum, INCLUSIVE a instala\u00e7\u00e3o do .rpm.</p> <p></p><pre><code># yum history\nID     | Login user               | Date and time    | Action(s)      | Altered\n\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014-\n     5 | root &lt;root&gt;              | 2014-08-28 01:31 | Install         |    1\n     4 | root &lt;root&gt;              | 2014-08-28 01:05 | Erase          |    1\n     3 | root &lt;root&gt;              | 2014-08-17 21:52 | Install         |    1 &gt;\n     2 | root &lt;root&gt;              | 2014-08-17 21:50 | I, U             |   60\n     1 | System &lt;unset&gt;       | 2014-08-17 21:44 | Install         |  205\n</code></pre> Adicionando o ID da primeira coluna e algumas outras op\u00e7\u00f5es, podemos complementar o comando.  Ex: \" yum history sub-comando ID \"<p></p> <p>Lista quais pacotes e a\u00e7\u00f5es foram realizadas no hor\u00e1rio informado. </p><pre><code># yum history info 5 \n</code></pre><p></p> <p>Lista os pacotes afetados/alterados no ID 5. </p><pre><code># yum history packages-list 5\n</code></pre><p></p> <p>Neste simples passo \u00e9 poss\u00edvel desfazer tudo que foi realizado no ID 4. No exemplo, o pacote ser\u00e1 reinstalado. </p><pre><code># yum history undo 4\n</code></pre><p></p> <p>Outros sub-comandos dispon\u00edveis podem ser consultados com a op\u00e7\u00e3o abaixo:</p> <p></p><pre><code># yum help history\nhistory [info | list|packages-list | summary | addon-info | redo | undo | rollback | new]\nDisplay, or use, the transaction history\n</code></pre> Essas foram apenas algumas dicas r\u00e1pidas, at\u00e9 a pr\u00f3xima.<p></p> <p>Fonte: 1. https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html-single/Deployment_Guide/index.html#ch-yum 2. man yum</p>"},{"location":"blog/2020/05/29/alterando_o_nome_das_interfaces_de_rede_rhelcentos_7/","title":"Alterando o nome das interfaces de rede RHEL/CentOS 7","text":""},{"location":"blog/2020/05/29/alterando_o_nome_das_interfaces_de_rede_rhelcentos_7/#alterando-o-nome-das-interfaces-de-rede-rhelcentos-7","title":"Alterando o nome das interfaces de rede RHEL/CentOS 7","text":"<p>Para quem \u00e9 acostumado com as interfaces de rede chamadas \u2018ethx\u2019  e encontram numa nova instala\u00e7\u00e3o do RHEL/CentOS 7 interfaces com nomes um tanto quanto complexos, como \u201ceno16777736\u201d, pode chegar a assustar.</p> <pre><code># ip addr show\neno16777736: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000\nlink/ether 00:0c:29:1b:56:7b brd ff:ff:ff:ff:ff:ff\ninet 172.16.94.141/24 brd 172.16.94.255 scope global dynamic eth0\nvalid_lft 1373sec preferred_lft 1373sec\n</code></pre> <p>Esse nome \u00e9 denominado atrav\u00e9s do udev, como pode ser visto na seguinte linha do dmesg: </p><pre><code># dmesg | grep eth0\n[    1.973153] e1000 0000:02:01.0 eth0: (PCI:66MHz:32-bit) 00:0c:29:1b:56:7b\n[    1.973159] e1000 0000:02:01.0 eth0: Intel(R) PRO/1000 Network Connection\n[    1.977444] systemd-udevd[367]: renamed network interface eth0 to eno16777736\n</code></pre> Para altera\u00e7\u00e3o do nome \u00e9 necess\u00e1rio o passar ao kernel atrav\u00e9s de par\u00e2metros que o nome da interface deve ser mantido. Segue passo a passo para \u2018corre\u00e7\u00e3o\u2019:<p></p>"},{"location":"blog/2020/05/29/alterando_o_nome_das_interfaces_de_rede_rhelcentos_7/#passo-1-alterar-o-grub","title":"Passo 1:  Alterar o GRUB","text":"<p>editar o arquivo /etc/default/grub, adicionando o par\u00e2metro \u2018net.ifnames=0\u2019 \u00e0 linha que se inicia com \u2018GRUB_CMDLINE_LINUX\u2019, como mostra a seguir:</p> <pre><code>#antes:\nGRUB_CMDLINE_LINUX=\u201drd.lvm.lv=centos/swap crashkernel=auto vconsole.keymap=us rd.lvm.lv=centos/root vconsole.font=latarcyrheb-sun16  rhgb quiet\u201d\n#depois:\nGRUB_CMDLINE_LINUX=\u201drd.lvm.lv=centos/swap crashkernel=auto vconsole.keymap=us rd.lvm.lv=centos/root vconsole.font=latarcyrheb-sun16  rhgb quiet net.ifnames=0\u2033\n</code></pre> <p>Ap\u00f3s salvar o arquivo, seguir com o comando:  </p><pre><code>grub2-mkconfig -o /boot/grub2/grub.cfg\n</code></pre> Isso ir\u00e1 fazer com que o grub passe esses novos par\u00e2metros para o kernel na inicializa\u00e7\u00e3o.<p></p>"},{"location":"blog/2020/05/29/alterando_o_nome_das_interfaces_de_rede_rhelcentos_7/#passo-2-alterar-o-nome-do-arquivo-de-configuracao","title":"Passo 2: alterar o nome do arquivo de configura\u00e7\u00e3o:","text":"<pre><code># cd /etc/sysconfig/network-scripts/\n# mv ifcfg-eno16777736 ifcfg-eth0\n</code></pre>"},{"location":"blog/2020/05/29/alterando_o_nome_das_interfaces_de_rede_rhelcentos_7/#passo-3-reboot-da-maquina","title":"Passo 3: reboot da m\u00e1quina","text":"<pre><code># shutdown -r now\n</code></pre> <p>Ap\u00f3s todos os passos acima, j\u00e1 ser\u00e1 vis\u00edvel a altera\u00e7\u00e3o no nome da interface</p> <pre><code># ip addr show\neth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000\nlink/ether 00:0c:29:1b:56:7b brd ff:ff:ff:ff:ff:ff\ninet 172.16.94.141/24 brd 172.16.94.255 scope global dynamic eth0\nvalid_lft 1775sec preferred_lft 1775sec\n</code></pre> <p>Fonte: 1. http://fedoraproject.org/wiki/Features/ConsistentNetworkDeviceNaming</p>"},{"location":"blog/2020/05/30/template_centos_7/","title":"Template CentOS 7","text":""},{"location":"blog/2020/05/30/template_centos_7/#template-centos-7","title":"Template CentOS 7","text":""},{"location":"blog/2020/05/30/template_centos_7/#passo1-minimal-instalation","title":"Passo1: Minimal Instalation","text":"<p>Procedimento de  instala\u00e7\u00e3o do CentOS 7, foi utilizado a ISO Minimal: </p> <ol> <li>Crie uma VM com o m\u00ednimo necess\u00e1rio e adicione a ISO e ligue a VM.</li> </ol> <ol> <li> <p>Clique on \u201cInstall CentOS Linux 7\u201d. </p> </li> <li> <p>Selecione o Idioma que deseja continuar o processo de instala\u00e7\u00e3o. </p> </li> <li> <p>Click em \u201cDate &amp; Time\u201d. </p> </li> <li> <p>Selecione o Timezone que o melhor representa. </p> </li> <li> <p>Clique em \u201cInstallation Destionation\u201d </p> </li> <li> <p>Clique para criar automaticamente . </p> </li> <li> <p>Defina a senha de ROOT </p> </li> </ol> <p>Espere a conclus\u00e3o da Instala\u00e7\u00e3o e reinicie a M\u00e1quina.</p>"},{"location":"blog/2020/05/30/template_centos_7/#passo2-minimal-instalation","title":"Passo2: Minimal Instalation","text":"<p>Ap\u00f3s a M\u00e1quina reiniciar, fa\u00e7a login com a senha definida pelo usu\u00e1rio root.</p> <ol> <li>\u00c9 muito comum que o SELinux seja desabilitado. Vamos alterar em execu\u00e7\u00e3o de \u201cenforcing\u201d para \u201cpermissive\u201d com o comando setenforce e posteriormente vamos alterar no arquivo de configura\u00e7\u00e3o para na pr\u00f3xima vez que a m\u00e1quina reinicie j\u00e1 fique com essa configura\u00e7\u00e3o realizada.</li> </ol> <p></p><pre><code>[root@localhost ~]#\n[root@localhost ~]# setenforce 0\n[root@localhost ~]# cat /etc/selinux/config\n# This file controls the state of SELinux on the system.\n# SELINUX= can take one of these three values:\n#     enforcing - SELinux security policy is enforced.\n#     permissive - SELinux prints warnings instead of enforcing.\n#     disabled - No SELinux policy is loaded.\nSELINUX=permissive\n# SELINUXTYPE= can take one of three two values:\n#     targeted - Targeted processes are protected,\n#     minimum - Modification of targeted policy. Only selected processes are protected.\n#     mls - Multi Level Security protection.\nSELINUXTYPE=targeted\n[root@localhost ~]# getenforce\nPermissive\n</code></pre> 02. Aproveite para instalar ferramentas necess\u00e1rias para Troubleshooting e deixar o Sistema Up-To-Date ajudando a mitigar com corre\u00e7\u00f5es e bugfixes.  <pre><code>[root@localhost ~]#\n[root@localhost ~]# yum -y install vim wget psmisc htop epel-release\n[root@localhost ~]# yum -y install selinux-policy yum-plugin-security\n[root@localhost ~]# yum -y install tcpdump net-tools bind-utils telnet nmap\n[root@localhost ~]# yum -y install open-vm-tools #(Caso esteja utilizando VMWARE como virtualizador)\n[root@localhost ~]# systemctl restart vmtoolsd #(Caso esteja utilizando VMWARE como virtualizador)\n[root@localhost ~]# systemctl enable vmtoolsd #(Caso esteja utilizando VMWARE como virtualizador)\n[root@localhost ~]#\n[root@localhost ~]# yum update -y\n[root@localhost ~]#\n</code></pre><p></p>"},{"location":"blog/2020/05/30/template_centos_7/#passo-3-zerando-registros","title":"PASSO 3: Zerando registros","text":"<p>Passos necess\u00e1rios para deixar o seu Sistema o mais labelless poss\u00edvel.</p> <ol> <li> <p>Removendo configura\u00e7\u00f5es de udev rules, para que a placa de rede ao iniciar o sistema fique a prim\u00e1ria padr\u00e3o. </p><pre><code>[root@localhost etc]#\n[root@localhost etc]#  rm -f /etc/udev/rules.d/70-persistent-net.rules\n[root@localhost etc]#\n</code></pre><p></p> </li> <li> <p>Habilitando a interface sem configura\u00e7\u00e3o pr\u00e9via. </p><pre><code>[root@localhost etc]#\n[root@localhost etc]# vim /etc/sysconfig/network-scripts/ifcfg-ens160\nDEVICE=ens160\nONBOOT=yes\n. . .\n[root@localhost ~]#\n</code></pre><p></p> </li> <li> <p>Apagando as chaves criadas, (novas ser\u00e3o criadas durante o processo de boot) </p><pre><code>[root@localhost etc]#\n[root@localhost etc]# rm -rf /etc/ssh/ssh_host_*\n[root@localhost etc]#\n</code></pre><p></p> </li> <li> <p>Limpando arquivos no filesystem e logs. Em seguida, desligando a m\u00e1quina. </p><pre><code>[root@localhost ~]#\n[root@localhost ~]# yum clean -q all\n[root@localhost ~]#\n[root@localhost ~]# service rsyslog stop &gt; /dev/null\n[root@localhost ~]# service auditd stop &gt; /dev/null\n[root@localhost ~]#\n[root@localhost ~]# logrotate -f /etc/logrotate.conf\n[root@localhost ~]# rm -f /var/log/*-???????? /var/log/*.gz\n[root@localhost ~]# rm -rf /var/log/anaconda\n[root@localhost ~]# rm -f /var/log/dmesg.old\n[root@localhost ~]#\n[root@localhost ~]# cat /dev/null &gt; /var/log/audit/audit.log\n[root@localhost ~]# cat /dev/null &gt; /var/log/wtmp\n[root@localhost ~]# cat /dev/null &gt; /var/log/lastlog\n[root@localhost ~]# cat /dev/null &gt; /var/log/grubby\n[root@localhost ~]#\n[root@localhost ~]# rm -rf /tmp/*\n[root@localhost ~]# rm -rf /var/tmp/*\n[root@localhost ~]#\n[root@localhost ~]# rm -rf ~root/.ssh/\n[root@localhost ~]# rm -f ~root/anaconda-ks.cfg\n[root@localhost ~]#\n[root@localhost ~]# rm -f ~root/.bash_history\n[root@localhost ~]# rm -f /home/*/.bash_history\n[root@localhost ~]#\n[root@localhost ~]# touch /.unconfigured\n[root@localhost ~]#\n[root@localhost ~]# shutdown -h now\n[root@localhost ~]#\n</code></pre><p></p> </li> <li> <p>Habilitando CPU/Memory Hot Plug  </p> </li> <li> <p>Convertendo a m\u00e1quina em template </p> </li> </ol> <p>Com isso finalizamos o template, para novas m\u00e1quinas virtuais iniciem dentro do padr\u00e3o, basta clicar no template com bot\u00e3o direito e clicar em \u201cCriar nova VM a partir do Template\u201d.</p>"},{"location":"blog/2020/05/31/tooltip_-_teampass/","title":"ToolTip - Teampass","text":"","tags":["teampass"]},{"location":"blog/2020/05/31/tooltip_-_teampass/#tooltip-teampass","title":"#ToolTip - Teampass","text":"<p>TeamPass \u00e9 um Gerenciador de Senhas opensource ideal para empresas e grupos de equipes, que possuam uma grande quantidade de senhas/acessos e necessitam de uma forma segura para colabora\u00e7\u00e3o de forma centralizada. Tamb\u00e9m \u00e9 poss\u00edvel um gerenciamento granular baseado em niveis de permiss\u00e3o diferenciados a grupos de usu\u00e1rios. Para o pessoal mais antigo pode-se dizer que a ferramenta se assemelha a um \u201ckeepass web\u201d, por causa da sua apar\u00eancia:</p> <p></p>","tags":["teampass"]},{"location":"blog/2020/05/31/tooltip_-_teampass/#segue-um-how-to-de-como-instalar-e-configurar-o-teampass-num-ambiente-empresarial","title":"Segue um How-To de como instalar e configurar o TeamPass num ambiente empresarial.","text":"<p>Passo1: Instala\u00e7\u00e3o da VM</p> <p>Foi instalado usando CentOS7, funciona em outras vers\u00f5es, mas neste lab utilizei essa.</p> <p>Para aumentar o n\u00edvel de seguran\u00e7a deste servi\u00e7o, foi utilizado o LUKS que \u00e9 a ferramenta padr\u00e3o de encripta\u00e7\u00e3o de disco utilizado pela RedHat. Ele \u00e9 utilizado para encriptar discos virtuais ou f\u00edsicos, l\u00f3gicos ou n\u00e3o, atrav\u00e9s de uma senha informada na instala\u00e7\u00e3o do SO(pode ser habilitado ap\u00f3s SO instalado). Quando o LUKS \u00e9 habilitado, se faz necess\u00e1rio inserir essa senha a cada boot da m\u00e1quina. Sem esta senha \u00e9 imposs\u00edvel a m\u00e1quina se inicie.</p> <p></p> <p>Passo2: Instala\u00e7\u00e3o dos pr\u00e9-requisitos</p> <ul> <li>MySQL 5.1 or higher,</li> <li>PHP 5.5.0 or higher,</li> <li>PHP extensions:</li> <li>mcrypt</li> <li>openssl</li> <li>ldap (if used)</li> <li>mbstring</li> <li>bcmath</li> <li>iconv</li> <li>xml</li> <li>gd</li> <li>openssl</li> <li>curl</li> </ul> <p>Comandos </p><pre><code>wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm\nrpm -ivh mysql-community-release-el7-5.noarch.rpm\nyum -y install mysql-server mysql-client\nyum install php php-mcrypt php-openssl php-ldap php-mbstring php-bcmath php-iconv php-xml php-gd php-openssl php-curl php-fpm php-mysqli\n</code></pre><p></p> <p>Alterar o max_exectution_time do php: </p><pre><code>cat /etc/php.ini\ncat /etc/php.ini| grep max_execution_time\nmax_execution_time = 120\n</code></pre> Criar Database conforme indicado<p></p> <pre><code>systemctl start mysqld\nsystemctl enable mysqld\nmysql_secure_installation\n- Set root password? [Y/n] y\n- Remove anonymous users? [Y/n] y\n- Disallow root login remotely? [Y/n] y\n- Remove test database and access to it? [Y/n] y\n- Reload privilege tables now? [Y/n] y\n\nmysql -u root -p\n******  \nMariaDB [(none)]&gt; create database teampassdb character set utf8 collate utf8_bin;\nMariaDB [(none)]&gt; grant all privileges on teampassdb.* to 'teamuser'@'localhost' identified by '********';\nMariaDB [(none)]&gt; flush privileges;\n</code></pre> <p>Passo3: Instala\u00e7\u00e3o</p> <p>Download do aplicativo e configura\u00e7\u00e3o de permiss\u00e3o e pastas. </p><pre><code>[root@teampass ~]#\ncd /var/www/html\n[root@teampass html]# wget https://github.com/nilsteampassnet/TeamPass/archive/2.1.27.16.zip\n[root@teampass html]# unzip 2.1.27.16.zip\n[root@teampass html]# mv 2.1.27.16 teampass\n[root@teampass html]#\n[root@teampass html]# chmod -R 0777 teampass/includes/config\n[root@teampass html]# chmod -R 0777 teampass/includes/avatars\n[root@teampass html]# chmod -R 0777 teampass/includes/libraries/csrfp/libs\n[root@teampass html]# chmod -R 0777 teampass/includes/libraries/csrfp/log\n[root@teampass html]# chmod -R 0777 teampass/includes/libraries/csrfp/js\n[root@teampass html]# chmod -R 0777 teampass/backups\n[root@teampass html]# chmod -R 0777 teampass/files\n[root@teampass html]# chmod -R 0777 teampass/install\n[root@teampass html]# chmod -R 0777 teampass/upload\n[root@teampass html]#\n[root@teampass html]# chown -Rf apache.apache *\n</code></pre><p></p> <p>Configura\u00e7\u00e3o do apache e restart do servi\u00e7o. </p><pre><code>[root@teampass html]#\n[root@teampass html]# cat /etc/httpd/conf.d/teampass.conf\n&lt;VirtualHost *:80&gt;\n\n    DocumentRoot \"/var/www/html/teampass\"\n    ServerName teampass.cringerlabs.local\n    ErrorLog \"/var/log/httpd/teampass-error.log\"\n    CustomLog \"/var/log/httpd/teampass-access.log\" combined\n\n&lt;/VirtualHost&gt;\n[root@teampass html]#\n[root@teampass html]# systemctl restart httpd\n[root@teampass html]#\n</code></pre><p></p> <p>Ap\u00f3s o reinicio do servi\u00e7o acesse o portal no endere\u00e7o criado e preencha com o dados configurados.  </p> <p>Passo4: Configura\u00e7\u00e3o</p> <ol> <li> <p>Ap\u00f3s login, para ir para as configura\u00e7\u00f5es basta clicar na ferramenta no topo da p\u00e1gina. </p> </li> <li> <p>Ao configurar o Email para este servi\u00e7o voc\u00ea, e sua equipe, sempre ser\u00e3o notificados a cada altera\u00e7\u00e3o. </p> </li> <li> <p>\u00c9 poss\u00edvel que os usu\u00e1rios sejam criados localmente e atrav\u00e9s de uma base de usu\u00e1rios LDAP, segue abaixo um exemplo de configura\u00e7\u00e3o utilizando um servidor Active Directory. </p> <p>Obs: Ap\u00f3s inserir o usu\u00e1rio escolhido no grupo do AD \u201cTeampassGroup\u201d, o usu\u00e1rio n\u00e3o aparecer\u00e1 automaticamente na lista de usu\u00e1rios existentes, se faz necess\u00e1rio que o mesmo tente realizar login na ferramenta. E ao tentar ele entrar\u00e1 automaticamente no grupo de acesso \u201ccommonuser\u201d, que conforme configurado, n\u00e3o possui acesso a nada (apenas login).</p> </li> <li> <p>Ap\u00f3s isso se faz necess\u00e1rio criar uma \u00e1rvore de diret\u00f3rios de forma que fique organizado do jeito mais pr\u00e1tico para seu uso. </p> </li> <li> <p>Posteriormente na op\u00e7\u00e3o \u201cManage Roles\u201d, \u00e9 possivel adicionar grupos de acesso.</p> <p>Conforme pode ver, o grupo \u201ccommonuser\u201d n\u00e3o possui acesso a nada, apenas os outros grupos e de forma granular. </p> </li> <li> <p>Por \u00faltimo, ap\u00f3s a tentativa de login do usu\u00e1rio, ele aparecer\u00e1 na lista de usu\u00e1rios existentes e \u00e9 possivel gerenciar e indicar quais roles esse usu\u00e1rio possui. </p> </li> </ol> <p>E assim, finalizamos a instala\u00e7\u00e3o e configura\u00e7\u00e3o b\u00e1sica do TeamPass.</p> <p>Bom uso e bom proveito.</p> <p>Fonte: 1. https://teampass.net/</p> <p>Bonus (em breve) A aplica\u00e7\u00e3o tambem suporta a utiliza\u00e7\u00e3o de API e Autentica\u00e7\u00e3o de 2 fatores. E para quem interessar a ferramenta j\u00e1 possui imagem em Docker.</p>","tags":["teampass"]},{"location":"blog/2020/06/01/tooltip_-_elk_stack/","title":"#ToolTip - ELK Stack","text":"","tags":["elk"]},{"location":"blog/2020/06/01/tooltip_-_elk_stack/#tooltip-elk-stack","title":"#ToolTip - ELK Stack","text":"<p>Descri\u00e7\u00e3o: ELK \u00e9 um pack de ferramentas utilizadas largamente em v\u00e1rios cen\u00e1rios, que podem variar desde um simples syslog, passando por SIEM (Correlacionador de Logs e Eventos)  e podendo chegar correla\u00e7\u00e3o de bancos de dados, BigData e servindo com seus Dashboards para as \u00e1reas de neg\u00f3cio e Marketing. </p> <p>Workflow das Informa\u00e7\u00f5es de LOG: - Logstash:     \u00c9 uma solu\u00e7\u00e3o para gerenciamento e agrega\u00e7\u00e3o de logs. Voc\u00ea consegue agregar logs de m\u00e1quinas, sistemas operacionais e aplica\u00e7\u00f5es distintas em um \u00fanico lugar. O Logstash permite pegar dados ou qualquer outro registro baseado em tempo, de onde quiser, processar e analisar exatamente como voc\u00ea quiser. O formato estruturado do JSON \u00e9 o padr\u00e3o, e tamb\u00e9m \u00e9 a forma como o ElasticSearch vai trat\u00e1-lo. Existem diversas op\u00e7\u00f5es de filtros e funcionalidades similares. - Elasticsearch:     \u00c9 uma engine de busca com foco na an\u00e1lise de dados em tempo real. Ele possui compatibilidade com a funcionalidade de pesquisa de texto completo padr\u00e3o, mas tamb\u00e9m diversas op\u00e7\u00f5es poderosas de realiza\u00e7\u00e3o de queries. O ElasticSearch \u00e9 baseado em documentos orientados e voc\u00ea pode armazenar tudo o que quiser no formato JSON. - Kibana:     \u00c9 o frontend do nosso stack, que ir\u00e1 apresentar os dados armazenados pelo Logstash no ElasticSearch, em uma interface altamente customiz\u00e1vel com histograma e outros pain\u00e9is. Ele permite transformar os logs em informa\u00e7\u00f5es \u00fateis, pois permite realizar correla\u00e7\u00e3o de eventos, filtrar logs por origem, hosts, e N outras combina\u00e7\u00f5es.</p> <p></p> <p>Ap\u00f3s a exemplica\u00e7\u00e3o acima, escolhemos o cen\u00e1rio de Syslog centralizado para: * Acesso a rede: Switches(tr\u00e1fego) * Aplica\u00e7\u00f5es/Sistemas (Tomcat) * Monitoramento de comandos (Linux) * Auditoria Windows (AD, FileServer)     (exemplifica\u00e7\u00e3o dos arquivos de configura\u00e7\u00e3o nas outras partes)</p> <p>Instala\u00e7\u00e3o e Configura\u00e7\u00e3o B\u00e1sica do ELK:</p> <p>Criar VM Linux CentOS b\u00e1sica: Template CentOS 7</p> <p>Realizar as seguintes instala\u00e7\u00f5es: </p><pre><code>[root@elk ~]# yum -y install epel-release  wget\n[root@elk ~]# yum -y update\n</code></pre><p></p> <p>Ap\u00f3s essas a\u00e7\u00f5es os servidor deve ser rebootado e instalado o java na \u00faltima vers\u00e3o. </p><pre><code>[root@elk ~]# cd /opt/\n[root@elk ~]# wget --no-cookies --no-check-certificate --header \"Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie\" \"http://download.oracle.com/otn-[root@elk ~]# pub/java/jdk/8u151-b12/e758a0de34e24606bca991d704f6dcbf/jdk-8u151-linux-x64.tar.gz\"\n[root@elk ~]# tar xzf jdk-8u151-linux-x64.tar.gz\n[root@elk ~]#\n[root@elk ~]# cd /opt/jdk1.8.0_151/\n[root@elk ~]# alternatives --install /usr/bin/java java /opt/jdk1.8.0_151/bin/java 2\n[root@elk ~]# alternatives --config java\n[root@elk ~]#  \n[root@elk ~]# alternatives --install /usr/bin/jar jar /opt/jdk1.8.0_151/bin/jar 2\n[root@elk ~]# alternatives --install /usr/bin/javac javac /opt/jdk1.8.0_151/bin/javac 2\n[root@elk ~]# alternatives --set jar /opt/jdk1.8.0_151/bin/jar\n[root@elk ~]# alternatives --set javac /opt/jdk1.8.0_151/bin/javac\n[root@elk ~]#\n[root@elk ~]# java -version\nopenjdk version \"1.8.0_151\"\nOpenJDK Runtime Environment (build 1.8.0_151-b09)\nOpenJDK 64-Bit Server VM (build 25.151-b09, mixed mode)\n[root@elk ~]# export JAVA_HOME=/opt/jdk1.8.0_151\n[root@elk ~]# export JRE_HOME=/opt/jdk1.8.0_151/jre\n[root@elk ~]# export PATH=$PATH:/opt/jdk1.8.0_151/bin:/opt/jdk1.8.0_151/jre/bin\n</code></pre><p></p> <p>Criar o arquivo com informa\u00e7\u00f5es de reposit\u00f3rio de todas as features instalada no servi\u00e7o ELK. </p><pre><code>[root@elk ~]# cat /etc/yum.repos.d/elasticsearch.repo\n[elk-6.x]\nname=Kibana repository for 6.x packages\nbaseurl=https://artifacts.elastic.co/packages/6.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=1\nautorefresh=1\ntype=rpm-md\n</code></pre><p></p> <p>Instalaremos as features do ELK. </p><pre><code>[root@elk ~]# yum -y install elasticsearch logstash kibana\n[root@elk ~]# firewall-cmd --permanent --add-port 9200/tcp # ElasticSearch\n[root@elk ~]# firewall-cmd --permanent --add-port 5044/tcp # Logstash\n[root@elk ~]# firewall-cmd --permanent --add-port 5601/tcp # Kibana\n[root@elk ~]# firewall-cmd --permanent --add-port 80/tcp # Nginx\n[root@elk ~]# firewall-cmd --reload\n</code></pre><p></p> <p>Efetuar a altera\u00e7\u00e3o abaixo e os seguintes comandos para o Logstash: </p><pre><code>[root@elk ~]# cat /etc/logstash/logstash.yml | grep -v \"#\"\npath.data: /var/lib/logstash\npath.logs: /var/log/logstash\n[root@elk ~]# systemctl enable logstash\n[root@elk ~]# systemctl start logstash\n</code></pre><p></p> <p>Efetuar a altera\u00e7\u00e3o abaixo e os seguintes comandos para o ElasticSearch. </p><pre><code>[root@elk ~]# cat  /etc/elasticsearch/elasticsearch.yml|grep -v \"#\"\npath.data: /var/lib/elasticsearch\npath.logs: /var/log/elasticsearch\nnetwork.host: &lt;IP da VM&gt;\nhttp.port: 9200\n[root@elk ~]# systemctl enable elasticsearch\n[root@elk ~]# systemctl start elasticsearch\n</code></pre><p></p> <p>Efetuar a altera\u00e7\u00e3o abaixo e os seguintes comandos para o Kibana. </p><pre><code>[root@elk ~]# cat /etc/kibana/kibana.yml |grep -v \"#\"\nelasticsearch.url: \"http://&lt;IP DO ELASTICSEARCH&gt;:9200\"\nlogging.dest: /var/log/kibana.log\n[root@elk ~]# systemctl enable kibana\n[root@elk ~]# systemctl start kibana\n</code></pre><p></p> <p>Realizar a instala\u00e7\u00e3o do NGinx e configura\u00e7\u00e3o conformes abaixo: </p><pre><code>[root@elk ~]# yum -y install nginx\n[root@elk ~]# vim /etc/nginx/conf.d/kibana.conf\nserver {\n        listen 80;\n        server_name elk;\n        auth_basic \"Restricted Access\";\n        auth_basic_user_file /etc/nginx/htpasswd.users;\n        location / {\n                proxy_pass http://localhost:5601;\n                proxy_http_version 1.1;\n                proxy_set_header Upgrade $http_upgrade;\n                proxy_set_header Connection 'upgrade';\n                proxy_set_header Host $host;\n                proxy_cache_bypass $http_upgrade;\n        }\n}\n[root@elk ~]# htpasswd -m /etc/nginx/htpasswd.users &lt;USER.NAME&gt;\n[root@elk ~]# systemctl enable nginx\n[root@elk ~]# systemctl start nginx\n</code></pre><p></p> <p>Essa \u00e9 a instala\u00e7\u00e3o base do ELK, nas outras partes teremos mais exemplifica\u00e7\u00f5es de como utilizar.</p> <p></p>","tags":["elk"]},{"location":"blog/2020/06/02/tooltip_-_elk_stack_-_part2sflow/","title":"#ToolTip - ELK Stack - Part2(SFLOW)","text":"","tags":["elk"]},{"location":"blog/2020/06/02/tooltip_-_elk_stack_-_part2sflow/#tooltip-elk-stack-part2sflow","title":"#ToolTip - ELK Stack - Part2(SFLOW)","text":"<p>Na parte 1 foi discutindo um pouco sobre a ferramenta e sua utiliza\u00e7\u00e3o, neste post irei demonstrar algumas utiliza\u00e7\u00f5es reais de utiliza\u00e7\u00e3o:</p> <p>Um uso bastante comum \u00e9 o de logs de rede, quando um equipamento de rede (switch/router/firewall/..) est\u00e1 com sflow habilitado ele envia alguns dados estatisticos regularmente para o servidor sflow configurado. Esse per\u00edodo geralmente se baseia em quantidade de pacotes trafegados, podendo ser 1/1000(um de mil), 1/10000(um de dez mil), 1/100000(um de cem mil), 1/1000000(um de um milh\u00e3o) a depender da marca/modelo do switch e principamente do poder de processamento disponivel no mesmo, pois quanto mais frequente o envio, mais exige do equipamento. </p> <p>Configura\u00e7\u00e3o do Logstash </p><pre><code>[root@elk ~]# cd /usr/share/logstash/bin/\n[root@elk bin]# ./logstash-plugin install logstash-codec-sflow\n[root@elk ~]#\n[root@elk ~]# vim /etc/logstash/conf.d/10-sflow.conf\ninput {\n        udp {\n                port =&gt; 6343\n                codec =&gt; sflow {}\n                type =&gt; \"sflow\"\n        }\n}\noutput {\n        if [type] == \"sflow\" {\n                elasticsearch {\n                        hosts =&gt; [\"&lt;IP DO ELASTIC&gt;:9200\"]\n                        index =&gt; \"sflow-%{+YYYY.MM.dd}\"\n                }\n        }\n}\n\n[root@elk ~]# systemctl restart logstash\n[root@elk ~]# firewall-cmd --permanent --add-port=6343/udp\nsuccess\n[root@elk ~]# firewall-cmd --reload\nsuccess\n[root@elk ~]#\n</code></pre><p></p> <p>Configura\u00e7\u00e3o no Switch </p><pre><code>interface GigabitEthernet1/0/10\n sflow sampling-rate 1000\n sflow flow collector 1\n#\ninterface GigabitEthernet1/0/11\n sflow sampling-rate 1000\n sflow flow collector 1\n#\ninterface GigabitEthernet1/0/12\n sflow sampling-rate 1000\n sflow flow collector 1\n#\ninterface GigabitEthernet1/0/13\n sflow sampling-rate 1000\n sflow flow collector 1\n#\ninterface GigabitEthernet1/0/22\n sflow sampling-rate 1000\n sflow flow collector 1\n#\ninterface GigabitEthernet2/0/10\n sflow sampling-rate 1000\n sflow flow collector 1\n#\ninterface GigabitEthernet2/0/11\n sflow sampling-rate 1000\n sflow flow collector 1\n#\ninterface GigabitEthernet2/0/12\n sflow sampling-rate 1000\n sflow flow collector 1\n#\ninterface GigabitEthernet2/0/13\n sflow sampling-rate 1000\n sflow flow collector 1\n#\ninterface GigabitEthernet2/0/22\n sflow sampling-rate 1000\n sflow flow collector 1\n#\n sflow agent ip &lt;IP DO SWITCH&gt;\n sflow source ip &lt;IP DO SWITCH&gt;\n sflow collector 1 ip &lt;IP DO LOGSTASH&gt; description \"CLI Collector\"\n#\n</code></pre><p></p> <p>Ap\u00f3s esses procedimentos, o switch ir\u00e1 come\u00e7ar a enviar pacotes para o ELK, fazendo com que o index seja criado e alimentado. Mas para que ele seja visivel \u00e9 necess\u00e1rio criar o  (Index Patterns). </p> <p>Conforme colocamos no arquivo de configura\u00e7\u00e3o, o prefixo definido \u00e9 \u201csflow-\u201c, logo, esse ser\u00e1 o pattern a ser criado. </p> <p>Abaixo demonstra como \u00e9 a visualiza\u00e7\u00e3o no ELK. </p> <p>Quanto a parte de configura\u00e7\u00e3o \u00e9 isso. A partir de agora voc\u00ea pode determinar/criar visualiza\u00e7\u00f5es a partir das op\u00e7\u00f5es disponiveis.</p> <p>Exemplos de Filtros poss\u00edveis. </p>","tags":["elk"]},{"location":"blog/2020/06/03/tooltip_-_elk_stack_-_part3tomcat/","title":"#ToolTip - ELK Stack - Part3(Tomcat)","text":"","tags":["elk"]},{"location":"blog/2020/06/03/tooltip_-_elk_stack_-_part3tomcat/#tooltip-elk-stack-part3tomcat","title":"#ToolTip - ELK Stack - Part3(Tomcat)","text":"<p>Continuando os estudos e utiliza\u00e7\u00f5es sobre o ELK, segue uma utiliza\u00e7\u00e3o geralmente utilizada no monitoramento de aplica\u00e7\u00f5es Tomcat:</p> <p>Arquivo de configura\u00e7\u00e3o do logstash. Ap\u00f3s adi\u00e7\u00e3o do conte\u00fado ser\u00e1 necess\u00e1rio reiniciar o servi\u00e7o, assim como liberar a respectiva porta no Firewall.</p> <pre><code>[root@elk ~]# vim /etc/logstash/conf.d/20-tomcat.conf\ninput {\n  udp {\n    port =&gt; 2514\n    type =&gt; \"tomcat\"\n  }\n}\n\nfilter {\n  if [type] == \"tomcat\" {\n    grok {\n      patterns_dir =&gt; [\"/etc/logstash/patterns\"]\n      match =&gt; { \"message\" =&gt; \"%{SYSLOGTIMESTAMP:syslog_timestamp} %{HOSTID:hostname} %{WORD:loglevel} %{WORD:method} %{URIPATHPARAM:urlpath} %{NUMBER:httpcode} %{USERNAME:userid} %{IP:client} %{NUMBER:durationms:int} %{NUMBER:durationsec:float}\" }\n    }\n  }\n}\n\noutput {\n        if [type] == \"tomcat\" {\n                elasticsearch {\n                        hosts =&gt; [\"&lt;IP DO ELASTIC&gt;:9200\"]\n                        index =&gt; \"tomcat-index-%{+YYYY.MM.dd}\"\n                }\n        }\n}\n[root@elk ~]# firewall-cmd --permanent --add-port=2514/udp\nsuccess\n[root@elk ~]# firewall-cmd --reload\nsuccess\n[root@elk ~]# vim /etc/logstash/patterns/tomcats\nUSERNAME [a-zA-Z0-9._-]+\nHOSTID [a-zA-Z0-9._-]+\n[root@elk ~]#\n[root@elk ~]# systemctl restart logstash\n[root@elk ~]#\n</code></pre> <p>Vamos ent\u00e3o para a configura\u00e7\u00e3o do servi\u00e7o nos servidores Tomcat. O campo a ser adicionado deve ser incluido no arquivo de configura\u00e7\u00e3o indicado, logo acima do \u201c\u201d. </p><pre><code>[root@tomcat1 ~]#\n[root@tomcat1 ~]# vim /opt/tomcat/conf/server.xml\n....\n      &lt;Host name=\"localhost\"  appBase=\"webapps\"\n            unpackWARs=\"true\" autoDeploy=\"true\"\n            xmlValidation=\"false\" xmlNamespaceAware=\"false\"&gt;\n\n        &lt;Valve\n                className=\"org.apache.catalina.valves.AccessLogValve\"\n                directory=\"${catalina.base}/logs\"\n                prefix=\"tomcat-2-elk\"\n                suffix=\".log\"\n                pattern=\"%m %U %s %u %a %D %T\"\n\n        /&gt;\n\n      &lt;/Host&gt;\n...\n[root@tomcat1 ~]# systemctl restart tomcat\n[root@tomcat1 ~]#\n</code></pre><p></p> <p>Esta linha adicionar\u00e1 no diret\u00f3rio de logs um arquivo chamado \u201ctomcat-2-elk.log\u201d e que ser\u00e1 preenchido seguindo o pattern escolhido, conforme as aplica\u00e7\u00f5es sejam acessadas. Mais op\u00e7\u00f5es podem ser utilizadas e consumidas, segue link com descri\u00e7\u00e3o. \u00c9 importante lembrar que cada campo informano neste pattern corresponde a um campo no match no arquivo de configura\u00e7\u00e3o do logstash, caso seja altearado aqui, tamb\u00e9m deve ser alterado l\u00e1 para manter um fluxo correto de informa\u00e7\u00f5es.</p> Pattern Descri\u00e7\u00e3o %a IP Remoto (cliente) %D Tempo da requisi\u00e7\u00e3o em milisegundos %m M\u00e9todo de requisi\u00e7\u00e3o %s Http code, da requisi\u00e7\u00e3o %T Tempo da requisi\u00e7\u00e3o em segundos %U URL path acessada %u Usu\u00e1rio remoto (autenticado) <p>Segue um exemplo de como \u00e9 o arquivo de log. </p><pre><code>[root@tomcat1 ~]#\n[root@tomcat1 ~]# tail /opt/tomcat/logs/tomcat-2-elk.log\nGET /application/scripts/global.js 200 user.teste01 172.16.199.252 0 0.000\nGET /application/scripts/system.js 200 user.teste01 172.16.199.252 1 0.200\nGET /application/scripts/ua.js 200 user.teste01 172.16.199.252 1 0.100\nGET /application/scripts/browser.js 200 user.teste01 172.16.199.252 0 0.000\nGET /application/scripts/tooltip.js 200 user.teste01 172.16.199.252 1 0.130\nGET /application/scripts/CalendarPopup.js 304 user.teste01 172.16.199.252 0 0.000\nGET /application/scripts/hint.js 304 user.teste01 172.16.199.252 0 0.000\nGET /application/scripts/coolmenus3.js 404 user.teste01 172.16.199.252 1 0.000\nGET /application/scripts/coolmenu-config.js 304 user.teste01 172.16.199.252 0 0.000\nGET /application/images/body_grad.png 200 user.teste01 172.16.199.252 1 0.800\n[root@tomcat1 ~]#\n</code></pre><p></p> <p>Com a configura\u00e7\u00e3o j\u00e1 em funcionamento, podemos ir para o pr\u00f3ximo passo que \u00e9 o envio desse arquivo para o ELK. Existem algumas formas para se fazer isso a que usarei ser\u00e1 o rsyslog. (outra op\u00e7\u00e3o \u00e9 o Filebeat, que \u00e9 uma ferramenta da Elastic). Foram adicionado os par\u00e2metros no arquivo de configura\u00e7\u00e3o do rsyslog e ap\u00f3s realizado o restart do servi\u00e7o.  </p><pre><code>[root@tomcat1 ~]#\n[root@tomcat1 ~]# vim /etc/rsyslog.conf\n.....\n$ModLoad imfile\n$InputFileName /opt/tomcat/logs/tomcat-2-elk.log\n$InputFileTag tomcatinfo\n$InputFileStateFile stat-tomcat-info\n$InputFileSeverity debug\n$InputFileFacility local3\n$InputRunFileMonitor\n\nlocal3.* @&lt;IP DO LOGSTASH&gt;:2514\n\n[root@tomcat1 ~]# systemctl restart rsyslog\n[root@tomcat1 ~]#\n</code></pre><p></p> <p>A partir disso os logs j\u00e1 ir\u00e3o ser automaticamente enviados para o ELK, a cada nova linha adicionada no arquivo. No ELK \u00e9 necess\u00e1rio que seja adicionado Index Pattern correspondente, conforme est\u00e1 no arquivo de configura\u00e7\u00e3o. </p> <p>Segue como os logs ser\u00e3o exibidos: </p> <p>A partir da\u00ed \u00e9 possivel criar suas visualiza\u00e7\u00f5es para montar seu dashboard, segue exemplo </p> <p>B\u00f4nus:</p> <p>Dependendo do seu fluxo de acesso no servidor, esse log pode crescer a ponto de comprometer o servi\u00e7o do tomcat. Uma boa pr\u00e1tica \u00e9 criar um rotate para esse arquivo de log, j\u00e1 que a informa\u00e7\u00e3o dele provavelmente j\u00e1 foi enviada para o ELK. Segue um exemplo de como configurar. </p><pre><code>[root@tomcat1 ~]#\n[root@tomcat1 ~]# vim /etc/logrotate.d/tomcat-2-elk\n/opt/tomcat/logs/tomcat-2-elk.log {\n  size 10M\n  copytruncate\n  dateext\n  rotate 2\n  compress\n  maxage 5\n}\n[root@tomcat1 ~]# /usr/sbin/logrotate -f /etc/logrotate.d/tomcat-2-elk\n[root@tomcat1 ~]#\n</code></pre><p></p>","tags":["elk"]},{"location":"blog/2020/06/04/tooltip_-_elk_stack_-_part4command_monitoring/","title":"#ToolTip - ELK Stack - Part4(Command Monitoring)","text":"","tags":["elk"]},{"location":"blog/2020/06/04/tooltip_-_elk_stack_-_part4command_monitoring/#tooltip-elk-stack-part4command-monitoring","title":"#ToolTip - ELK Stack - Part4(Command Monitoring)","text":"<p>Uma necessidade muito importante para um ambinte de infraestrutura, \u00e9 saber o por que uma coisa aconteceu e se poss\u00edvel ter a auditoria da mesma. As vezes se faz necess\u00e1rio descobrir quais atividades foram realizadas por qual usu\u00e1rio. Segue abaixo um meio que encontrei de ter evid\u00eancias dos comandos executados.</p> <p>Passo 1: Adicionar o trecho abaixo no final do arquivo \u201c/etc/bashrc\u201d para que seja padr\u00e3o para todos usu\u00e1rios conforme realize login.</p> <pre><code>[root@linux00 ~]$vim /etc/bashrc\n....\n# Adicionando comandos no rsyslogd\nexport PROMPT_COMMAND='history -a &gt;(tee -a ~/.bash_history | logger -p local6.debug -t \"$USER[$$] $SSH_CONNECTION\")'\n[root@linux00 ~]$\n</code></pre> <p>Explica\u00e7\u00e3o: A linha informa que o ultimo comando executado, al\u00e9m de adicionado ao .bash_history tamb\u00e9m ser\u00e1 enviado via logger com as informa\u00e7\u00f5es do Usu\u00e1rio logado e informa\u00e7\u00f5es de conex\u00e3o SSH.</p> <p>Passo 2: Adicionar o servi\u00e7o rsyslog o arquivo conforme abaixo: </p><pre><code>[root@linux00 ~]$vim /etc/rsyslog.d/bash.conf\nlocal6.* @&lt;IP DO LOGSTASH&gt;:4514\n[root@linux00 ~]$\n[root@linux00 ~]$ systemctl restart rsyslog\n[root@linux00 ~]$\n</code></pre><p></p> <p>Passo 3: Configurar o Logstash para receber as informa\u00e7\u00f5es passadas. </p><pre><code>[root@elk ~]# vim /etc/logstash/conf.d/40-linuxcommands.conf\ninput {\n  udp {\n    port =&gt; 4514\n    type =&gt; \"rsyslog\"\n  }\n}\n\nfilter {\n        grok {\n            match =&gt; {\n                \"message\" =&gt; \"%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}?: %{DATA:syslog_user}\\[%{POSINT:syslog_pid}\\] : %{GREEDYDATA:syslog_command}\"\n                }\n            add_field =&gt; [ \"received_from\", \"%{host}\" ]\n        }\n        grok {\n            match =&gt; {\n                \"message\" =&gt; \"%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program} %{DATA:syslog_user}\\[%{POSINT:syslog_pid}\\] %{DATA:syslog_ip_src} %{DATA:syslog_port_src} %{DATA:syslog_ip_dest} %{DATA:syslog_port_dest}: %{GREEDYDATA:syslog_command}\"\n                }\n            add_field =&gt; [ \"received_from\", \"%{host}\" ]\n        }\n}\n\noutput {\n if [type] == \"rsyslog\" {\n    elasticsearch {\n      hosts =&gt; [\"&lt;IP DO ELASTIC&gt;:9200\"]\n      index =&gt; \"linuxcommands-%{+YYYY.MM.dd}\"\n    }\n }\n}\n\n[root@elk ~]#\n</code></pre><p></p> <p>Neste arquivo, criei dois Matchs possiveis, um que indique o IP/Porta de Origem, e outro para quando n\u00e3o seja poss\u00edvel informar (Ex: ap\u00f3s uma escalada de privil\u00e9gios).</p> <p>Passo 4: Adicionar o Index Patterns, conforme configurado no arquivo do Logstash. </p> <p>Passo 5: Visualizar os logs. \u00c9 possivel ver a quantidade de informa\u00e7\u00e3o recebida pelo syslog a partir do campo \u201cmessage\u201d, a partir dai o Logstash faz um parse na mensagem e a divide em informa\u00e7\u00f5es melhores vistas do ponto de vista humano.</p> <p>Log com a informa\u00e7\u00e3o do IP de origem: </p> <p>Log sem a informa\u00e7\u00e3o do IP de origem (ap\u00f3s escalada de privil\u00e9gio) </p> <p>Tamb\u00e9m \u00e9 possivel criar um dashboard informando a lista de \u00faltimos comandos executados. </p>","tags":["elk"]},{"location":"blog/2020/07/01/tooltip_-_elk_stack_-_log_maintenance/","title":"#ToolTip - ELK Stack - Log Maintenance","text":"","tags":["elk"]},{"location":"blog/2020/07/01/tooltip_-_elk_stack_-_log_maintenance/#tooltip-elk-stack-log-maintenance","title":"#ToolTip - ELK Stack - Log Maintenance","text":"<p>Se voc\u00ea usa a ferramenta ELK (vers\u00e3o community) sabe que tem algumas limita\u00e7\u00f5es, principalmente no quesito manuten\u00e7\u00e3o/administra\u00e7\u00e3o.</p>","tags":["elk"]},{"location":"blog/2020/07/01/tooltip_-_elk_stack_-_log_maintenance/#sem-espaco-em-disco","title":"Sem espa\u00e7o em disco:","text":"<p>Dependendo do tamanho da sua infraestrutura \u00e9 bastante complicado manter e rotacionar os logs principalmente por n\u00e3o poder automatizar nada pela propria ferramenta. Um meio que encontrei de realizar isso \u00e9 utilizando o proprio bash.</p> <p>Como em todos os arquivos de configura\u00e7\u00e3o do logstash eu indiquei qual o formato do nome do index Pattern eu queria, sempre esta organizado em \u201cnomeindex-ano.mes.dia\u201d (posts anteriores). Ent\u00e3o diariamente ser\u00e1 criado um novo padr\u00e3o de index respeitando o padr\u00e3o indicado.</p> <p>Pra visualizar todos os indexs criados, utilizei a ferramenta curl conforme abaixo. </p><pre><code>[root@elk ~]# curl -s '&lt;IP DO ELASTIC&gt;:9200/_cat/indices?v'\nhealth status index                           uuid                   pri rep docs.count docs.deleted store.size pri.store.size\nyellow open   fuse-2020.04.06                 jD4RYxp9T0-1SQyj5Nbg0Q   3   1    1849552            0    496.2mb        496.2mb\nyellow open   haproxy-index-2020.04.08        UyppsDqVTRSstcQthYbBMg   5   1     452541            0    380.9mb        380.9mb\nyellow open   fuse-2020.03.12                 kFfOcuMlR5G4hoCV-tJTsw   3   1    1140480            0    267.7mb        267.7mb\nyellow open   fuse-2020.04.18                 GGXc6JufSSu9rQO21l71sQ   3   1    1650477            0    468.8mb        468.8mb\nyellow open   tomcat-index-2020.04.19         YHkms1YATjmMYjdRSNCOWA   5   1    1906775            0    461.8mb        461.8mb\nyellow open   fuse-2020.04.20                 _Q8JvrwgQKqcIiqlawcrbA   3   1    1879587            0    499.9mb        499.9mb\nyellow open   fuse-2020.05.04                 ttLv5EBTRcme3V-TyF1yfg   3   1    1809184            0    491.4mb        491.4mb\ngreen  open   .kibana_task_manager            84KpsjRMTQ2Y8m5fjUKSXw   1   0          2            0       13kb           13kb\nyellow open   sflow-2020.04.16                tccFw6JdRqSbop4fkVKaYg   5   1     113336            0     38.3mb         38.3mb\nyellow open   tomcat-index-2020.05.06         yRGJKwc5ToipSFXJ0g33pA   5   1     323874            0     79.9mb         79.9mb\ngreen  open   .monitoring-kibana-6-2020.05.05 sOTVTm_WRfe_7_L02iQJZw   1   0      17278            0      2.9mb          2.9mb\nyellow open   apm-6.8.4-onboarding-2019.11.11 HMXsfQ61To6yyV41Fx_AGQ   1   1          2            0     11.9kb         11.9kb\ngreen  open   .monitoring-kibana-6-2020.05.03 1nyA2ReBSYyEsgAzx-WEIQ   1   0      17278            0      2.8mb          2.8mb\nyellow open   fuse-2020.04.25                 Xr0cW0hETpmMGyFj1Nv1hQ   3   1    1847443            0    494.1mb        49mb\n.....\n</code></pre><p></p> <p>Caso queira visualizar algum em espec\u00edfico, pode complementar a pesquisa com a ferramenta grep. </p><pre><code>[root@elk ~]# curl -s '&lt;IP DO ELASTIC&gt;:9200/_cat/indices?v'|grep sflow\nyellow open   sflow-2020.04.16                tccFw6JdRqSbop4fkVKaYg   5   1     113336            0     38.3mb         38.3mb\nyellow open   sflow-2020.04.22                eNtzfvm0TfCE9hVezsVCOw   5   1     192250            0     57.1mb         57.1mb\nyellow open   sflow-2020.03.20                gWQGYPt6TgWRQjVw6GMaUw   5   1     187187            0     65.7mb         65.7mb\nyellow open   sflow-2020.03.10                dbRbrlagSnec88HqLCFJTQ   5   1     263029            0     87.3mb         87.3mb\nyellow open   sflow-2020.03.15                Dg5Se7wXR_ujnJNy1_8hYQ   5   1     324807            0     99.7mb         99.7mb\nyellow open   sflow-2020.05.06                j7iATksGTF6cp-JvqJ3WWA   5   1      15546            0      6.5mb          6.5mb\nyellow open   sflow-2020.03.27                gB1P3Wa4QmqVwqjPhcP0rw   5   1      84101            0     28.8mb         28.8mb\nyellow open   sflow-2020.03.14                mEB0FUoZQdCJU0vK_xCTTA   5   1     336368            0    111.9mb        111.9mb\nyellow open   sflow-2020.03.23                MPDWlbPDSUqWbjWk5yKZsA   5   1     237505            0     69.1mb         69.1mb\nyellow open   sflow-2020.05.04                iNKLFW6sQ8K7plYiQooI7A   5   1     232472            0     69.1mb         69.1mb\n.....\n</code></pre><p></p> <p>Caso deseje excluir algum Index de algum dia em espec\u00edfico (Ex: sflow-2020.04.11), se faz necess\u00e1rio a utiliza\u00e7\u00e3o de \u201crequest Command\u201d, op\u00e7\u00e3o -XDELETE. </p><pre><code>[root@elk ~]# curl -s -XDELETE '&lt;IP DO ELASTIC&gt;:9200/sflow-2020.04.11\n{\"acknowledged\":true}\n[root@elk ~]#\n</code></pre><p></p> <p>Caso queria excluir mais de um Index, ex: (m\u00eas inteiro), tamb\u00e9m \u00e9 poss\u00edvel utilizando \u201c*\u201d. </p><pre><code>[root@elk ~]# curl -s -XDELETE '&lt;IP DO ELASTIC&gt;:9200/sflow-2020.04.*\n{\"acknowledged\":true}\n[root@elk ~]#\n</code></pre><p></p> <p>Ap\u00f3s definir por quanto tempo voc\u00ea pretente manter cada Index, baseando-se previamente na criticidade de cada um \u00e9 poss\u00edvel automatizar adicionando um crontab. Conforme exemplo abaixo: </p><pre><code>[root@elk ~]# crontab -l\n# Limpar Logs do ELK\n00 01 * * * bash /root/clear-elk.sh\n[root@elk ~]#\n[root@elk ~]# vim /root/clear-elk.sh\n#!/bin/bash\n\nMESES2=$(date --date=\"2 months ago\" +%Y.%m.%d)\nMESES3=$(date --date=\"3 months ago\" +%Y.%m.%d)\nMESES6=$(date --date=\"6 months ago\" +%Y.%m.%d)\nDATE=$(date +%Y-%m-%d-%H:%M )\n\necho \"\" &gt;&gt; /var/log/logstash/manual-rotate.log\necho \"$DATE bpad01 limpando log maior que 6 Meses\" &gt;&gt; /var/log/logstash/manual-rotate.log\ncurl -s -XDELETE &lt;IP DO ELASTIC&gt;:9200/bpad01-$MESES6* &amp;amp;&gt;&gt; /var/log/logstash/manual-rotate.log\n\necho \"\" &gt;&gt; /var/log/logstash/manual-rotate.log\necho \"$DATE auditoriafs limpando log maior que 3 Meses\" &gt;&gt; /var/log/logstash/manual-rotate.log\ncurl -s -XDELETE &lt;IP DO ELASTIC&gt;:9200/auditoriafs-$MESES3* &amp;amp;&gt;&gt; /var/log/logstash/manual-rotate.log\n\necho \"\" &gt;&gt; /var/log/logstash/manual-rotate.log\necho \"$DATE HAPROXY limpando log maior que 2 Meses\" &gt;&gt; /var/log/logstash/manual-rotate.log\ncurl -s -XDELETE &lt;IP DO ELASTIC&gt;:9200/haproxy-index-$MESES2* &amp;amp;&gt;&gt; /var/log/logstash/manual-rotate.log\n\necho \"\" &gt;&gt; /var/log/logstash/manual-rotate.log\necho \"$DATE FILEBEAT limpando log maior que 2 Meses\" &gt;&gt; /var/log/logstash/manual-rotate.log\ncurl -s -XDELETE &lt;IP DO ELASTIC&gt;:9200/filebeat-6.2.3-$MESES2* &amp;amp;&gt;&gt; /var/log/logstash/manual-rotate.log\n\necho \"\" &gt;&gt; /var/log/logstash/manual-rotate.log\necho \"$DATE SFLOW limpando log maior que 2 Meses\" &gt;&gt; /var/log/logstash/manual-rotate.log\ncurl -s -XDELETE &lt;IP DO ELASTIC&gt;:9200/sflow-$MESES2* &amp;amp;&gt;&gt; /var/log/logstash/manual-rotate.log\n\necho \"\" &gt;&gt; /var/log/logstash/manual-rotate.log\necho \"$DATE FUSE limpando log maior que 2 Meses\" &gt;&gt; /var/log/logstash/manual-rotate.log\ncurl -s -XDELETE &lt;IP DO ELASTIC&gt;:9200/fuse-$MESES2* &amp;amp;&gt;&gt; /var/log/logstash/manual-rotate.log\n\necho \"\" &gt;&gt; /var/log/logstash/manual-rotate.log\necho \"$DATE TOMCAT_INDEX limpando log maior que 2 Meses\" &gt;&gt; /var/log/logstash/manual-rotate.log\ncurl -s -XDELETE &lt;IP DO ELASTIC&gt;:9200/tomcat-index-$MESES2* &amp;amp;&gt;&gt; /var/log/logstash/manual-rotate.log\n\necho \"\" &gt;&gt; /var/log/logstash/manual-rotate.log\necho \"----------------------------------------------------------\" &gt;&gt; /var/log/logstash/manual-rotate.log\n</code></pre><p></p> <p>O script acima, al\u00e9m de executar diariamente o rotate dos Index existentes, conforme reten\u00e7\u00e3o definida, ainda adiciona num arquivo de log toda atividade realizada.</p>","tags":["elk"]},{"location":"blog/2020/07/01/tooltip_-_elk_stack_-_log_maintenance/#limitando-o-acesso","title":"Limitando o acesso:","text":"<p>Inicialmente n\u00e3o \u00e9 poss\u00edvel que ter grupos de usu\u00e1rios com niveis de acesso diferenciado. Primordialmente n\u00e3o existe tela de login, mas \u00e9 possivel colocar uma feature extremamente conhecida chamada htpasswd atrav\u00e9s de proxys-reverso (apache/nginx). Segue exemplo de configura\u00e7\u00e3o existente no meu lab. </p><pre><code>[root@elk ~]# vim /etc/nginx/conf.d/kibana.conf\nserver {\n        listen 80;\n        server_name elk.cringerlabs.local;\n        auth_basic \"Restricted Access\"; # Aviso no Banner\n        auth_basic_user_file /etc/nginx/htpasswd.users; #Base de usu\u00e1rios em arquivo\n        location / {\n                proxy_pass http://localhost:5601;\n                proxy_http_version 1.1;\n                proxy_set_header Upgrade $http_upgrade;\n                proxy_set_header Connection 'upgrade';\n                proxy_set_header Host $host;\n                proxy_cache_bypass $http_upgrade;\n        }\n}\n[root@elk ~]# htpasswd /etc/nginx/htpasswd.users karlipe\nNew password:\nRe-type new password:\nAdding password for user karlipe\n[root@elk ~]#\n[root@elk ~]# systemctl reload nginx\n[root@elk ~]#\n</code></pre><p></p> <p>Tela de autentica\u00e7\u00e3o: </p> <p>Vale lembrar que todos os usu\u00e1rios criados ter\u00e3o o mesmo n\u00edvel de acesso.</p> <p>Por hoje \u00e9 isso, bom uso!</p>","tags":["elk"]},{"location":"blog/2020/07/03/tooltip_-_awx_ansible_tower/","title":"#ToolTip - AWX (Ansible Tower)","text":"","tags":["ansible"]},{"location":"blog/2020/07/03/tooltip_-_awx_ansible_tower/#tooltip-awx-ansible-tower","title":"#ToolTip - AWX (Ansible Tower)","text":"<p>Pra voc\u00ea que est\u00e1 mexendo com Ansible a um tempo, com certeza j\u00e1 deve conhecer essa ferramenta. Simplesmente uma das interfaces de gerenciamento mais conhecidas para o ansible. AWX tamb\u00e9m \u00e9 o projeto upstream do Ansible Tower, que pertence a Red Hat.</p> <p>Com base na documenta\u00e7\u00e3o oficial, existem 3 formas de instala\u00e7\u00e3o, Openshift, Kubernetes e Docker compose. Irei mostrar o procedimento para instala\u00e7\u00e3o utilizando Containers(docker) em cima do CentOS 7. Vamos iniciar com os pre-requisitos para o correta instala\u00e7\u00e3o.</p> <pre><code>yum install -y yum-utils git ansible python3 libselinux-python3 -y\n</code></pre> <p>Agora instala\u00e7\u00e3o do Docker. </p><pre><code>yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\nyum install docker-ce docker-ce-cli containerd.io -y \n\nsystemctl start docker\nsystemctl enable docker\nInstala\u00e7\u00e3o do docker-compose (m\u00f3dulo python).\n</code></pre><p></p> <pre><code>pip3 install docker-compose\nalternatives --set python /usr/bin/python3\n</code></pre> <p>Instala\u00e7\u00e3o do Docker compose. </p><pre><code>curl -L \"https://github.com/docker/compose/releases/download/1.26.1/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose\nln -s /usr/local/bin/docker-compose /usr/bin/docker-compose\n</code></pre><p></p> <p>Cria\u00e7\u00e3o das regras de firewall necess\u00e1rias para o funcionamento do servi\u00e7o. </p><pre><code>firewall-cmd --zone=public --add-masquerade --permanent\nfirewall-cmd --permanent --add-service=http\nfirewall-cmd --permanent --add-service=https\nfirewall-cmd --reload\n</code></pre><p></p> <p>Cria\u00e7\u00e3o do diret\u00f3rio default do projeto para o postgres, conforme arquivo de configura\u00e7\u00e3o. E download dos arquivos do projeto oficial no github. </p><pre><code>mkdir /var/lib/pgdocker\ngit clone https://github.com/ansible/awx.git\ncd awx/installer/\n</code></pre><p></p> <p>Execu\u00e7\u00e3o do playbook de instala\u00e7\u00e3o. </p><pre><code>ansible-playbook -i inventory install.yml\n</code></pre><p></p> <p>Com isso voc\u00ea pode acessar no ip ou hostname da M\u00e1quina que voc\u00ea instalou. Ir\u00e1 aparecer uma p\u00e1gina como esta. Login e Senha padr\u00e3o , admin / password. </p> <p>Agora, \u00e9 cadastrar os hosts, configurar os playbooks e os jobs. </p>","tags":["ansible"]},{"location":"blog/2020/07/03/tooltip_-_awx_ansible_tower/#workaround1-awx-is-upgrading","title":"Workaround1 \u2013 AWX is Upgrading","text":"<p>Caso ap\u00f3s o procedimento de instala\u00e7\u00e3o tenha aparecido uma tela como esta e permane\u00e7a por muito tempo. </p> <p>Voc\u00ea pode enviar o comando a partir da m\u00e1quina onde est\u00e1 instalado: </p><pre><code>docker logs -f awx_task\n</code></pre><p></p> <p>Com isso voc\u00ea ir\u00e1 acompanhar os logs do container, awx_task. Caso voc\u00ea encontre repetidamente a exist\u00eancia do seguinte trecho nos logs, significa que algo ocorreu durante o boot dos containers e n\u00e3o est\u00e1 comunicando corretamente</p> <pre><code>django.db.utils.ProgrammingError: relation \"main_instance\" does not exist\nLINE 1: SELECT (1) AS \"a\" FROM \"main_instance\" WHERE \"main_instance\"...\n                               ^\n\n2020-07-03 20:16:21,353 INFO exited: dispatcher (exit status 1; not expected)\n2020-07-03 20:16:21,353 INFO exited: dispatcher (exit status 1; not expected)\n2020-07-03 20:16:22,357 INFO spawned: 'dispatcher' with pid 237\n2020-07-03 20:16:22,357 INFO spawned: 'dispatcher' with pid 237\n2020-07-03 20:16:23,359 INFO success: dispatcher entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)\n2020-07-03 20:16:23,359 INFO success: dispatcher entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)\n2020-07-03 20:16:25,793 WARNING  awx.main.dispatch.periodic periodic beat started\nTraceback (most recent call last):\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\npsycopg2.errors.UndefinedTable: relation \"main_instance\" does not exist\nLINE 1: SELECT (1) AS \"a\" FROM \"main_instance\" WHERE \"main_instance\"...\n                               ^\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/bin/awx-manage\", line 8, in &lt;module&gt;\n    sys.exit(manage())\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/awx/__init__.py\", line 154, in manage\n    execute_from_command_line(sys.argv)\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/django/core/management/__init__.py\", line 381, in execute_from_command_line\n    utility.execute()\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/django/core/management/__init__.py\", line 375, in execute\n    self.fetch_command(subcommand).run_from_argv(self.argv)\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/django/core/management/base.py\", line 323, in run_from_argv\n    self.execute(*args, **cmd_options)\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/django/core/management/base.py\", line 364, in execute\n    output = self.handle(*args, **options)\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/awx/main/management/commands/run_dispatcher.py\", line 55, in handle\n    reaper.reap()\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/awx/main/dispatch/reaper.py\", line 38, in reap\n    (changed, me) = Instance.objects.get_or_register()\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/awx/main/managers.py\", line 144, in get_or_register\n    return (False, self.me())\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/awx/main/managers.py\", line 100, in me\n    if node.exists():\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/django/db/models/query.py\", line 766, in exists\n    return self.query.has_results(using=self.db)\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/django/db/models/sql/query.py\", line 522, in has_results\n    return compiler.has_results()\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/django/db/models/sql/compiler.py\", line 1110, in has_results\n    return bool(self.execute_sql(SINGLE))\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/django/db/models/sql/compiler.py\", line 1140, in execute_sql\n    cursor.execute(sql, params)\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/django/db/backends/utils.py\", line 67, in execute\n    return self._execute_with_wrappers(sql, params, many=False, executor=self._execute)\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/django/db/backends/utils.py\", line 76, in _execute_with_wrappers\n    return executor(sql, params, many, context)\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/django/db/utils.py\", line 89, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n  File \"/var/lib/awx/venv/awx/lib/python3.6/site-packages/django/db/backends/utils.py\", line 84, in _execute\n    return self.cursor.execute(sql, params)\ndjango.db.utils.ProgrammingError: relation \"main_instance\" does not exist\nLINE 1: SELECT (1) AS \"a\" FROM \"main_instance\" WHERE \"main_instance\"...\n                               ^\n</code></pre> <p>Uma solu\u00e7\u00e3o que encontrei para isso foi, reiniciar o servi\u00e7o docker. Ap\u00f3s o reboot, os servi\u00e7os normalizaram e subiram corretamente, e o log do awx_task ficou, assim: </p><pre><code>RESULT 2\nOKREADY\n2020-07-04 02:44:02,426 DEBUG    awx.main.dispatch task f6eee5e4-5a28-4b36-81e0-0742d680a54e starting awx.main.tasks.awx_periodic_scheduler(*[])\n2020-07-04 02:44:02,433 DEBUG    awx.main.tasks Starting periodic scheduler\n2020-07-04 02:44:02,436 DEBUG    awx.main.tasks Last scheduler run was: 2020-07-04 02:43:32.404286+00:00\n2020-07-04 02:44:12,437 DEBUG    awx.main.dispatch task d38b3829-0bc3-4476-a164-c9b8017e8711 starting awx.main.scheduler.tasks.run_task_manager(*[])\n2020-07-04 02:44:12,438 DEBUG    awx.main.scheduler Running Tower task manager.\n2020-07-04 02:44:12,452 DEBUG    awx.main.scheduler Starting Scheduler\n2020-07-04 02:44:12,479 DEBUG    awx.main.scheduler Finishing Scheduler\n2020-07-04 02:44:32,477 DEBUG    awx.main.dispatch task e9f7f38b-5638-41d9-bf20-daa04b43f792 starting awx.main.tasks.awx_periodic_scheduler(*[])\n2020-07-04 02:44:32,595 DEBUG    awx.main.tasks Starting periodic scheduler\n2020-07-04 02:44:32,473 DEBUG    awx.main.dispatch task 68163837-51b6-4b4b-ac7d-569206898d86 starting awx.main.tasks.awx_k8s_reaper(*[])\n2020-07-04 02:44:32,472 DEBUG    awx.main.dispatch task f5352616-419a-42fb-a13f-0606d3764423 starting awx.main.tasks.cluster_node_heartbeat(*[])\n2020-07-04 02:44:32,598 DEBUG    awx.main.tasks Cluster node heartbeat task.\n2020-07-04 02:44:32,599 DEBUG    awx.main.tasks Last scheduler run was: 2020-07-04 02:44:02.434157+00:00\n2020-07-04 02:44:32,486 DEBUG    awx.main.dispatch task 6dbd2e92-0279-4557-b70a-edd2f40da337 starting awx.main.scheduler.tasks.run_task_manager(*[])\n2020-07-04 02:44:32,611 DEBUG    awx.main.scheduler Running Tower task manager.\n2020-07-04 02:44:32,618 DEBUG    awx.main.scheduler Starting Scheduler\n2020-07-04 02:44:32,643 DEBUG    awx.main.scheduler Finishing Scheduler\n2020-07-04 02:44:52,502 DEBUG    awx.main.dispatch task ab829c24-ce33-4f25-aece-2a5fab0eecea starting awx.main.scheduler.tasks.run_task_manager(*[])\n2020-07-04 02:44:52,504 DEBUG    awx.main.scheduler Running Tower task manager.\n2020-07-04 02:44:52,518 DEBUG    awx.main.scheduler Starting Scheduler\n2020-07-04 02:44:52,545 DEBUG    awx.main.scheduler Finishing Scheduler\nRESULT 2\n</code></pre><p></p> <p>Caso queira automatizar ainda mais a instala\u00e7\u00e3o, segue o link de um playbook em ansible, assim como outros projetos.</p>","tags":["ansible"]},{"location":"blog/2021/03/07/howtosre_-_convite_inicial/","title":"#HowToSRE - Convite inicial","text":"","tags":["ansible"]},{"location":"blog/2021/03/07/howtosre_-_convite_inicial/#howtosre-convite-inicial","title":"#HowToSRE - Convite inicial","text":"<p>E a\u00ed pessoal, tudo tranquilo? Sei que t\u00f4 sumido, mas foram por motivos de for\u00e7a maior! Mas o importante \u00e9 que t\u00f4 tentando voltar com mais frequ\u00eancia e agora quero compartilhar a minha nova rotina de estudos incluindo ferramentas, conceitos e pr\u00e1tica sempre que poss\u00edvel.</p> <p>Quero durante todo esse percurso, abordar assuntos que s\u00e3o da minha linha de interesse e assim conseguir repassar todo conte\u00fado adquirido durante todo o processo.</p> <p>Durante esse OpenTraining que carinhosamente chamei de:</p>","tags":["ansible"]},{"location":"blog/2021/03/07/howtosre_-_convite_inicial/#howtosre","title":"#HowToSRE:","text":"<p>Eu sei que n\u00f3s que estudamos com TI vemos muitos slides durante todo nosso percurso e se voc\u00ea assim como eu tem aquela pitadinha de TDAH, aulas muito mon\u00f3tonas podem acabar atrapalhando todo o processo. Mas infelizmente foi um mal necess\u00e1rio para que eu pudesse organizar meus pensamentos e fazer um direcionamento mais assertivo. MAS ai vem a parte boa, eu n\u00e3o vou apenas liberar os meus slides pra voc\u00eas! Quero mostrar os Slides para guiar o conte\u00fado, mas sempre acompanhado de uma demonstra\u00e7\u00e3o pr\u00e1tica para o ambiente do mundo real.</p>","tags":["ansible"]},{"location":"blog/2021/03/07/howtosre_-_convite_inicial/#a-minha-ideia-e-conseguir-passar-da-seguinte-forma","title":"A minha id\u00e9ia \u00e9 conseguir passar da seguinte forma:","text":"<ul> <li>Escrever aqui no blog a teoria e exibindo parte dos slides;</li> <li>Inserir tamb\u00e9m aqui a cada post o link do GitHub com os exercicios e solu\u00e7\u00f5es de cada \"aula\";</li> <li>Junto ao post colocar um v\u00eddeo do YouTube, explicando o os slides de forma falada e mostrando na pr\u00e1tica dos exercicios.</li> </ul> <p>Dessa forma acho que conseguirei atingir melhor o meu objetivo e voc\u00ea ir\u00e1 conseguir ter diferentes formas de acompanhar. Este n\u00e3o \u00e9 um processo fixo, ele poder\u00e1 ser alterado conforme as coisas forem acontecendo!</p>","tags":["ansible"]},{"location":"blog/2021/03/07/howtosre_-_convite_inicial/#quero-passar-por-assuntos-como","title":"Quero passar por assuntos como:","text":"<ul> <li>Configuration Management</li> <li>Versioning</li> <li>Containers</li> <li>Containers Orchestration</li> <li>CI/CD</li> <li>Observability</li> <li>Service Mesh</li> <li>Infra as code</li> </ul>","tags":["ansible"]},{"location":"blog/2021/03/07/howtosre_-_convite_inicial/#publico-alvo","title":"P\u00fablico-alvo","text":"<p>O principal p\u00fablico deste projeto, s\u00e3o SysAdmins que assim como eu, est\u00e3o interessados em realizar esta transi\u00e7\u00e3o de carreira. Saindo de uma vida mais repetitiva para uma mais automatizada e com desafios mais interessantes. Espera-se que as pessoas interessadas tenham j\u00e1 uma certa familiaridade com Linux para atividades corriqueiras do dia-a-dia, pois alguns conceitos ser\u00e3o abstraidos durante o processo.</p> <p>Espero por voc\u00eas nos proximos posts e boa sorte!</p>","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/","title":"#HowToSRE - Ansible-Parte01","text":"","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#howtosre-ansible-parte01","title":"#HowToSRE - Ansible-Parte01","text":"","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#pre-requisitos-e-orientacoes","title":"Pre-requisitos e Orienta\u00e7\u00f5es","text":"<p>Antes de iniciar \u00e9 importante entender como o ambiente de lab est\u00e1 sendo pensado. Utilizaremos a principio 3 VMs, sendo uma delas a control-node e outras duas os servidores onde testaremos de fato as funcionalidades do ansible.</p> <p>Segue abaixo um desenho de como se espera que esteja montado.</p> <p></p> <p>Quanto ao endere\u00e7amento IP, voc\u00ea pode se sentir livre para definir qual utilizar, desde que todas as VMs tenham acesso a internet para realizar o download e instala\u00e7\u00e3o de pacotes. Todas as VMs utilizadas nesse lab ser\u00e3o CentOS. Caso seja necess\u00e1rio adicione no \"/etc/hosts\" os endere\u00e7os dos hosts. </p>","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#understanding-ansible","title":"Understanding Ansible","text":"<p>Ansible \u00e9 uma ferramenta desenhada para SysAdmins que precisam automatizar provisionamento, configura\u00e7\u00e3o, deploy de aplica\u00e7\u00f5es e orquestra\u00e7\u00e3o. O projeto foi pensado para que fosse simples, otimizado e de f\u00e1cil entendimento. Hoje \u00e9 um projeto da comunidade OpenSource que \u00e9 patrocinado pela Red Hat, mas apesar disso \u00e9 totalmente compat\u00edvel com outras distribui\u00e7\u00f5es como Ubuntu/Debian e outros. </p>","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#why","title":"Why?","text":"<ul> <li> <p>Agentless</p> <p>N\u00e3o \u00e9 necess\u00e1rio a instala\u00e7\u00e3o de agentes de comunica\u00e7\u00e3o com o host que est\u00e1 executando o playbook. Sendo assim o controle de forma descentralizada, podendo ser executado a partir de qualquer m\u00e1quina que tenha a comunica\u00e7\u00e3o garantida com o servidor de destino. Ansible se conecta nos hosts gerenciados a partir de SSH ou WinRM no caso de Windows.</p> </li> <li> <p>Simple (yaml)</p> <p>A implementa\u00e7\u00e3o \u00e9 de f\u00e1cil compreens\u00e3o para humanos, isso significa que a leitura dos playbooks n\u00e3o iria gerar uma complica\u00e7\u00e3o, pois a linguagem \u00e9 descritiva. Geralmente \u00e9 utilizado no formato yaml, mas podendo ser utilizado tamb\u00e9m no formato json.</p> </li> <li> <p>Powerful</p> <p>A aplicabilidade do Ansible pode ser muito diferenciada, podendo ser utilizada em um workflow de automa\u00e7\u00e3o, automa\u00e7\u00e3o de rede, orquestrar o ciclo de vida de aplica\u00e7\u00f5es, gerenciar configura\u00e7\u00e3o e instala\u00e7\u00e3o de pacotes em servidores.</p> </li> </ul> <p></p>","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#ansible-configuration","title":"Ansible Configuration","text":"","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#installation","title":"Installation","text":"<p>O primeiro passo que precisamos dar \u00e9 a instala\u00e7\u00e3o do ansible no servidor de control-node.</p> <pre><code>yum install epel-release -y\nyum install ansible\nansible --version\n</code></pre> <p></p> <p>Dois dos arquivos mais importantes de toda configura\u00e7\u00e3o do ansible s\u00e3o \"ansible.cfg\" e \"inventory\", onde ficam salvos e armazenados todas as configura\u00e7\u00f5es e a lista de invent\u00e1rio de hosts, respectivamente. </p>","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#ansiblecfg","title":"ansible.cfg","text":"<p>Como pode ser visto no print anterior o diret\u00f3rio padr\u00e3o \u00e9 \"/etc/ansible/ansible.cfg\". Mas quando se administra v\u00e1rios tipos de ambientes, e/ou quando o control-node \u00e9 acessado por mais de um administrador as vezes \u00e9 necess\u00e1rio realizar altera\u00e7\u00f5es neste arquivo para que se encaixe na configura\u00e7\u00e3o para cada usu\u00e1rio. Neste caso \u00e9 indicado que cada usu\u00e1rio tenha um arquivo de configura\u00e7\u00e3o em sua home, ex: \"~/.ansible.cfg\". Observe no print abaixo que a localiza\u00e7\u00e3o do arquivo de configura\u00e7\u00e3o foi alterado.</p> <p></p> <p>Mas caso mesmo assim seja interessante que em cada projeto tenha configura\u00e7\u00f5es diferenciadas para atender demandas espec\u00edficas, \u00e9 possivel ainda que cada projeto tenha o seu proprio arquivo de configura\u00e7\u00e3o, bastando adicionar o arquivo na raiz do seu projeto, onde pretende executar os playbooks, conforme abaixo:  </p>","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#inventory","title":"inventory","text":"<p>O arquivo de invent\u00e1rio defaul do ansible tem o caminho \"/etc/ansible/hosts\", mas j\u00e1 que iremos realizar v\u00e1rios projetos contendo arquivos \"ansible.cfg\" diferentes, vamos definir um arquivo de configura\u00e7\u00e3o que ser\u00e1 utilizado por todos atrav\u00e9s da vari\u00e1vel \"inventory\", conforme exemplo abaixo:</p> <p></p> <p>Definiremos ent\u00e3o um grupo chamado linux, contendo o FQDN do primeiro host que iremos testar.</p> <p></p> <p>Os invent\u00e1rios podem ser de dois tipos est\u00e1tico, definido fixamente atrav\u00e9s do arquivo acima, e din\u00e2mico que fazendo a utiliza\u00e7\u00e3o de m\u00f3dulos, pode se conectar em clouds, service providers e virtualizadores e colher as informa\u00e7\u00f5es necess\u00e1rias.</p> <p>Quanto a forma de implementa\u00e7\u00e3o podem ser feitas de 2 formas INI and YAMl. Segue exemplo comparativo da mesma configura\u00e7\u00e3o. Mas para padroniza\u00e7\u00e3o, utilizaremos o formato INI.</p> <p>INI </p><pre><code>lb.example.com\n\n[web]\nserver1.example.com\nserver2.example.com\n\n[database]\nserver3.example.com\n</code></pre> YAML <pre><code>all:\n    hosts:\n        lb.example.com:\n    children:\n        web:\n            hosts:\n                server1.example.com:\n                server2.example.com:\n        database:\n            hosts:\n                server3.example.com:\n</code></pre> <p></p>","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#ansible-documentation","title":"Ansible Documentation","text":"","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#ad-hoc-commands","title":"ad-hoc Commands","text":"<p>Para iniciar configura\u00e7\u00f5es b\u00e1sicas com ansible, podemos utilizar a forma \"ad-hoc\", que se baseia em escrever as a\u00e7\u00f5es diretamente na linha de comando. O primeiro passo necess\u00e1rio \u00e9 a troca de chave entre os servidores. </p><pre><code># ssh-keygen\n# ssh-copy-id host1.example.com\nroot@host1.example.com's password: \n\nNumber of key(s) added: 1\n\nNow try logging into the machine, with:   \"ssh 'host1.example.com'\"\nand check to make sure that only the key(s) you wanted were added.\n</code></pre><p></p> <p>Como j\u00e1 definimos um host no invent\u00e1rio anterior, vamos para o diret\u00f3rio onde est\u00e1 o arquivo ansible.cfg e vamos testar a conectividade atrav\u00e9s do m\u00f3dulo ping. O exemplo abaixo, representa uma tentativa com conectividade ok!</p> <pre><code>[root@control-node labs]# ansible all -m ping\nhost1.example.com | SUCCESS =&gt; {\n    \"ansible_facts\": {\n        \"discovered_interpreter_python\": \"/usr/bin/python\"\n    }, \n    \"changed\": false, \n    \"ping\": \"pong\"\n}\n</code></pre> <p>Podemos testar o conteudo do arquivo /etc/motd, do servidor host1. Como n\u00e3o est\u00e1 exibindo nada, o arquivo est\u00e1 vazio.</p> <p></p> <p>Ao utilizarmos o m\u00f3dulo copy, e os argumentos content para definir o conte\u00fado e dest, para definir o arquivo de destino. O bin\u00e1rio do Ansible, j\u00e1 nos mostra que o arquivo foi alterado e assim ainda informa algumas informa\u00e7\u00f5es sobre o mesmo.</p> <p></p> <p>E como pode ser notado, agora o arquivo tem o conte\u00fado indicado. </p>","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#ansible-doc","title":"ansible-doc","text":"<p>Ok chegamos num ponto onde j\u00e1 temos o execut\u00e1vel instalado, trocamos a chave e testamos o funcionamento do ansible. Mas para que possamos implementar playbooks com a\u00e7\u00f5es e configura\u00e7\u00f5es necess\u00e1rias, \u00e9 importante que saibamos qual m\u00f3dulo utilizar, assim como quais argumentos devem ser passados.</p> <p>Para isso temos o bin\u00e1rio de documenta\u00e7\u00e3o, ansible-doc, onde podemos listar e consultar os m\u00f3dulos e argumentos existentes:</p> <p>Listar os m\u00f3dulos existentes/instalados. </p><pre><code>ansible-doc -l\n</code></pre><p></p> <p>Listar os m\u00f3dulos existentes/instalados, filtrando por a\u00e7\u00f5es que se espera encontrar. </p><pre><code>ansible-doc -l | grep -i copy\n</code></pre><p></p> <p>Listar os os argumentos presentes no m\u00f3dulo com breve explica\u00e7\u00e3o. </p><pre><code>ansible-doc -s copy\n</code></pre><p></p> <p>Listar documenta\u00e7\u00e3o completa sobre o m\u00f3dulo </p><pre><code>ansible-doc copy\n</code></pre><p></p> <p>DICA: Ao entrar na documenta\u00e7\u00e3o completa do m\u00f3dulo voc\u00ea pode pesquisar por \"EXAMPLES\", onde ser\u00e1 exibido v\u00e1rios exemplos de configura\u00e7\u00e3o e como utilizar de forma correta o m\u00f3dulo.</p> <p> </p>","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#ansible-playbook","title":"Ansible Playbook","text":"<p>Quando \u00e9 necess\u00e1rio realizar v\u00e1rias a\u00e7\u00f5es consecutivas, ou que pelo menos fique gravado/versionado as a\u00e7\u00f5es realizadas, n\u00e3o se torna interessante a utiliza\u00e7\u00e3o de m\u00f3dulos direto atrav\u00e9s da CLI. Para isso utilizaremos um arquivo chamado de playbook, onde indicar\u00e1 quais hosts executaremos as atividades e quais as tarefas a serem realizadas.</p> <p>Segue exemplo, baseado na atividade anterior. </p><pre><code># vim motd.yml\n---\n- name: Alterarando arquivos\n  hosts: host1.example.com\n  tasks:\n    - name: Alterando conteudo do /etc/motd\n      copy:\n        content: \"Bem Vindo\"\n        dest: /etc/motd\n</code></pre><p></p> <p>Uma forma simples de verificar se o playbook est\u00e1 escrito de forma correta \u00e9 utilizar a op\u00e7\u00e3o \"--syntax-check\", conforme exemplo abaixo. \u00c9 importante dizer que esta op\u00e7\u00e3o apenas verifica sintaxe do arquivo, considerando identa\u00e7\u00e3o e existencia do m\u00f3dulo. </p> <pre><code>ansible-playbook --syntax-check motd.yml\n</code></pre> <p>Para executar basta: </p><pre><code>ansible-playbook motd.yml\n</code></pre><p></p> <p>Uma outra forma de simular a execu\u00e7\u00e3o do playbook \u00e9 utilizando a op\u00e7\u00e3o \"-C\", onde ser\u00e1 verificado atrav\u00e9s de um *dry-run, checando as execu\u00e7\u00f5es mas n\u00e3o executando nenhuma de fato.</p> <p></p><pre><code>ansible-playbook -C motd.yml\n</code></pre> <p></p>","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#dica-do-sucesso","title":"Dica do Sucesso","text":"<p>Edite o arquivo \"/etc/vimrc\" e adicione ao final do mesmo para ficar com tabula\u00e7\u00e3o, espa\u00e7amento, a coluna, numera\u00e7\u00e3o e a coluna para ajudar voc\u00ea nos seus arquivos yaml.</p> <p></p><pre><code>autocmd FileType yaml setlocal ai ts=2 sw=2 et nu cuc\nautocmd FileType yaml colo desert\n</code></pre> <p></p>","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#exercicio","title":"Exercicio","text":"<p>Todo dia de repasse ser\u00e1 entregue um LAB baseado no conteudo repassado. Tente realizar o exercicio, caso tenha alguma dificuldade pode checar o arquivo no projeto do GitHUB, ou no link do v\u00eddeo.</p>","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#lab01","title":"LAB01","text":"<ul> <li>Montar um servidor WEB<ul> <li>Instalar o pacote httpd</li> <li>Habilitar o servi\u00e7o httpd em execu\u00e7\u00e3o e no boot</li> <li>Liberar porta de servi\u00e7o httpd</li> <li>Copiar o:<ul> <li>conteudo: \"CringerLabs Ansible !!\"</li> <li>para o destino: \"/var/www/html/index.html\"</li> </ul> </li> </ul> </li> </ul>","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#links-do-repasse","title":"Links do repasse","text":"<p>Divido entre labs e solutions, labs voc\u00ea ir\u00e1 encontrar os exercicios e os arquivos necess\u00e1rios, quando existirem. E no diret\u00f3rio solutions o exericio resolvido, conforme v\u00eddeo. Segue como est\u00e3o divido os diret\u00f3rios.</p> <p>GITHUB - #HowToSRE Ansible</p> <pre><code># cd how_to_sre-ansible\n$ tree .     \n.\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 labs\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lab01\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 EXERCICIO_lab01.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lab02\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 store.sql\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 lab03\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 block.txt\n\u2514\u2500\u2500 solutions\n    \u251c\u2500\u2500 ansible.cfg\n    \u251c\u2500\u2500 inventory\n    \u251c\u2500\u2500 lab01\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 add-user.yml\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 lab01.yml\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 meuprimeiro-playbook.yml\n    \u2514\u2500\u2500 lab02\n        \u2514\u2500\u2500 store.sql\n</code></pre> <p>SLIDES</p> <p> </p>","tags":["ansible"]},{"location":"blog/2021/03/22/howtosre_-_ansible-parte01/#agradecimentos","title":"Agradecimentos.","text":"<p>Obrigado ao Joel e ao Joaquim por revisarem o material.</p> <p>Joel-Linkedin - Joel-Blog </p> <p>Joaquim-Linkedin</p>","tags":["ansible"]},{"location":"blog/2021/03/30/howtosre_-_ansible-parte02/","title":"#HowToSRE - Ansible-Parte02","text":"","tags":["ansible"]},{"location":"blog/2021/03/30/howtosre_-_ansible-parte02/#howtosre-ansible-parte02","title":"#HowToSRE - Ansible-Parte02","text":"","tags":["ansible"]},{"location":"blog/2021/03/30/howtosre_-_ansible-parte02/#playbooks-advanced","title":"Playbooks Advanced","text":"<p>Como vimos no post anterior, criar um playbook n\u00e3o \u00e9 algo muito complicado. Tentaremos ent\u00e3o deixar um pouco mais divertido. Veja como \u00e9 interessante e as grandes possibilidades que o Ansible \u00e9 capaz de entregar!</p>","tags":["ansible"]},{"location":"blog/2021/03/30/howtosre_-_ansible-parte02/#ignoring-errors","title":"Ignoring Errors","text":"<p>Um op\u00e7\u00e3o bastante interessante \u00e9 a de ignorar erros durante a execu\u00e7\u00e3o de playbook, n\u00e3o \u00e9 recomendado, nem indicado que coloque esta op\u00e7\u00e3o em ambientes de produ\u00e7\u00e3o e/ou com criticidade alta. Mas normalmente a mesma \u00e9 utilizada para execu\u00e7\u00e3o quando se tem certeza que alguns hosts est\u00e3o indispon\u00edveis ou ir\u00e3o apresentar erros conhecidos. Pois como voc\u00ea j\u00e1 deve ter percebido a execu\u00e7\u00e3o completa do Playbook \u00e9 cancelada ao apresentar qualquer erro!</p> <p>A configura\u00e7\u00e3o correta ficaria ent\u00e3o:</p> <pre><code>$ vim motd.yml\n---\n- name: Alterarando arquivos\n  hosts: host1.example.com\n  gather_facts: no\n  ignore_erros: yes\n  ...\n</code></pre> <p>Tambem \u00e9 possivel inserir esta op\u00e7\u00e3o dentro de uma task espec\u00edfica caso n\u00e3o queria que fique dispon\u00edel para o playbook inteiro, ex:</p> <p></p><pre><code>$ vim install_httpd.yml\n...\n  tasks:\n    - name: Install httpd package\n      yum:\n        name: httpd\n        state: present\n      ignore_erros: yes\n...\n</code></pre> <p></p>","tags":["ansible"]},{"location":"blog/2021/03/30/howtosre_-_ansible-parte02/#vars-variaveis","title":"Vars (Vari\u00e1veis)","text":"<p>Provavelmente a op\u00e7\u00e3o mais utilizada no ansible seja a de consumir vari\u00e1veis definidas no playbook. Mas existem algumas formas de se fazer isso.</p>","tags":["ansible"]},{"location":"blog/2021/03/30/howtosre_-_ansible-parte02/#arquivo-de-inventario","title":"Arquivo de Invent\u00e1rio","text":"<p>Definindo para grupos ou vari\u00e1veis, conforme exemplo abaixo: </p><pre><code>$ cat inventory\nhost2.example.com\n\n[linux]\nhost1.example.com\n\n[linux:vars]\nuser=karlipe\n</code></pre> <p></p>","tags":["ansible"]},{"location":"blog/2021/03/30/howtosre_-_ansible-parte02/#arquivos-externos","title":"Arquivos externos","text":"<p>Podendo este ser divididos entre 2 formas comuns. A primeira \u00e9 definindo variaveis direcionadas a cada host em especifico. Dentro da pasta do seu projeto, deve criar um diret\u00f3rio \"host_vars\" e em seguida criar um arquivo com o nome do host definido no invent\u00e1rio contendo as informa\u00e7\u00f5es necess\u00e1rias, como no exemplo abaixo:</p> <pre><code>$ cat host_vars/host1.example.com\npackage: http\n$ cat host_vars/host2.example.com\npackage: mariadb\n</code></pre> <p>A segunda forma seria ao inv\u00e9s de definir vari\u00e1veis utilizando arquivos individuais, \u00e9 utilizando o nome de grupos definidos no invent\u00e1rio. Dentro da pasta do seu projeto, deve criar um diret\u00f3rio \"group_vars\" e em seguida criar um arquivo com o nome do grupo que queira referenciar, sendo o mesmo definido no invent\u00e1rio contendo as informa\u00e7\u00f5es necess\u00e1rias, como no exemplo abaixo: </p><pre><code>$ cat group_vars/linux\npackage: vim\n</code></pre> <p></p>","tags":["ansible"]},{"location":"blog/2021/03/30/howtosre_-_ansible-parte02/#dentro-do-playbook","title":"Dentro do Playbook","text":"<p>J\u00e1 quando se usa Playbooks pequenos e com poucas tasks, o jeito mais f\u00e1cil de gerenciar \u00e9 inserindo as informa\u00e7\u00f5es de variaveis dentro do proprio playbook. As boas pr\u00e1ticas indicam que o melhor formato \u00e9 declara-las no inicio do arquivo:</p> <p>{% raw %} </p><pre><code>---\n- name: Install commom packages\n  hosts: host1.example.com\n  vars:\n    package:\n      - vim\n      - wget\n      - git\n  tasks:\n\n    - name: Install {{ package }} packages\n      yum:\n        name: \"{{ package }}\"\n        state: present\n  ...\n</code></pre><p></p> <p>Mas tamb\u00e9m \u00e9 possivel que voc\u00ea encontre Playbooks pela internet, onde s\u00e3o declaradas apenas quando forem ser utilizadas, atrav\u00e9s de loops:</p> <p>{% raw %} </p><pre><code>$ vim install_basic_packages.yml\n...\n  tasks:\n    - name: Install basic packages\n      yum:\n        name: \"{{ item }}\"\n        state: present\n      loop:\n        - net-tools\n        - tcpdump\n        - bind-utils\n...\n</code></pre> {% endraw %} <p></p>","tags":["ansible"]},{"location":"blog/2021/03/30/howtosre_-_ansible-parte02/#handlers","title":"Handlers","text":"<p>Handlers s\u00e3o tasks que respondem a gatilhos acionados por outras tasks. A Task manda uma notifica\u00e7\u00e3o quando ela \u00e9 \u201calterada\u201d que por sua vez executa a a\u00e7\u00e3o definda. Boas pr\u00e1ticas indicam que ao definir handlers no Playbook, o mesmo fique identado igualmente a coluna da op\u00e7\u00e3o tasks, conforme exemplo abaixo:</p> <pre><code>$ vim install_ftp.yml\n...\n  tasks:\n    - name: Install vsftpd\n      yum:\n        name: vsftpd\n        state: present\n      notify: Restart vsftpd\n\n  handlers:\n    - name: Restart vsftpd\n      service:\n        name: vsftpd\n        state: restarted\n...\n</code></pre> <p>\u00c9 importante salientar que os handlers tem que ter exatamente o mesmo nome escrito no gatilho(notify), para que ele seja reconhecido e por consequ\u00eancia, executado. </p>","tags":["ansible"]},{"location":"blog/2021/03/30/howtosre_-_ansible-parte02/#controlling-handlers-in-failure","title":"Controlling Handlers in Failure","text":"<p>Caso exista alguma necessidade especial, \u00e9 possivel for\u00e7ar a execu\u00e7\u00e3o de handlers, mesmo quando a task falhe na execu\u00e7\u00e3o de algum host. Para for\u00e7ar \u00e9 necess\u00e1rio apenas executar junto na linha do Playbook:</p> <pre><code>$ ansible-playbook playbook-handler.yml --force-handlers\n</code></pre> <p>Tambem \u00e9 possivel definir dentro do Playbook: </p><pre><code>$ vim motd.yml\n---\n- name: Alterarando arquivos\n  hosts: host1.example.com\n  force_handlers: True\n  ...\n</code></pre><p></p> <p>Caso voc\u00ea queira generalizar para todos os playbooks dos seus projetos \u00e9 possivel adicionalo ao arquivo de configura\u00e7\u00e3o \"ansible.cfg\".</p> <p> </p>","tags":["ansible"]},{"location":"blog/2021/03/30/howtosre_-_ansible-parte02/#flushing-handlers","title":"Flushing Handlers","text":"<p>Como voc\u00eas sabem todos os handlers s\u00e3o executados somente na finaliza\u00e7\u00e3o do playbook. Caso voc\u00ea tenha muitas tasks e alguma dessas tasks tenha depend\u00eancia e voc\u00ea precise que seja executada de forma imediata, existe uma op\u00e7\u00e3o que ir\u00e1 te salvar, um m\u00f3dulo chamado meta. </p><pre><code>$ vim motd.yml\n---\n- name: Forcing handlers execution\n  meta: flush_handlers\n  ...\n</code></pre> <p></p>","tags":["ansible"]},{"location":"blog/2021/03/30/howtosre_-_ansible-parte02/#exercicio","title":"Exercicio","text":"<p>Todo post de repasse ser\u00e1 entregue um ou mais LABs baseados no conteudo repassado. Tente realizar o exercicio, caso tenha alguma dificuldade pode checar o arquivo no projeto do GitHUB, ou no link do v\u00eddeo.</p>","tags":["ansible"]},{"location":"blog/2021/03/30/howtosre_-_ansible-parte02/#lab02","title":"LAB02","text":"<ul> <li>Utilizando as melhores pr\u00e1ticas monte um Banco de Dados no host2.<ul> <li>Instalar a seguir pacotes (utilizando vari\u00e1veis)<ul> <li>mariadb-server</li> <li>MySQL-python</li> </ul> </li> <li>Habilitar servi\u00e7o para iniciar imediatamente e permanecer ao boot</li> <li>Liberar porta do servi\u00e7o mysql</li> <li>Criar database \u201cstore\u201d</li> <li>Copiar conteudo para base de dados (store.sql)</li> <li>Checar se dados est\u00e3o corretos</li> </ul> </li> </ul>","tags":["ansible"]},{"location":"blog/2021/03/30/howtosre_-_ansible-parte02/#lab03","title":"LAB03","text":"<ul> <li>Criar um template de instala\u00e7\u00e3o base para todos os hosts.<ul> <li>Definir hostname igual a invent\u00e1rio</li> <li>Instalar Repositorio EPEL (pacote epel-release)</li> <li>Instalar pacotes bases:<ul> <li>(tcpdump, net-tools, bind-utils, vim, git, open-vm-tools, htop, screen)</li> </ul> </li> <li>Atualizar servidores</li> <li>Copiar arquivo motd personalizado para /etc/motd</li> <li>Personalizar bash <ul> <li>Adicionar o conteudo do arquivo block.txt, ao final do arquivo /etc/bashrc</li> </ul> </li> </ul> </li> </ul>","tags":["ansible"]},{"location":"blog/2021/03/30/howtosre_-_ansible-parte02/#links-do-repasse","title":"Links do repasse","text":"<p>Divido entre labs e solutions, labs voc\u00ea ir\u00e1 encontrar os exercicios e os arquivos necess\u00e1rios, quando existirem. E no diret\u00f3rio solutions o exericio resolvido, conforme v\u00eddeo. Segue como est\u00e3o divido os diret\u00f3rios.</p> <p>GITHUB - #HowToSRE Ansible</p> <pre><code>$ cd how_to_sre-ansible\n$ tree .\n.\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 labs\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lab01\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 EXERCICIO_lab01.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lab02\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 store.sql\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 lab03\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 block.txt\n\u2514\u2500\u2500 solutions\n    \u251c\u2500\u2500 ansible.cfg\n    \u251c\u2500\u2500 inventory\n    \u251c\u2500\u2500 lab01\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 add-user.yml\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 lab01.yml\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 meuprimeiro-playbook.yml\n    \u2514\u2500\u2500 lab02\n        \u2514\u2500\u2500 store.sql\n</code></pre> <p>SLIDES</p> <p> </p>","tags":["ansible"]},{"location":"blog/2021/03/30/howtosre_-_ansible-parte02/#agradecimentos","title":"Agradecimentos.","text":"<p>Obrigado ao Joel por revisar o material e ao Joaquim por ser minha cobaia nesse repasse. &lt;3</p> <p>Joel-Linkedin - Joel-Blog </p> <p>Joaquim-Linkedin</p>","tags":["ansible"]},{"location":"blog/2021/04/06/howtosre_-_ansible-parte03/","title":"#HowToSRE - Ansible-Parte03","text":"","tags":["ansible"]},{"location":"blog/2021/04/06/howtosre_-_ansible-parte03/#howtosre-ansible-parte03","title":"#HowToSRE - Ansible-Parte03","text":"<p>E ae galera beleza? Nesse post iremos falar um pouco sobre o que s\u00e3o Facts e como podemos utilizar as informa\u00e7\u00f5es contidas neles. Falaremos tamb\u00e9m sobre Ansible Vault, qual sua utilidade, exemplos e como utilizar na pr\u00e1tica, al\u00e9m de claro ter como praticar com alguns LABs.</p> <p>Aproveitem!! \ud83e\udd19\ud83e\udd19</p>","tags":["ansible"]},{"location":"blog/2021/04/06/howtosre_-_ansible-parte03/#facts","title":"Facts","text":"","tags":["ansible"]},{"location":"blog/2021/04/06/howtosre_-_ansible-parte03/#como-obter-informacoes","title":"Como obter informa\u00e7\u00f5es","text":"<p>Facts ou Fatos s\u00e3o informa\u00e7\u00f5es do servidor destino que podem ser obtidas utilizando ansible que retornam utilizando vari\u00e1veis nativas do ansible. Exemplo:</p> <pre><code>$ ansible host1.example.com -m setup \nhost1.example.com | SUCCESS =&gt; {\n    \"ansible_facts\": {\n        \"ansible_all_ipv4_addresses\": [\n            \"172.31.2.51\"\n        ], \n        \"ansible_all_ipv6_addresses\": [\n            \"fe80::5cd8:2eaf:3adf:c23a\"\n        ], \n        \"ansible_apparmor\": {\n            \"status\": \"disabled\"\n        }, \n        \"ansible_architecture\": \"x86_64\", \n        \"ansible_bios_date\": \"12/12/2018\", \n        \"ansible_bios_version\": \"6.00\", \n        ....\n        ....\n</code></pre> <p>Existe a possibilidade de ainda utilizando o modo ad-hoc mas filtrar algumas informa\u00e7\u00f5es caso julgue importante. Exemplo: </p><pre><code>$ ansible host2.example.com -m setup -a \"filter=ansible_kernel\"\nhost2.example.com | SUCCESS =&gt; {\n    \"ansible_facts\": {\n        \"ansible_kernel\": \"3.10.0-1160.21.1.el7.x86_64\", \n        \"discovered_interpreter_python\": \"/usr/bin/python\"\n    }, \n    \"changed\": false\n}\n</code></pre> <p></p>","tags":["ansible"]},{"location":"blog/2021/04/06/howtosre_-_ansible-parte03/#desabilitando-gathering-facts","title":"Desabilitando Gathering Facts","text":"<p>Caso voc\u00ea n\u00e3o tenha notado nos v\u00eddeos dos repasses anteriores, sempre ao in\u00edcio de cada execu\u00e7\u00e3o dos playbooks, este fun\u00e7\u00e3o \u00e9 realizada a fim de colher informa\u00e7\u00f5es que talvez sejam necess\u00e1rias para a execu\u00e7\u00e3o correta do Playbook.</p> <p></p> <p>Uma boa pr\u00e1tica importante, caso voc\u00ea n\u00e3o a necessidade de usar essas informa\u00e7\u00f5es e/ou caso voc\u00ea tenha um grande grupo de m\u00e1quinas para executar, o que pode causar uma certa lentid\u00e3o no ambiente, o indicado \u00e9 desabilitar esta op\u00e7\u00e3o dentro do playbook, da seguinte forma:</p> <pre><code>$ vim motd.yml\n---\n- name: Alterarando arquivos\n  hosts: host1.example.com\n  gather_facts: no\n  ...\n</code></pre> <p></p> <p></p>","tags":["ansible"]},{"location":"blog/2021/04/06/howtosre_-_ansible-parte03/#custom-facts","title":"Custom Facts","text":"<p>Administradores podem criar Facts Personalizados para seus hosts gerenciados, estas informa\u00e7\u00f5es ficar\u00e3o gravads localmente em cada host. Por padr\u00e3o os Facts personalizados s\u00e3o salvos em arquivos \".fact\" e salvos no diret\u00f3rio \"/etc/ansible/facts.d/\". Estes arquivs\u00e3o s\u00e3o escritos no formato INI ou tamb\u00e9m podem ser escritos no formato json. Segue abaixo um exemplo de um arquivo escrito no formato INI. Onde assim como no invent\u00e1rio o grupo \u00e9 definido pelo nome entre colchetes \"[...]\" e logo abaixo a vari\u00e1vel com a defini\u00e7\u00e3o de valor.</p> <pre><code>$ cat /etc/ansible/fact.d/cringerlabs.fact\n[environment]\ndeploy = prod\n\n[general]\npackage = nginx\n</code></pre> <p>E assim como os Fatos nativos, estes tamb\u00e9m podem ser consumidos pelo bin\u00e1rio de forma ad-hoc, filtrando pelo par\u00e2metro \"ansible_local\". </p><pre><code>$ ansible host2.example.com -m setup -a \"filter=ansible_local\"\nhost2.example.com | SUCCESS =&gt; {\n    \"ansible_facts\": {\n        \"ansible_local\": {\n            \"cringerlabs\": {\n                \"environment\": {\n                    \"deploy\": \"prod\"\n                }\n                \"general\": {\n                    \"package\": \"nginx\"\n                }\n            }\n        }\n        \"discovered_interpreter_python\": \"/usr/bin/python\"\n    }, \n    \"changed\": false\n}\n</code></pre> <p></p>","tags":["ansible"]},{"location":"blog/2021/04/06/howtosre_-_ansible-parte03/#utilizando-facts-no-playbook","title":"Utilizando Facts no Playbook","text":"<p>Um exemplo b\u00e1sico de utiliza\u00e7\u00e3o de Facts no playbook \u00e9 conforme o exemplo abaixo. Utilizando a vari\u00e1vel \"ansible_fqdn podemos obter o fqdn de todos os hosts envolvidos. {% raw %} </p><pre><code>---\n- name: Utilizando Facts no Playbook01\n  hosts: all\n  tasks:\n  - name: Exibindo FQDN\n    debug:\n      msg: &gt;\n        The package to install on {{ ansible_fqdn }}\n</code></pre><p></p> <p></p> <p>Outra forma igualmente elegante \u00e9 utilizar custom facts, com base no exemplo citado mais acima veja como \u00e9 simples de instalar um pacote. {% raw %} </p><pre><code>---\n- name: Utilizando Facts no Playbook02\n  hosts: all\n  tasks: \n  - name: Instalando Pacotes\n    yum:\n      name: \"{{ ansible_facts.ansible_local.cringerlabs.general.package }}\"\n      state: latest\n</code></pre><p></p> <p>Como visto no exemplo, \u00e9 necess\u00e1rio informar toda a cadeia de grupos at\u00e9 a vari\u00e1vei que ser\u00e1 utilizada na task.</p> <p></p>","tags":["ansible"]},{"location":"blog/2021/04/06/howtosre_-_ansible-parte03/#ansible-vault","title":"Ansible Vault","text":"<p>Ansible Vault veio para dar um al\u00edvio aos Administradores que necessitam passar informa\u00e7\u00f5es sens\u00edveis como senhas, api keys, chaves de acesso dentre outros, em seus playbooks e n\u00e3o podem utilizar essa informa\u00e7\u00f5es em texto plano. Ao instalar o pacote do ansible j\u00e1 \u00e9 poss\u00edvel utiliza-lo para encriptar e decriptar qualquer arquivo que poder\u00e1 ser utilizado pelo ansible, incluindo: invent\u00e1rio, arquivos de vari\u00e1veis, playbooks.</p>","tags":["ansible"]},{"location":"blog/2021/04/06/howtosre_-_ansible-parte03/#manipucao-de-arquivos-encriptados","title":"Manipu\u00e7\u00e3o de arquivos encriptados","text":"<p>Segue abaixo uma exemplifica\u00e7\u00e3o de como fazer:</p> <p>Cria\u00e7\u00e3o de arquivo </p><pre><code>$ ansible-vault create arquivo.yml\nNew Vault password: \nConfirm New Vault password:\n</code></pre><p></p> <p>Edi\u00e7\u00e3o de arquivo encriptado </p><pre><code>$ ansible-vault edit arquivo.yml\nVault password: \n</code></pre><p></p> <p>Visualiza\u00e7\u00e3o de arquivo encriptado </p><pre><code>$ ansible-vault view arquivo.yml\nVault password: \n</code></pre><p></p> <p>Encriptar arquivo ja existente </p><pre><code>$ ansible-vault encrypt arquivo.yml \nNew Vault password: \nConfirm New Vault password:\n</code></pre><p></p> <p>Decriptar arquivo ja existente </p><pre><code>$ ansible-vault decrypt arquivo.yml --output=arquivo-decriptado.yml\nVault password: \n\n$ ls\narquivo.yml\narquivo-decriptado.yml\n</code></pre><p></p> <p>Recria\u00e7\u00e3o de chave vault em arquivo encriptado </p><pre><code>$ ansible-vault create arquivo.yml\nVault password: #senha_atual\nNew Vault password: #senha_nova\nConfirm New Vault password: #senha_nova\n</code></pre><p></p> <p>Caso voc\u00ea n\u00e3o queria ter que digitar a senha \u00e9 possivel utilizar um arquivo contendo a senha para automatiza\u00e7\u00e3o de scripts.</p> <p>Conteudo do arquivo </p><pre><code>$ cat senha-vault.txt\npassword\n</code></pre><p></p> <p>Visualiza\u00e7\u00e3o de conte\u00fado utilizando arquivo de senha </p><pre><code>$ ansible-vault view --vault-password-file=senha-vault.txt arquivo.yml\n</code></pre><p></p> <p>Edi\u00e7\u00e3o de conte\u00fado utilizando arquivo de senha </p><pre><code>$ ansible-vault edit --vault-password-file=senha-vault.txt arquivo.yml\n</code></pre> <p></p>","tags":["ansible"]},{"location":"blog/2021/04/06/howtosre_-_ansible-parte03/#utilizando-ansible-vault-no-playbook","title":"Utilizando Ansible Vault no Playbook","text":"<p>Supondo que o arquivo de variaveis do grupo esteja criptografado \"/group_vars/linux\", e voc\u00ea queira instalar um pacote \"httpd\" definido no mesmo. Ao tentar executar o Playbook voc\u00ea ir\u00e1 se depar\u00e1 com a seguinte tela.</p> <p></p> <p>No erro informa que n\u00e3o foi encontrado \"vault secrets\" para decriptar o Playbook. Em outras palavras \u00e9 necess\u00e1rio que voc\u00ea passe o secret para o Playbook e h\u00e1 duas formas simples de fazer isso.</p> <p>A primeira que \u00e9 solicitar que o Playbook pergunte a senha de forma, conforme abaixo: </p><pre><code>$ ansible-playbook --vault-id @prompt package-vault.yml\nVault password:\n\nPLAY [cada pacote no seu servidor] **********************************************************************\n\nTASK [Gathering Facts] **********************************************************************************\nok: [host1.example.com]\n\nTASK [instando o pacote httpd] **************************************************************************\nchanged: [host1.example.com]\n\nPLAY RECAP **********************************************************************************************\nhost1.example.com          : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n</code></pre><p></p> <p>A segunda forma \u00e9 utilizar arquivo de senha: </p><pre><code>$ ansible-playbook --vault-password-file=senha-vault.txt package-vault.yml\n\nPLAY [cada pacote no seu servidor] **********************************************************************\n\nTASK [Gathering Facts] **********************************************************************************\nok: [host1.example.com]\n\nTASK [instando o pacote httpd] **************************************************************************\nchanged: [host1.example.com]\n\nPLAY RECAP **********************************************************************************************\nhost1.example.com          : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n</code></pre> <p></p>","tags":["ansible"]},{"location":"blog/2021/04/06/howtosre_-_ansible-parte03/#dica-do-sucesso","title":"Dica do sucesso!","text":"<p>Para acelerar processos de envolvendo criptografia, \u00e9 aconselhado instalar o pacote python-cryptography. Por padr\u00e3o o ansible utiliza fun\u00e7\u00f5es do pacote \"python-crypto\", mas caso pretenda utilizar muitos arquivos encriptados o pacote python-criptography prover bibliotecas python que melhoram o desempenho.</p> <p></p><pre><code>$ yum install python-cryptography\n</code></pre> <p></p>","tags":["ansible"]},{"location":"blog/2021/04/06/howtosre_-_ansible-parte03/#exercicios","title":"Exercicios","text":"<p>Todo post de repasse ser\u00e1 entregue um ou mais LABs baseados no conteudo repassado. Tente realizar o exercicio, caso tenha alguma dificuldade pode checar o arquivo no projeto do GitHUB, ou no link do v\u00eddeo.</p>","tags":["ansible"]},{"location":"blog/2021/04/06/howtosre_-_ansible-parte03/#lab04","title":"LAB04","text":"<ul> <li>Criar um playbook direcionado ao servidor host1</li> <li> <p>Adicionar um custom fact no servidor</p> <ul> <li>Crie um arquivo chamado \"cringerlabs.fact\" e adione os fatos abaixo</li> <li>Group: webserver<ul> <li>Variable: role </li> <li>Value: webserver</li> </ul> </li> <li>Group: general<ul> <li>Variable: port</li> <li>Value: 80</li> <li>Variable: package</li> <li>Value: nginx</li> </ul> </li> <li>Leve este arquivo ao servidor no diret\u00f3rio correto.</li> </ul> </li> <li> <p>Criar um segundo playbook para consumir os facts criados no playbook anterior gerando a frase abaixo:     A fun\u00e7\u00e3o do servidor host1 \u00e9 'role',      o pacote que instala o servi\u00e7o principal \u00e9 o 'package',     que \u00e9 executado na porta 'port'/tcp.\"</p> </li> </ul>","tags":["ansible"]},{"location":"blog/2021/04/06/howtosre_-_ansible-parte03/#lab05","title":"LAB05","text":"<ul> <li>Criar Playbook direcionado ao host1.</li> <li>Desinstalar o package httpd<ul> <li>Exiba o MacAddress com a seguinte frase</li> <li>\u201cO MacAddress do servidor host1 \u00e9 'fact_contendo_macaddress'.\u201d</li> <li>Instale o package criado no Fact</li> <li>Libere o servi\u00e7o criado no Fact</li> <li>Inicie o servi\u00e7o criado no Fact</li> <li>Use handlers</li> <li>Force a inicializa\u00e7\u00e3o do handler imediatamente</li> <li>Check a vers\u00e3o do nginx instalado</li> <li>Exiba a vers\u00e3o no nginx</li> <li>Crie um arquivo de vari\u00e1vel para o host1 utilizando o Vault </li> <li>Variavel: \u201cCringerLabs SECRETS!!!\u201d</li> <li>Utilize o valor dessa vari\u00e1vel como conte\u00fado para o arquivo index.html com destino \u201c/usr/share/nginx/html/\u201d</li> <li>Check se o arquivo foi substituido</li> </ul> </li> </ul>","tags":["ansible"]},{"location":"blog/2021/04/06/howtosre_-_ansible-parte03/#links-do-repasse","title":"Links do repasse","text":"<p>Divido entre labs e solutions, labs voc\u00ea ir\u00e1 encontrar os exercicios e os arquivos necess\u00e1rios, quando existirem. E no diret\u00f3rio solutions o exericio resolvido, conforme v\u00eddeo. Segue como est\u00e3o divido os diret\u00f3rios.</p> <p>GITHUB - #HowToSRE Ansible</p> <pre><code>$ cd how_to_sre-ansible\n$ tree .\n.\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 labs\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lab01\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 README.md\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lab02\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 store.sql\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 lab03\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 block.txt\n\u2514\u2500\u2500 solutions\n    \u251c\u2500\u2500 ansible.cfg\n    \u251c\u2500\u2500 inventory\n    \u251c\u2500\u2500 lab01\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 add-user.yml\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 lab01.yml\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 meuprimeiro-playbook.yml\n    \u2514\u2500\u2500 lab02\n        \u2514\u2500\u2500 store.sql\n</code></pre> <p>SLIDES</p> <p> </p>","tags":["ansible"]},{"location":"blog/2021/04/06/howtosre_-_ansible-parte03/#agradecimentos","title":"Agradecimentos.","text":"<p>Obrigado ao Joel por revisar o material e ao Joaquim por ser minha cobaia nesse repasse. &lt;3</p> <p>Joel-Linkedin - Joel-Blog </p> <p>Joaquim-Linkedin</p>","tags":["ansible"]},{"location":"blog/2025/09/10/melange_criando_seus_pr%C3%B3prios_pacotes_apk/","title":"MELANGE: Criando seus pr\u00f3prios pacotes APK","text":"","tags":["distroless","melange","supply chain"]},{"location":"blog/2025/09/10/melange_criando_seus_pr%C3%B3prios_pacotes_apk/#melange-criando-seus-proprios-pacotes-apk","title":"MELANGE: Criando seus pr\u00f3prios pacotes APK","text":"<p>O Melange \u00e9 uma ferramenta de build de pacotes APK (formato utilizado pelo Alpine Linux). Se voc\u00ea j\u00e1 trabalhou com containers baseados em Alpine, sabe como a leveza e a simplicidade s\u00e3o pontos fortes \u2014 e como, ao mesmo tempo, pode ser um desafio adaptar pacotes para atender necessidades espec\u00edficas. \u00c9 a\u00ed que o Melange entra: ele permite que voc\u00ea crie e mantenha seus pr\u00f3prios pacotes, de forma reprodut\u00edvel, automatiz\u00e1vel e multi-arquitetura. Isso tudo de forma declarativa em um \u00fanico arquivo YAML.</p>","tags":["distroless","melange","supply chain"]},{"location":"blog/2025/09/10/melange_criando_seus_pr%C3%B3prios_pacotes_apk/#porque-usar","title":"Porque Usar?","text":"<p>Para times de DevOps e SREs, isso abre v\u00e1rias possibilidades pr\u00e1ticas, como:</p> <ul> <li>Empacotar sua pr\u00f3pria aplica\u00e7\u00e3o: por exemplo, transformar um projeto Python em um pacote APK instal\u00e1vel diretamente no seu ambiente.</li> <li>Criar um pacote daquela ferramenta que n\u00e3o existe pacote para Alpine, apenas aquele bom e velho <code>.tar.gz</code> e voc\u00ea tem que fazer a configura\u00e7\u00e3o e instala\u00e7\u00e3o manual ap\u00f3s isso.</li> <li>Personalizar depend\u00eancias padr\u00e3o: imagine criar um pacote do .NET SDK que j\u00e1 traga os plugins necess\u00e1rios para o seu fluxo de trabalho em pipelines (evitando instala\u00e7\u00e3o recorrente durante o processo).</li> <li>Adicionar integra\u00e7\u00f5es internas: como embutir o certificado raiz da sua empresa em um pacote, garantindo que todos os containers usem o mesmo ponto de confian\u00e7a sem gambiarras manuais.</li> <li>Como padronizar e distribuir software de forma segura, audit\u00e1vel e adaptada ao meu contexto.</li> </ul> <p>A P\u00e1gina de documenta\u00e7\u00e3o da Chainguard \u00e9 bem completa e pode ajudar bastante a entender, utilizando alguns exemplos pr\u00e1ticos. Inclusive nem \u00e9 necess\u00e1rio instalar nada, pois a partir do proprio container do melange (via docker run) \u00e9 poss\u00edvel criar esses pacotes.</p>","tags":["distroless","melange","supply chain"]},{"location":"blog/2025/09/10/melange_criando_seus_pr%C3%B3prios_pacotes_apk/#como-utilizar","title":"Como Utilizar","text":"","tags":["distroless","melange","supply chain"]},{"location":"blog/2025/09/10/melange_criando_seus_pr%C3%B3prios_pacotes_apk/#pre-requisito","title":"Pr\u00e9-requisito","text":"<ul> <li> <p>Para Usu\u00e1rios Linux:voc\u00ea ir\u00e1 precisar executar o comando abaixo pra adicionar headers no seu Kernel. Caso voc\u00ea tenha instalado \"Docker Desktop\", no caso de macOS, este passo n\u00e3o ser\u00e1 necess\u00e1rio</p> Adding QEMU headers<pre><code>docker run --rm --privileged multiarch/qemu-user-static --reset -p yes\n</code></pre> </li> <li> <p>Download da imagem: Outro passo de boa pr\u00e1tica mas n\u00e3o 100% necess\u00e1rio, porque indiretamente a imagem ser\u00e1 baixada quando voc\u00ea executar de fato o comando, \u00e9 baixar a ultima imagem dispon\u00edvel na sua m\u00e1quina para que voc\u00ea consiga realizar alguns passos caso queira realizar de forma offline.</p> Downloading Melange image<pre><code>docker pull cgr.dev/chainguard/melange:latest\n</code></pre> </li> <li> <p>Gerar Certificado Pr\u00f3prio: Uma boa pr\u00e1tica \u00e9, antes de come\u00e7ar a cria\u00e7\u00e3o dos seus pacotes, voc\u00ea criar uma pair de chaves rsa utilizando a mesma imagem</p> Generate Certificate<pre><code>$ docker run --rm -v \"${PWD}\":/work cgr.dev/chainguard/melange keygen\n\n2025/09/10 20:17:12 INFO generating keypair with a 4096 bit prime, please wait...\n2025/09/10 20:17:13 INFO wrote private key to melange.rsa\n2025/09/10 20:17:13 INFO wrote public key to melange.rsa.pub\n</code></pre> </li> </ul>","tags":["distroless","melange","supply chain"]},{"location":"blog/2025/09/10/melange_criando_seus_pr%C3%B3prios_pacotes_apk/#cenario-hipotetico","title":"Cen\u00e1rio Hipot\u00e9tico","text":"<p>Controlar a vers\u00e3o de SDK e Plugins!</p> <p>Imagine que sua empresa possui um pipeline parada cada API, e que nesse pipeline \u00e9 instalado o SDK e alguns Plugins para execu\u00e7\u00e3o de alguns steps de verifica\u00e7\u00e3o b\u00e1sica de c\u00f3digo, al\u00e9m do build da aplica\u00e7\u00e3o. ATUALMENTE, na maioria dos pipelines sempre est\u00e1 sendo instalado a latest e em outros esta 'mockada' uma vers\u00e3o antiga, por\u00e9m voc\u00ea tem que manter de forma controlada a vers\u00e3o utilizada de cada SDK, assim como a vers\u00e3o de cada Plugin para garantir que todos estejam no mesmo passo, checando as mesmas coisas com o mesmo grau de compatibilidade. Tudo isso pensando em dupla Arquitetura: X64 e ARM.</p> <p>Vers\u00f5es utilizadas para exemplo:</p> <ul> <li> DotNet SDK 8 <ul> <li> dotnet-sonarscanner (vers\u00e3o latest) (sem problemas de compatibilidade com o sonarqube)</li> <li> dotnet-coverage (vers\u00e3o 17.13.1) (problemas de compatibilidade com vers\u00e3o do SDK)</li> <li> Swashbuckle.AspNetCore.Cli (vers\u00e3o 7.2.0)</li> </ul> </li> </ul>","tags":["distroless","melange","supply chain"]},{"location":"blog/2025/09/10/melange_criando_seus_pr%C3%B3prios_pacotes_apk/#exemplo-pratico","title":"Exemplo Pr\u00e1tico","text":"","tags":["distroless","melange","supply chain"]},{"location":"blog/2025/09/10/melange_criando_seus_pr%C3%B3prios_pacotes_apk/#criar-arquivo-de-configuracao","title":"Criar Arquivo de Configura\u00e7\u00e3o","text":"<p>Segue uma exemplifica\u00e7\u00e3o de um arquivo .yaml que atende todas as necessidades citadas no cen\u00e1rio passado.</p> dotnet8-builder.yaml <pre><code>package:\n  name: dotnet8-builder\n  version: 8.0.413\n  description: \".NET SDK 8.0 para Alpine Linux\"\n  copyright:\n    - license: MIT\n  dependencies:\n    runtime:\n      - ca-certificates-bundle\n      - icu\n      - icu-libs\n      - libgcc\n      - libintl\n      - libgdiplus\n      - libssl3\n      - libstdc++\n\nenvironment:\n  contents:\n    repositories:\n      - https://dl-cdn.alpinelinux.org/alpine/edge/main\n      - https://dl-cdn.alpinelinux.org/alpine/edge/community\n    packages:\n      - bash\n      - curl\n      - icu\n      - icu-libs\n      - libgcc\n      - libstdc++\n      - tar\n\npipeline:\n  - runs: |\n      mkdir -p /home/build/aspnet/\n\n  - assertions:\n      required-steps: 1\n    pipeline:\n      - uses: fetch\n        if: ${{build.arch}} == 'aarch64'\n        with:\n          uri: https://builds.dotnet.microsoft.com/dotnet/Sdk/${{package.version}}/dotnet-sdk-${{package.version}}-linux-musl-arm64.tar.gz\n          directory: /home/build/aspnet/\n          strip-components: 0\n          expected-sha512: 1380ddfdc715b831e459ee48636d8a2a89aa6c34857e4a428a63effcab40f88cf6c72a076f9b210c496c39bde24dd17c1db9f7b110e724174e39fb748f8e4b50\n\n      - uses: fetch\n        if: ${{build.arch}} == 'x86_64'\n        with:\n          uri: https://builds.dotnet.microsoft.com/dotnet/Sdk/${{package.version}}/dotnet-sdk-${{package.version}}-linux-musl-x64.tar.gz\n          directory: /home/build/aspnet/\n          strip-components: 0\n          expected-sha512: 1490e8061d8665373506db3cbbf8a30b7b7d99884de02d4f6e7ace5852e16a4f9e061a668abec1cc0af21e4d5a3fa1eee804b60d249f7d568363bb9ee1abdab9\n\n  - runs: |          \n      # Create destination dir \n      mkdir -p \"${{targets.destdir}}/usr/share/dotnet\"\n      mv /home/build/aspnet/* \"${{targets.destdir}}/usr/share/dotnet\"\n\n      # Create symbolic link\n      mkdir -p \"${{targets.destdir}}/usr/bin\"\n      ln -s /usr/share/dotnet/dotnet \"${{targets.destdir}}/usr/bin/dotnet\"\n\n      # Install paths (dotnet tools)\n      export DOTNET_ROOT=\"${{targets.destdir}}/usr/share/dotnet\"\n      export PATH=\"$PATH:${{targets.destdir}}/usr/share/dotnet\"\n\n      # Verify dotnet Installation\n      dotnet --info\n\n      ###################### Tools \n      # Install SonarScanner\n      dotnet tool install dotnet-sonarscanner \\\n        --tool-path ${{targets.destdir}}/usr/share/dotnet \n\n      # Install Coverage\n      dotnet tool install dotnet-coverage --version 17.13.1 \\\n        --tool-path ${{targets.destdir}}/usr/share/dotnet \n\n      # Install Swashbuckle\n      dotnet tool install Swashbuckle.AspNetCore.Cli --version 7.2.0 \\\n        --tool-path ${{targets.destdir}}/usr/share/dotnet \n\n      # remove useless packages\n      find \"${{targets.destdir}}/usr/share/dotnet/.store\" -type d -path \"*/any/ubuntu*\" -exec rm -rf {} +\n\n      if [ \"${{ build.arch }}\" = \"aarch64\" ]; then\n        find \"${{targets.destdir}}/usr/share/dotnet/.store\" -type d -path \"*/alpine/x64*\" -exec rm -rf {} +\n      elif [ \"${{ build.arch }}\" = \"x86_64\" ]; then\n        find \"${{targets.destdir}}/usr/share/dotnet/.store\" -type d -path \"*/alpine/arm64*\" -exec rm -rf {} +\n      else\n        echo \"Arquitetura diferente de aarch64/x86_64\"\n        exit 1\n      fi\n\n      # Check tool List Configuration\n      dotnet tool list --tool-path ${{targets.destdir}}/usr/share/dotnet\n</code></pre>","tags":["distroless","melange","supply chain"]},{"location":"blog/2025/09/10/melange_criando_seus_pr%C3%B3prios_pacotes_apk/#explicando-as-opcoes-utilizadas","title":"Explicando as op\u00e7\u00f5es utilizadas:","text":"<ul> <li> <p>Sections</p> <ul> <li>name, version, description, s\u00e3o auto explicativos.</li> <li>copyright: \u00e9 possivel especificar qual licen\u00e7a \u00e9 a utilizada pelo pacote que voc\u00ea ta criando, para que seja reproduz\u00edvel ou n\u00e3o com base em qual \u00e9 utilizada.     <pre><code>..\n    copyright:\n        - license: MIT\n..\n</code></pre></li> <li>dependencies: Aqui deve ser referenciado a lista de pacotes 'pre-requisitos' para a instala\u00e7\u00e3o do seu pacote no ambiente que voc\u00ea esta criando.     <pre><code>..\n    dependencies:\n        runtime:\n            - gcompat\n            ..\n</code></pre></li> <li>environment: a lista de pacotes necess\u00e1rios para criar o SEU pacote, durante o 'pipeline' que ser\u00e1 executado. E de qual reposit\u00f3rio eles ser\u00e3o encontrados.     <pre><code>..\n    environment:\n        contents:\n            repositories:\n                - https://dl-cdn.alpinelinux.org/alpine/edge/main\n                - https://dl-cdn.alpinelinux.org/alpine/edge/community\n            packages:\n                - bash\n                ..\n</code></pre></li> <li>pipeline: \u00e9 onde fica a lista de passos que ser\u00e3o executados para construir o seu pacote.     <pre><code>..\n    pipeline:\n        - runs: |\n..\n</code></pre><ul> <li>runs: quando o 'runs' \u00e9 informado, \u00e9 literalmente uma sequencia de comandos bash a serem executados, no caso a cria\u00e7\u00e3o de um diret\u00f3rio.     <pre><code>..\n    - runs: |\n        mkdir -p /home/build/aspnet/\n..\n</code></pre></li> <li>assertions: quando voc\u00ea tem condi\u00e7\u00f5es a serem 'confirmadas', no caso \u00e9 requirido que pelo menos 1 dos steps seja verdadeiro. Na sequ\u00eancia referenciamos um 'sub-pipeline' e usamos a fun\u00e7\u00e3o 'fetch' com uma condi\u00e7\u00e3o para cada ambiente, referenciando para qual link, qual diret\u00f3rio ser\u00e1 realizado, se ser\u00e1 descompactado(strip-components) e fazendo a checagem com o 'sha512' fornecido pela Microsoft.     <pre><code>..\n    - assertions:\n        required-steps: 1\n      pipeline:\n        - uses: fetch\n          if: ${{build.arch}} == 'aarch64'\n          with:\n            uri: https://builds.dotnet.microsoft.com/dotnet/Sdk/${{package.version}}/dotnet-sdk-${{package.version}}-linux-musl-arm64.tar.gz\n            directory: /home/build/aspnet/\n            strip-components: 0\n            expected-sha512: 1380ddfdc715b831e459ee48636d8a2a89aa6c34857e4a428a63effcab40f88cf6c72a076f9b210c496c39bde24dd17c1db9f7b110e724174e39fb748f8e4b50\n\n      - uses: fetch\n        if: ${{build.arch}} == 'x86_64'\n        .....\n..\n</code></pre></li> <li>runs: quando o 'runs' \u00e9 informado, \u00e9 literalmente uma sequencia de comandos bash a serem executados, no caso a cria\u00e7\u00e3o de um diret\u00f3rio.     <pre><code>..\n    - runs: |          \n        # Create destination dir \n        ..\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Parameters</p> <ul> <li> <p>${{build.arch}}</p> <p>Qual arquitetura esta sendo referenciada durante a execu\u00e7\u00e3o.</p> </li> <li> <p>${{package.version}}</p> <p>\u00c9 referente pelo par\u00e2metro 'version', descrita no come\u00e7o do arquivo.</p> </li> <li> <p>${{targets.destdir}}</p> <p>Literalmente o destino de onde ser\u00e1 instalado, o padr\u00e3o de referenciado ser\u00e1 './', caso isso n\u00e3o seja especificado poder\u00e1 acontecer problemas de onde ele ser\u00e1 executado caso a instala\u00e7\u00e3o seja feito de forma manual em um diret\u00f3rio n\u00e3o esperado.</p> </li> </ul> </li> </ul>","tags":["distroless","melange","supply chain"]},{"location":"blog/2025/09/10/melange_criando_seus_pr%C3%B3prios_pacotes_apk/#execucao-e-arquivos-gerados","title":"Execu\u00e7\u00e3o e Arquivos Gerados","text":"<p>Para buildar o pacote, bastaria executar o comando abaixo. Nele podemos ver que est\u00e1 sendo referenciado quais arquiteturas ser\u00e3o utilizadas <code>--arch amd64,aarch64</code> e a chave privada gerada previamente <code>--signing-key melange.rsa</code>.</p> Creating Package dotnet8-builder<pre><code>docker run --privileged --rm -v \"${PWD}\":/work \\\n  cgr.dev/chainguard/melange build dotnet8-builder.yaml \\\n  --arch amd64,aarch64 \\\n  --signing-key melange.rsa\n</code></pre> <p>Abaixo podemos ver os arquivos de pair-key e os arquivos gerados pela execu\u00e7\u00e3o do build. Seguindo padr\u00e3o de organiza\u00e7\u00e3o dos reposit\u00f3rios do Alpine. Note que ele \u00e9 separado por arquitetura (as mesmas que referenciamos), e que ele usa os par\u00e2metros <code>name</code> e <code>version</code> referenciados no arquivo. Caso criassemos v\u00e1rios pacotes em sequ\u00eancia, automaticamente ele adicionaria as informa\u00e7\u00f5es pertinentes no <code>APKINDEX.tar.gz</code> e alimentaria automaticamente </p> Directory Tree<pre><code>.\n\u251c\u2500\u2500 melange.rsa\n\u251c\u2500\u2500 melange.rsa.pub\n\u251c\u2500\u2500 packages\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 aarch64\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 APKINDEX.tar.gz\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 dotnet8-builder-8.0.413-r0.apk\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 x86_64\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 APKINDEX.tar.gz\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 dotnet8-builder-8.0.413-r0.apk\n\u2514\u2500\u2500 dotnet8-builder.yaml\n</code></pre> <p>Segue tambem a saida dos logs dessa execu\u00e7\u00e3o para que voc\u00ea possa analisar e ver como seria a forma da sa\u00edda do comando executado.</p> Generated Logs <pre><code>2025/09/10 20:45:01 INFO melange v0.30.6+dirty is building: arch=aarch64\n2025/09/10 20:45:01 INFO melange v0.30.6+dirty is building: arch=x86_64\n2025/09/10 20:45:01 INFO populating workspace /tmp/melange-workspace-2663022281 from . arch=aarch64\n2025/09/10 20:45:01 INFO populating workspace /tmp/melange-workspace-284474888 from . arch=x86_64\n2025/09/10 20:45:08 INFO image configuration: arch=x86_64\n2025/09/10 20:45:08 INFO   contents: arch=x86_64\n2025/09/10 20:45:08 INFO     build repositories: [] arch=x86_64\n2025/09/10 20:45:08 INFO     runtime repositories: [] arch=x86_64\n2025/09/10 20:45:08 INFO     repositories: [https://dl-cdn.alpinelinux.org/alpine/edge/community https://dl-cdn.alpinelinux.org/alpine/edge/main] arch=x86_64\n2025/09/10 20:45:08 INFO     keyring:      [] arch=x86_64\n2025/09/10 20:45:08 INFO     packages:     [acl-libs=2.3.2-r1 bash=5.3.3-r1 brotli-libs=1.1.0-r2 busybox-binsh=1.37.0-r23 busybox=1.37.0-r23 c-ares=1.34.5-r0 ca-certificates-bundle=20250619-r0 curl=8.16.0-r0 icu-data-en=76.1-r1 icu-libs=76.1-r1 icu=76.1-r1 libcrypto3=3.5.2-r0 libcurl=8.16.0-r0 libgcc=15.2.0-r0 libidn2=2.3.8-r0 libncursesw=6.5_p20250816-r0 libpsl=0.21.5-r3 libssl3=3.5.2-r0 libstdc++=15.2.0-r0 libunistring=1.3-r0 musl=1.2.5-r20 ncurses-terminfo-base=6.5_p20250816-r0 nghttp2-libs=1.66.0-r0 nghttp3=1.9.0-r0 pcre2=10.46-r0 readline=8.3.1-r0 tar=1.35-r4 wget=1.25.0-r2 zlib=1.3.1-r2 zstd-libs=1.5.7-r2] arch=x86_64\n2025/09/10 20:45:08 INFO   accounts: arch=x86_64\n2025/09/10 20:45:08 INFO     runas:   arch=x86_64\n2025/09/10 20:45:08 INFO     users: arch=x86_64\n2025/09/10 20:45:08 INFO       - uid=1000(build) gid=1000 arch=x86_64\n2025/09/10 20:45:08 INFO     groups: arch=x86_64\n2025/09/10 20:45:08 INFO       - gid=1000(build) members=[build] arch=x86_64\n2025/09/10 20:45:08 INFO auth configured for: [] arch=x86_64\n2025/09/10 20:45:08 INFO image configuration: arch=aarch64\n2025/09/10 20:45:08 INFO   contents: arch=aarch64\n2025/09/10 20:45:08 INFO     build repositories: [] arch=aarch64\n2025/09/10 20:45:08 INFO     runtime repositories: [] arch=aarch64\n2025/09/10 20:45:08 INFO     repositories: [https://dl-cdn.alpinelinux.org/alpine/edge/community https://dl-cdn.alpinelinux.org/alpine/edge/main] arch=aarch64\n2025/09/10 20:45:08 INFO     keyring:      [] arch=aarch64\n2025/09/10 20:45:08 INFO     packages:     [acl-libs=2.3.2-r1 bash=5.3.3-r1 brotli-libs=1.1.0-r2 busybox-binsh=1.37.0-r23 busybox=1.37.0-r23 c-ares=1.34.5-r0 ca-certificates-bundle=20250619-r0 curl=8.16.0-r0 icu-data-en=76.1-r1 icu-libs=76.1-r1 icu=76.1-r1 libcrypto3=3.5.2-r0 libcurl=8.16.0-r0 libgcc=15.2.0-r0 libidn2=2.3.8-r0 libncursesw=6.5_p20250816-r0 libpsl=0.21.5-r3 libssl3=3.5.2-r0 libstdc++=15.2.0-r0 libunistring=1.3-r0 musl=1.2.5-r20 ncurses-terminfo-base=6.5_p20250816-r0 nghttp2-libs=1.66.0-r0 nghttp3=1.9.0-r0 pcre2=10.46-r0 readline=8.3.1-r0 tar=1.35-r4 wget=1.25.0-r2 zlib=1.3.1-r2 zstd-libs=1.5.7-r2] arch=aarch64\n2025/09/10 20:45:08 INFO   accounts: arch=aarch64\n2025/09/10 20:45:08 INFO     runas:   arch=aarch64\n2025/09/10 20:45:08 INFO     users: arch=aarch64\n2025/09/10 20:45:08 INFO       - uid=1000(build) gid=1000 arch=aarch64\n2025/09/10 20:45:08 INFO     groups: arch=aarch64\n2025/09/10 20:45:08 INFO       - gid=1000(build) members=[build] arch=aarch64\n2025/09/10 20:45:08 INFO auth configured for: [] arch=aarch64\n2025/09/10 20:45:10 INFO installing musl (1.2.5-r20) arch=x86_64\n2025/09/10 20:45:10 INFO installing acl-libs (2.3.2-r1) arch=x86_64\n2025/09/10 20:45:10 INFO installing busybox (1.37.0-r23) arch=x86_64\n2025/09/10 20:45:10 INFO installing busybox-binsh (1.37.0-r23) arch=x86_64\n2025/09/10 20:45:10 INFO installing ncurses-terminfo-base (6.5_p20250816-r0) arch=x86_64\n2025/09/10 20:45:10 INFO installing libncursesw (6.5_p20250816-r0) arch=x86_64\n2025/09/10 20:45:10 INFO installing readline (8.3.1-r0) arch=x86_64\n2025/09/10 20:45:10 INFO installing bash (5.3.3-r1) arch=x86_64\n2025/09/10 20:45:10 INFO installing brotli-libs (1.1.0-r2) arch=x86_64\n2025/09/10 20:45:10 INFO installing c-ares (1.34.5-r0) arch=x86_64\n2025/09/10 20:45:10 INFO installing ca-certificates-bundle (20250619-r0) arch=x86_64\n2025/09/10 20:45:10 INFO installing musl (1.2.5-r20) arch=aarch64\n2025/09/10 20:45:10 INFO installing acl-libs (2.3.2-r1) arch=aarch64\n2025/09/10 20:45:10 INFO installing busybox (1.37.0-r23) arch=aarch64\n2025/09/10 20:45:10 INFO installing busybox-binsh (1.37.0-r23) arch=aarch64\n2025/09/10 20:45:10 INFO installing ncurses-terminfo-base (6.5_p20250816-r0) arch=aarch64\n2025/09/10 20:45:10 INFO installing libncursesw (6.5_p20250816-r0) arch=aarch64\n2025/09/10 20:45:10 INFO installing readline (8.3.1-r0) arch=aarch64\n2025/09/10 20:45:10 INFO installing bash (5.3.3-r1) arch=aarch64\n2025/09/10 20:45:10 INFO installing brotli-libs (1.1.0-r2) arch=aarch64\n2025/09/10 20:45:10 INFO installing c-ares (1.34.5-r0) arch=aarch64\n2025/09/10 20:45:10 INFO installing ca-certificates-bundle (20250619-r0) arch=aarch64\n2025/09/10 20:45:10 INFO installing libcrypto3 (3.5.2-r0) arch=x86_64\n2025/09/10 20:45:10 INFO installing libunistring (1.3-r0) arch=x86_64\n2025/09/10 20:45:10 INFO installing libidn2 (2.3.8-r0) arch=x86_64\n2025/09/10 20:45:10 INFO installing nghttp2-libs (1.66.0-r0) arch=x86_64\n2025/09/10 20:45:10 INFO installing nghttp3 (1.9.0-r0) arch=x86_64\n2025/09/10 20:45:10 INFO installing libpsl (0.21.5-r3) arch=x86_64\n2025/09/10 20:45:10 INFO installing libssl3 (3.5.2-r0) arch=x86_64\n2025/09/10 20:45:10 INFO installing zlib (1.3.1-r2) arch=x86_64\n2025/09/10 20:45:10 INFO installing zstd-libs (1.5.7-r2) arch=x86_64\n2025/09/10 20:45:10 INFO installing libcurl (8.16.0-r0) arch=x86_64\n2025/09/10 20:45:10 INFO installing libcrypto3 (3.5.2-r0) arch=aarch64\n2025/09/10 20:45:10 INFO installing libunistring (1.3-r0) arch=aarch64\n2025/09/10 20:45:10 INFO installing libidn2 (2.3.8-r0) arch=aarch64\n2025/09/10 20:45:10 INFO installing nghttp2-libs (1.66.0-r0) arch=aarch64\n2025/09/10 20:45:10 INFO installing nghttp3 (1.9.0-r0) arch=aarch64\n2025/09/10 20:45:10 INFO installing libpsl (0.21.5-r3) arch=aarch64\n2025/09/10 20:45:10 INFO installing libssl3 (3.5.2-r0) arch=aarch64\n2025/09/10 20:45:10 INFO installing zlib (1.3.1-r2) arch=aarch64\n2025/09/10 20:45:10 INFO installing zstd-libs (1.5.7-r2) arch=aarch64\n2025/09/10 20:45:10 INFO installing libcurl (8.16.0-r0) arch=aarch64\n2025/09/10 20:45:10 INFO installing curl (8.16.0-r0) arch=aarch64\n2025/09/10 20:45:10 INFO installing curl (8.16.0-r0) arch=x86_64\n2025/09/10 20:45:10 INFO installing icu-data-en (76.1-r1) arch=x86_64\n2025/09/10 20:45:10 INFO installing libgcc (15.2.0-r0) arch=x86_64\n2025/09/10 20:45:10 INFO installing libstdc++ (15.2.0-r0) arch=x86_64\n2025/09/10 20:45:11 INFO installing icu-data-en (76.1-r1) arch=aarch64\n2025/09/10 20:45:11 INFO installing libgcc (15.2.0-r0) arch=aarch64\n2025/09/10 20:45:11 INFO installing libstdc++ (15.2.0-r0) arch=aarch64\n2025/09/10 20:45:11 INFO installing icu-libs (76.1-r1) arch=aarch64\n2025/09/10 20:45:11 INFO installing icu (76.1-r1) arch=aarch64\n2025/09/10 20:45:11 INFO installing pcre2 (10.46-r0) arch=aarch64\n2025/09/10 20:45:11 INFO installing tar (1.35-r4) arch=aarch64\n2025/09/10 20:45:11 INFO installing wget (1.25.0-r2) arch=aarch64\n2025/09/10 20:45:11 WARN /etc/os-release is missing arch=aarch64\n2025/09/10 20:45:11 INFO installing icu-libs (76.1-r1) arch=x86_64\n2025/09/10 20:45:11 INFO installing icu (76.1-r1) arch=x86_64\n2025/09/10 20:45:11 INFO installing pcre2 (10.46-r0) arch=x86_64\n2025/09/10 20:45:11 INFO installing tar (1.35-r4) arch=x86_64\n2025/09/10 20:45:11 INFO installing wget (1.25.0-r2) arch=x86_64\n2025/09/10 20:45:11 WARN /etc/os-release is missing arch=x86_64\n2025/09/10 20:45:11 INFO running step \"fetch\" arch=x86_64\n2025/09/10 20:45:11 WARN --2025-09-10 20:45:11--  https://builds.dotnet.microsoft.com/dotnet/Sdk/8.0.413/dotnet-sdk-8.0.413-linux-musl-x64.tar.gz arch=x86_64\n2025/09/10 20:45:11 INFO running step \"fetch\" arch=aarch64\n2025/09/10 20:45:11 WARN --2025-09-10 20:45:11--  https://builds.dotnet.microsoft.com/dotnet/Sdk/8.0.413/dotnet-sdk-8.0.413-linux-musl-arm64.tar.gz arch=aarch64\n2025/09/10 20:45:11 WARN Resolving builds.dotnet.microsoft.com (builds.dotnet.microsoft.com)... 23.53.35.241, 23.53.35.228, 2600:1408:ec00:15::17d7:cc, ... arch=x86_64\n2025/09/10 20:45:11 WARN Connecting to builds.dotnet.microsoft.com (builds.dotnet.microsoft.com)|23.53.35.241|:443... connected. arch=x86_64\n2025/09/10 20:45:11 WARN Resolving builds.dotnet.microsoft.com (builds.dotnet.microsoft.com)... 23.53.35.71, 23.53.35.68, 2600:1408:ec00:15::17d7:cc, ... arch=aarch64\n2025/09/10 20:45:11 WARN Connecting to builds.dotnet.microsoft.com (builds.dotnet.microsoft.com)|23.53.35.71|:443... connected. arch=aarch64\n2025/09/10 20:45:12 WARN HTTP request sent, awaiting response... 200 OK arch=x86_64\n2025/09/10 20:45:12 WARN Length: 216249095 (206M) [application/octet-stream] arch=x86_64\n2025/09/10 20:45:12 WARN Saving to: 'dotnet-sdk-8.0.413-linux-musl-x64.tar.gz' arch=x86_64\n2025/09/10 20:45:12 WARN arch=x86_64\n2025/09/10 20:45:12 WARN      0K .......... .......... .......... .......... ..........  0% 1.11M 3m6s arch=x86_64\n2025/09/10 20:45:12 WARN HTTP request sent, awaiting response... 200 OK arch=aarch64\n2025/09/10 20:45:12 WARN Length: 211421059 (202M) [application/octet-stream] arch=aarch64\n2025/09/10 20:45:12 WARN Saving to: 'dotnet-sdk-8.0.413-linux-musl-arm64.tar.gz' arch=aarch64\n2025/09/10 20:45:12 WARN arch=aarch64\n2025/09/10 20:45:12 WARN     50K .......... .......... .......... .......... ..........  0%  218K 9m37s arch=x86_64\n2025/09/10 20:45:12 WARN    100K .......... .......... .......... .......... ..........  0%  978K 7m36s arch=x86_64\n.....\n2025/09/10 20:49:55 WARN 210850K .......... .......... .......... .......... .......... 99% 7.80M 0s arch=x86_64\n2025/09/10 20:49:55 WARN 210900K .......... .......... .......... .......... .......... 99% 21.9M 0s arch=x86_64\n2025/09/10 20:49:55 WARN 210950K .......... .......... .......... .......... .......... 99% 12.4M 0s arch=x86_64\n2025/09/10 20:49:55 WARN 211000K .......... .......... .......... .......... .......... 99% 15.6M 0s arch=x86_64\n2025/09/10 20:49:55 WARN 211050K .......... .......... .......... .......... .......... 99% 19.1M 0s arch=x86_64\n2025/09/10 20:49:55 WARN 211100K .......... .......... .......... .......... .......... 99% 6.31M 0s arch=x86_64\n2025/09/10 20:49:55 WARN 211150K .......... .......... ..........                      100%  199M=57s arch=x86_64\n2025/09/10 20:49:55 WARN arch=x86_64\n2025/09/10 20:49:55 WARN 2025-09-10 20:49:55 (3.62 MB/s) - 'dotnet-sdk-8.0.413-linux-musl-x64.tar.gz' saved [216249095/216249095] arch=x86_64\n2025/09/10 20:49:55 WARN arch=x86_64\n2025/09/10 20:49:55 INFO fetch: Expected sha512: 1490e8061d8665373506db3cbbf8a30b7b7d99884de02d4f6e7ace5852e16a4f9e061a668abec1cc0af21e4d5a3fa1eee804b60d249f7d568363bb9ee1abdab9 arch=x86_64\n2025/09/10 20:50:02 INFO .NET SDK: arch=x86_64\n2025/09/10 20:50:02 INFO  Version:           8.0.413 arch=x86_64\n2025/09/10 20:50:02 INFO  Commit:            a31823e79b arch=x86_64\n2025/09/10 20:50:02 INFO  Workload version:  8.0.400-manifests.6322a93a arch=x86_64\n2025/09/10 20:50:02 INFO  MSBuild version:   17.11.38+901dc04e4 arch=x86_64\n2025/09/10 20:50:02 INFO arch=x86_64\n2025/09/10 20:50:02 INFO Runtime Environment: arch=x86_64\n2025/09/10 20:50:02 INFO  OS Name:     Linux arch=x86_64\n2025/09/10 20:50:02 INFO  OS Version:   arch=x86_64\n2025/09/10 20:50:02 INFO  OS Platform: Linux arch=x86_64\n2025/09/10 20:50:02 INFO  RID:         linux-musl-x64 arch=x86_64\n2025/09/10 20:50:02 INFO  Base Path:   /home/build/melange-out/dotnet8-builder/usr/share/dotnet/sdk/8.0.413/ arch=x86_64\n2025/09/10 20:50:02 INFO arch=x86_64\n2025/09/10 20:50:02 INFO .NET workloads installed: arch=x86_64\n2025/09/10 20:50:02 INFO Configured to use loose manifests when installing new manifests. arch=x86_64\n2025/09/10 20:50:02 INFO There are no installed workloads to display. arch=x86_64\n2025/09/10 20:50:02 INFO arch=x86_64\n2025/09/10 20:50:02 INFO Host: arch=x86_64\n2025/09/10 20:50:02 INFO   Version:      8.0.19 arch=x86_64\n2025/09/10 20:50:02 INFO   Architecture: x64 arch=x86_64\n2025/09/10 20:50:02 INFO   Commit:       fce8ed90dc arch=x86_64\n2025/09/10 20:50:02 INFO arch=x86_64\n2025/09/10 20:50:02 INFO .NET SDKs installed: arch=x86_64\n2025/09/10 20:50:02 INFO   8.0.413 [/home/build/melange-out/dotnet8-builder/usr/share/dotnet/sdk] arch=x86_64\n2025/09/10 20:50:02 INFO arch=x86_64\n2025/09/10 20:50:02 INFO .NET runtimes installed: arch=x86_64\n2025/09/10 20:50:02 INFO   Microsoft.AspNetCore.App 8.0.19 [/home/build/melange-out/dotnet8-builder/usr/share/dotnet/shared/Microsoft.AspNetCore.App] arch=x86_64\n2025/09/10 20:50:02 INFO   Microsoft.NETCore.App 8.0.19 [/home/build/melange-out/dotnet8-builder/usr/share/dotnet/shared/Microsoft.NETCore.App] arch=x86_64\n2025/09/10 20:50:02 INFO arch=x86_64\n2025/09/10 20:50:02 INFO Other architectures found: arch=x86_64\n2025/09/10 20:50:02 INFO   None arch=x86_64\n2025/09/10 20:50:02 INFO arch=x86_64\n2025/09/10 20:50:02 INFO Environment variables: arch=x86_64\n2025/09/10 20:50:02 INFO   DOTNET_ROOT       [/home/build/melange-out/dotnet8-builder/usr/share/dotnet] arch=x86_64\n2025/09/10 20:50:02 INFO arch=x86_64\n2025/09/10 20:50:02 INFO global.json file: arch=x86_64\n2025/09/10 20:50:02 INFO   Not found arch=x86_64\n2025/09/10 20:50:02 INFO arch=x86_64\n2025/09/10 20:50:02 INFO Learn more: arch=x86_64\n2025/09/10 20:50:02 INFO   https://aka.ms/dotnet/info arch=x86_64\n2025/09/10 20:50:02 INFO arch=x86_64\n2025/09/10 20:50:02 INFO Download .NET: arch=x86_64\n2025/09/10 20:50:02 INFO   https://aka.ms/dotnet/download arch=x86_64\n2025/09/10 20:50:02 INFO arch=x86_64\narch=x86_640:50:02 INFO Welcome to .NET 8.0!\narch=x86_640:50:02 INFO ---------------------\n2025/09/10 20:50:02 INFO SDK Version: 8.0.413 arch=x86_64\n2025/09/10 20:50:02 INFO arch=x86_64\narch=x86_640:50:02 INFO Telemetry\narch=x86_640:50:02 INFO ---------\n2025/09/10 20:50:02 INFO The .NET tools collect usage data in order to help us improve your experience. It is collected by Microsoft and shared with the comm arch=x86_64an opt-out of telemetry by setting the DOTNET_CLI_TELEMETRY_OPTOUT environment variable to '1' or 'true' using your favorite shell.\narch=x86_640:50:02 INFO \n2025/09/10 20:50:02 INFO Read more about .NET CLI Tools telemetry: https://aka.ms/dotnet-cli-telemetry arch=x86_64\n2025/09/10 20:50:02 INFO arch=x86_64\narch=x86_640:50:02 INFO ----------------\narch=x86_640:50:02 INFO Installed an ASP.NET Core HTTPS development certificate.\n2025/09/10 20:50:02 INFO To trust the certificate, view the instructions: https://aka.ms/dotnet-https-linux arch=x86_64\n2025/09/10 20:50:02 INFO arch=x86_64\narch=x86_640:50:02 INFO ----------------\narch=x86_640:50:02 INFO Write your first app: https://aka.ms/dotnet-hello-world\narch=x86_640:50:02 INFO Find out what's new: https://aka.ms/dotnet-whats-new\narch=x86_640:50:02 INFO Explore documentation: https://aka.ms/dotnet-docs\narch=x86_640:50:02 INFO Report issues and find source on GitHub: https://github.com/dotnet/core\narch=x86_640:50:02 INFO Use 'dotnet --help' to see available commands or visit: https://aka.ms/dotnet-cli\n2025/09/10 20:50:02 INFO -------------------------------------------------------------------------------------- arch=x86_64\narch=x86_640:50:05 INFO You can invoke the tool using the following command: dotnet-sonarscanner\n2025/09/10 20:50:05 INFO Tool 'dotnet-sonarscanner' (version '10.3.0') was successfully installed. arch=x86_64\narch=x86_640:50:09 INFO You can invoke the tool using the following command: dotnet-coverage\n2025/09/10 20:50:09 INFO Tool 'dotnet-coverage' (version '17.14.2') was successfully installed. arch=x86_64\narch=x86_640:50:10 INFO You can invoke the tool using the following command: swagger\n2025/09/10 20:50:10 INFO Tool 'swashbuckle.aspnetcore.cli' (version '7.2.0') was successfully installed. arch=x86_64\n2025/09/10 20:50:11 INFO Package Id                      Version      Commands            arch=x86_64\n2025/09/10 20:50:11 INFO ---------------------------------------------------------------- arch=x86_64\n2025/09/10 20:50:11 INFO dotnet-coverage                 17.14.2      dotnet-coverage     arch=x86_64\n2025/09/10 20:50:11 INFO dotnet-sonarscanner             10.3.0       dotnet-sonarscanner arch=x86_64\n2025/09/10 20:50:11 INFO swashbuckle.aspnetcore.cli      7.2.0        swagger             arch=x86_64\n2025/09/10 20:50:11 INFO retrieving workspace from builder:  arch=x86_64\n2025/09/10 20:50:11 WARN cat: can't open '/etc/os-release': No such file or directory arch=x86_64\n2025/09/10 20:50:11 WARN failed to retrieve release data from runner, OS section will be unknown: failed to read os-release: exit status 1 arch=x86_64\n2025/09/10 20:50:11 INFO retrieved and wrote post-build workspace to: /tmp/melange-workspace-671198310 arch=x86_64\n2025/09/10 20:50:11 INFO running package linters for dotnet8-builder arch=x86_64\n2025/09/10 20:50:11 INFO linting apk: dotnet8-builder arch=x86_64\n2025/09/10 20:50:11 WARN linter \"lddcheck\" failed on package \"dotnet8-builder\": shared object found: usr/share/dotnet/.store/dotnet-coverage/17.14.2/dotnet-coverage/17.14.2/tools/net8.0/any/alpine/x64/libCoverageInstrumentationMethod.so; suggest: This package provides shared object files, please add the ldd-check test pipeline arch=x86_64\n2025/09/10 20:50:11 INFO checking license information arch=x86_64\n2025/09/10 20:50:11 INFO no license files detected arch=x86_64\n2025/09/10 20:50:11 WARN SPDXRef-Package-dotnet8-builder-8.0.413-r0: no license specified, defaulting to NOASSERTION arch=x86_64\n2025/09/10 20:50:11 WARN invalid license: NOASSERTION arch=x86_64\n2025/09/10 20:50:11 INFO writing SBOM for dotnet8-builder arch=x86_64\n2025/09/10 20:50:11 INFO generating package dotnet8-builder-8.0.413-r0 arch=x86_64\n2025/09/10 20:50:11 INFO scanning for ld.so.conf.d files... arch=x86_64\n2025/09/10 20:50:11 INFO scanning for shared object dependencies... arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/.store/dotnet-coverage/17.14.2/dotnet-coverage/17.14.2/tools/net8.0/any/alpine/x64/libCoverageInstrumentationMethod.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/.store/dotnet-coverage/17.14.2/dotnet-coverage/17.14.2/tools/net8.0/any/alpine/x64/libCoverageInstrumentationMethod.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/.store/dotnet-coverage/17.14.2/dotnet-coverage/17.14.2/tools/net8.0/any/alpine/x64/libCoverageInstrumentationMethod.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libintl.so.8 for usr/share/dotnet/.store/dotnet-coverage/17.14.2/dotnet-coverage/17.14.2/tools/net8.0/any/alpine/x64/libInstrumentationEngine.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/.store/dotnet-coverage/17.14.2/dotnet-coverage/17.14.2/tools/net8.0/any/alpine/x64/libInstrumentationEngine.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libxml2.so.2 for usr/share/dotnet/.store/dotnet-coverage/17.14.2/dotnet-coverage/17.14.2/tools/net8.0/any/alpine/x64/libInstrumentationEngine.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/.store/dotnet-coverage/17.14.2/dotnet-coverage/17.14.2/tools/net8.0/any/alpine/x64/libInstrumentationEngine.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/.store/dotnet-coverage/17.14.2/dotnet-coverage/17.14.2/tools/net8.0/any/alpine/x64/libInstrumentationEngine.so arch=x86_64\n2025/09/10 20:50:11 INFO interpreter for dotnet =&gt; /lib/ld-musl-x86_64.so.1 arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/dotnet arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/dotnet arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/dotnet arch=x86_64\n2025/09/10 20:50:11 INFO interpreter for dotnet-coverage =&gt; /lib/ld-musl-x86_64.so.1 arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/dotnet-coverage arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/dotnet-coverage arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/dotnet-coverage arch=x86_64\n2025/09/10 20:50:11 INFO interpreter for dotnet-sonarscanner =&gt; /lib/ld-musl-x86_64.so.1 arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/dotnet-sonarscanner arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/dotnet-sonarscanner arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/dotnet-sonarscanner arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/host/fxr/8.0.19/libhostfxr.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/host/fxr/8.0.19/libhostfxr.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/host/fxr/8.0.19/libhostfxr.so arch=x86_64\n2025/09/10 20:50:11 INFO interpreter for apphost =&gt; /lib/ld-musl-x86_64.so.1 arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-x64/8.0.19/runtimes/linux-musl-x64/native/apphost arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-x64/8.0.19/runtimes/linux-musl-x64/native/apphost arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-x64/8.0.19/runtimes/linux-musl-x64/native/apphost arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-x64/8.0.19/runtimes/linux-musl-x64/native/libnethost.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-x64/8.0.19/runtimes/linux-musl-x64/native/libnethost.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-x64/8.0.19/runtimes/linux-musl-x64/native/libnethost.so arch=x86_64\n2025/09/10 20:50:11 INFO interpreter for singlefilehost =&gt; /lib/ld-musl-x86_64.so.1 arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libz.so.1 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-x64/8.0.19/runtimes/linux-musl-x64/native/singlefilehost arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-x64/8.0.19/runtimes/linux-musl-x64/native/singlefilehost arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-x64/8.0.19/runtimes/linux-musl-x64/native/singlefilehost arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-x64/8.0.19/runtimes/linux-musl-x64/native/singlefilehost arch=x86_64\n2025/09/10 20:50:11 INFO interpreter for apphost =&gt; /lib/ld-musl-x86_64.so.1 arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/sdk/8.0.413/AppHostTemplate/apphost arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/sdk/8.0.413/AppHostTemplate/apphost arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/sdk/8.0.413/AppHostTemplate/apphost arch=x86_64\n2025/09/10 20:50:11 INFO interpreter for createdump =&gt; /lib/ld-musl-x86_64.so.1 arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/createdump arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/createdump arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/createdump arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libSystem.Globalization.Native.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libz.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libSystem.IO.Compression.Native.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libSystem.IO.Compression.Native.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libSystem.Native.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libSystem.Net.Security.Native.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libSystem.Security.Cryptography.Native.OpenSsl.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libclrgc.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libclrgc.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libclrgc.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libclrjit.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libclrjit.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libclrjit.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libcoreclr.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libcoreclr.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libcoreclr.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib liblttng-ust.so.0 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libcoreclrtraceptprovider.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libcoreclrtraceptprovider.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libcoreclrtraceptprovider.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libcoreclrtraceptprovider.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libhostpolicy.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libhostpolicy.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libhostpolicy.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libmscordaccore.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libmscordaccore.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libmscordaccore.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libmscordbi.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libmscordbi.so arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libmscordbi.so arch=x86_64\n2025/09/10 20:50:11 INFO interpreter for swagger =&gt; /lib/ld-musl-x86_64.so.1 arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libstdc++.so.6 for usr/share/dotnet/swagger arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/swagger arch=x86_64\n2025/09/10 20:50:11 INFO   found lib libc.musl-x86_64.so.1 for usr/share/dotnet/swagger arch=x86_64\n2025/09/10 20:50:11 INFO scanning for commands... arch=x86_64\n2025/09/10 20:50:11 INFO scanning for -doc package... arch=x86_64\n2025/09/10 20:50:11 INFO scanning for pkg-config data... arch=x86_64\n2025/09/10 20:50:11 INFO scanning for python modules... arch=x86_64\n2025/09/10 20:50:11 INFO scanning for ruby gems... arch=x86_64\n2025/09/10 20:50:11 INFO scanning for shbang deps... arch=x86_64\n2025/09/10 20:50:11 INFO   runtime: arch=x86_64\n2025/09/10 20:50:11 INFO     gcompat arch=x86_64\n2025/09/10 20:50:11 INFO     icu-libs&gt;=76 arch=x86_64\n2025/09/10 20:50:11 INFO     icu&gt;=76 arch=x86_64\n2025/09/10 20:50:11 INFO     libintl arch=x86_64\n2025/09/10 20:50:11 INFO     lttng-ust-dev=2.12.0-r3 arch=x86_64\n2025/09/10 20:50:11 INFO     lttng-ust=2.12.0-r3 arch=x86_64\n2025/09/10 20:50:11 INFO     musl arch=x86_64\n2025/09/10 20:50:11 INFO     so:libc.musl-x86_64.so.1 arch=x86_64\n2025/09/10 20:50:11 INFO     so:libgcc_s.so.1 arch=x86_64\n2025/09/10 20:50:11 INFO     so:libintl.so.8 arch=x86_64\n2025/09/10 20:50:11 INFO     so:liblttng-ust.so.0 arch=x86_64\n2025/09/10 20:50:11 INFO     so:libstdc++.so.6 arch=x86_64\n2025/09/10 20:50:11 INFO     so:libxml2.so.2 arch=x86_64\n2025/09/10 20:50:11 INFO     so:libz.so.1 arch=x86_64\n2025/09/10 20:50:11 INFO     userspace-rcu-dev=0.12.2-r0 arch=x86_64\n2025/09/10 20:50:11 INFO     userspace-rcu=0.12.2-r0 arch=x86_64\n2025/09/10 20:50:11 INFO   installed-size: 672421235 arch=x86_64\n2025/09/10 20:50:14 INFO   data.tar.gz digest: bfb6d2f1b8f85b5700c53e5aafb97c265a4a1d41c2190804952b582ec98f2ac7 arch=x86_64\n2025/09/10 20:50:24 INFO wrote packages/x86_64/dotnet8-builder-8.0.413-r0.apk arch=x86_64\n2025/09/10 20:50:24 INFO cleaning Workspace by removing 15 file/directories in /home/build arch=x86_64\n2025/09/10 20:50:24 INFO generating apk index from packages in packages/x86_64 arch=x86_64\n2025/09/10 20:50:24 INFO processing package packages/x86_64/dotnet8-builder-8.0.413-r0.apk arch=x86_64\n2025/09/10 20:50:24 INFO loaded 1/1 packages from index packages/x86_64/APKINDEX.tar.gz arch=x86_64\n2025/09/10 20:50:24 INFO updating index at packages/x86_64/APKINDEX.tar.gz with new packages: [dotnet8-builder-8.0.413-r0] arch=x86_64\n2025/09/10 20:50:24 INFO signing apk index at packages/x86_64/APKINDEX.tar.gz arch=x86_64\n2025/09/10 20:50:24 INFO signing index packages/x86_64/APKINDEX.tar.gz with key melange.rsa arch=x86_64\n2025/09/10 20:50:24 INFO appending signature RSA256 to index packages/x86_64/APKINDEX.tar.gz arch=x86_64\n2025/09/10 20:50:24 INFO writing signed index to packages/x86_64/APKINDEX.tar.gz arch=x86_64\n2025/09/10 20:50:24 INFO signed index packages/x86_64/APKINDEX.tar.gz with key melange.rsa arch=x86_64\n2025/09/10 20:50:27 INFO .NET SDK: arch=aarch64\n2025/09/10 20:50:27 INFO  Version:           8.0.413 arch=aarch64\n2025/09/10 20:50:27 INFO  Commit:            a31823e79b arch=aarch64\n2025/09/10 20:50:28 INFO  Workload version:  8.0.400-manifests.6322a93a arch=aarch64\n2025/09/10 20:50:28 INFO  MSBuild version:   17.11.38+901dc04e4 arch=aarch64\n2025/09/10 20:50:28 INFO arch=aarch64\n2025/09/10 20:50:28 INFO Runtime Environment: arch=aarch64\n2025/09/10 20:50:28 INFO  OS Name:     Linux arch=aarch64\n2025/09/10 20:50:28 INFO  OS Version:   arch=aarch64\n2025/09/10 20:50:28 INFO  OS Platform: Linux arch=aarch64\n2025/09/10 20:50:28 INFO  RID:         linux-musl-arm64 arch=aarch64\n2025/09/10 20:50:28 INFO  Base Path:   /home/build/melange-out/dotnet8-builder/usr/share/dotnet/sdk/8.0.413/ arch=aarch64\n2025/09/10 20:50:28 INFO arch=aarch64\n2025/09/10 20:50:28 INFO .NET workloads installed: arch=aarch64\n2025/09/10 20:50:28 INFO Configured to use loose manifests when installing new manifests. arch=aarch64\n2025/09/10 20:50:28 INFO There are no installed workloads to display. arch=aarch64\n2025/09/10 20:50:28 INFO arch=aarch64\n2025/09/10 20:50:28 INFO Host: arch=aarch64\n2025/09/10 20:50:28 INFO   Version:      8.0.19 arch=aarch64\n2025/09/10 20:50:28 INFO   Architecture: arm64 arch=aarch64\n2025/09/10 20:50:28 INFO   Commit:       fce8ed90dc arch=aarch64\n2025/09/10 20:50:28 INFO arch=aarch64\n2025/09/10 20:50:28 INFO .NET SDKs installed: arch=aarch64\n2025/09/10 20:50:28 INFO   8.0.413 [/home/build/melange-out/dotnet8-builder/usr/share/dotnet/sdk] arch=aarch64\n2025/09/10 20:50:28 INFO arch=aarch64\n2025/09/10 20:50:28 INFO .NET runtimes installed: arch=aarch64\n2025/09/10 20:50:28 INFO   Microsoft.AspNetCore.App 8.0.19 [/home/build/melange-out/dotnet8-builder/usr/share/dotnet/shared/Microsoft.AspNetCore.App] arch=aarch64\n2025/09/10 20:50:28 INFO   Microsoft.NETCore.App 8.0.19 [/home/build/melange-out/dotnet8-builder/usr/share/dotnet/shared/Microsoft.NETCore.App] arch=aarch64\n2025/09/10 20:50:28 INFO arch=aarch64\n2025/09/10 20:50:28 INFO Other architectures found: arch=aarch64\n2025/09/10 20:50:28 INFO   None arch=aarch64\n2025/09/10 20:50:28 INFO arch=aarch64\n2025/09/10 20:50:28 INFO Environment variables: arch=aarch64\n2025/09/10 20:50:28 INFO   DOTNET_ROOT       [/home/build/melange-out/dotnet8-builder/usr/share/dotnet] arch=aarch64\n2025/09/10 20:50:28 INFO arch=aarch64\n2025/09/10 20:50:28 INFO global.json file: arch=aarch64\n2025/09/10 20:50:28 INFO   Not found arch=aarch64\n2025/09/10 20:50:28 INFO arch=aarch64\n2025/09/10 20:50:28 INFO Learn more: arch=aarch64\n2025/09/10 20:50:28 INFO   https://aka.ms/dotnet/info arch=aarch64\n2025/09/10 20:50:28 INFO arch=aarch64\n2025/09/10 20:50:28 INFO Download .NET: arch=aarch64\n2025/09/10 20:50:28 INFO   https://aka.ms/dotnet/download arch=aarch64\n2025/09/10 20:50:31 INFO arch=aarch64\narch=aarch64:50:31 INFO Welcome to .NET 8.0!\narch=aarch64:50:31 INFO ---------------------\n2025/09/10 20:50:31 INFO SDK Version: 8.0.413 arch=aarch64\n2025/09/10 20:50:31 INFO arch=aarch64\narch=aarch64:50:31 INFO Telemetry\narch=aarch64:50:31 INFO ---------\n2025/09/10 20:50:31 INFO The .NET tools collect usage data in order to help us improve your experience. It is collected by Microsoft and shared with the comm arch=aarch64n opt-out of telemetry by setting the DOTNET_CLI_TELEMETRY_OPTOUT environment variable to '1' or 'true' using your favorite shell.\narch=aarch64:50:31 INFO \n2025/09/10 20:50:31 INFO Read more about .NET CLI Tools telemetry: https://aka.ms/dotnet-cli-telemetry arch=aarch64\n2025/09/10 20:50:32 INFO arch=aarch64\narch=aarch64:50:32 INFO ----------------\narch=aarch64:50:32 INFO Installed an ASP.NET Core HTTPS development certificate.\n2025/09/10 20:50:32 INFO To trust the certificate, view the instructions: https://aka.ms/dotnet-https-linux arch=aarch64\n2025/09/10 20:50:32 INFO arch=aarch64\narch=aarch64:50:32 INFO ----------------\narch=aarch64:50:32 INFO Write your first app: https://aka.ms/dotnet-hello-world\narch=aarch64:50:32 INFO Find out what's new: https://aka.ms/dotnet-whats-new\narch=aarch64:50:32 INFO Explore documentation: https://aka.ms/dotnet-docs\narch=aarch64:50:32 INFO Report issues and find source on GitHub: https://github.com/dotnet/core\narch=aarch64:50:32 INFO Use 'dotnet --help' to see available commands or visit: https://aka.ms/dotnet-cli\n2025/09/10 20:50:32 INFO -------------------------------------------------------------------------------------- arch=aarch64\narch=aarch64:50:40 INFO You can invoke the tool using the following command: dotnet-sonarscanner\n2025/09/10 20:50:40 INFO Tool 'dotnet-sonarscanner' (version '10.3.0') was successfully installed. arch=aarch64\narch=aarch64:50:53 INFO You can invoke the tool using the following command: dotnet-coverage\n2025/09/10 20:50:53 INFO Tool 'dotnet-coverage' (version '17.14.2') was successfully installed. arch=aarch64\narch=aarch64:51:02 INFO You can invoke the tool using the following command: swagger\n2025/09/10 20:51:02 INFO Tool 'swashbuckle.aspnetcore.cli' (version '7.2.0') was successfully installed. arch=aarch64\n2025/09/10 20:51:07 INFO Package Id                      Version      Commands            arch=aarch64\n2025/09/10 20:51:07 INFO ---------------------------------------------------------------- arch=aarch64\n2025/09/10 20:51:07 INFO dotnet-coverage                 17.14.2      dotnet-coverage     arch=aarch64\n2025/09/10 20:51:07 INFO dotnet-sonarscanner             10.3.0       dotnet-sonarscanner arch=aarch64\n2025/09/10 20:51:07 INFO swashbuckle.aspnetcore.cli      7.2.0        swagger             arch=aarch64\n2025/09/10 20:51:07 INFO retrieving workspace from builder:  arch=aarch64\n2025/09/10 20:51:07 WARN cat: can't open '/etc/os-release': No such file or directory arch=aarch64\n2025/09/10 20:51:07 WARN failed to retrieve release data from runner, OS section will be unknown: failed to read os-release: exit status 1 arch=aarch64\n2025/09/10 20:51:07 INFO retrieved and wrote post-build workspace to: /tmp/melange-workspace-2943230085 arch=aarch64\n2025/09/10 20:51:07 INFO running package linters for dotnet8-builder arch=aarch64\n2025/09/10 20:51:07 INFO linting apk: dotnet8-builder arch=aarch64\n2025/09/10 20:51:07 WARN linter \"lddcheck\" failed on package \"dotnet8-builder\": shared object found: usr/share/dotnet/host/fxr/8.0.19/libhostfxr.so; suggest: This package provides shared object files, please add the ldd-check test pipeline arch=aarch64\n2025/09/10 20:51:07 INFO checking license information arch=aarch64\n2025/09/10 20:51:07 INFO no license files detected arch=aarch64\n2025/09/10 20:51:07 WARN SPDXRef-Package-dotnet8-builder-8.0.413-r0: no license specified, defaulting to NOASSERTION arch=aarch64\n2025/09/10 20:51:07 WARN invalid license: NOASSERTION arch=aarch64\n2025/09/10 20:51:07 INFO writing SBOM for dotnet8-builder arch=aarch64\n2025/09/10 20:51:07 INFO generating package dotnet8-builder-8.0.413-r0 arch=aarch64\n2025/09/10 20:51:07 INFO scanning for ld.so.conf.d files... arch=aarch64\n2025/09/10 20:51:07 INFO scanning for shared object dependencies... arch=aarch64\n2025/09/10 20:51:07 INFO interpreter for dotnet =&gt; /lib/ld-musl-aarch64.so.1 arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/dotnet arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/dotnet arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/dotnet arch=aarch64\n2025/09/10 20:51:07 INFO interpreter for dotnet-coverage =&gt; /lib/ld-musl-aarch64.so.1 arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/dotnet-coverage arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/dotnet-coverage arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/dotnet-coverage arch=aarch64\n2025/09/10 20:51:07 INFO interpreter for dotnet-sonarscanner =&gt; /lib/ld-musl-aarch64.so.1 arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/dotnet-sonarscanner arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/dotnet-sonarscanner arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/dotnet-sonarscanner arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/host/fxr/8.0.19/libhostfxr.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/host/fxr/8.0.19/libhostfxr.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/host/fxr/8.0.19/libhostfxr.so arch=aarch64\n2025/09/10 20:51:07 INFO interpreter for apphost =&gt; /lib/ld-musl-aarch64.so.1 arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-arm64/8.0.19/runtimes/linux-musl-arm64/native/apphost arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-arm64/8.0.19/runtimes/linux-musl-arm64/native/apphost arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-arm64/8.0.19/runtimes/linux-musl-arm64/native/apphost arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-arm64/8.0.19/runtimes/linux-musl-arm64/native/libnethost.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-arm64/8.0.19/runtimes/linux-musl-arm64/native/libnethost.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-arm64/8.0.19/runtimes/linux-musl-arm64/native/libnethost.so arch=aarch64\n2025/09/10 20:51:07 INFO interpreter for singlefilehost =&gt; /lib/ld-musl-aarch64.so.1 arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libz.so.1 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-arm64/8.0.19/runtimes/linux-musl-arm64/native/singlefilehost arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-arm64/8.0.19/runtimes/linux-musl-arm64/native/singlefilehost arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-arm64/8.0.19/runtimes/linux-musl-arm64/native/singlefilehost arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/packs/Microsoft.NETCore.App.Host.linux-musl-arm64/8.0.19/runtimes/linux-musl-arm64/native/singlefilehost arch=aarch64\n2025/09/10 20:51:07 INFO interpreter for apphost =&gt; /lib/ld-musl-aarch64.so.1 arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/sdk/8.0.413/AppHostTemplate/apphost arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/sdk/8.0.413/AppHostTemplate/apphost arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/sdk/8.0.413/AppHostTemplate/apphost arch=aarch64\n2025/09/10 20:51:07 INFO interpreter for createdump =&gt; /lib/ld-musl-aarch64.so.1 arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/createdump arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/createdump arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/createdump arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libSystem.Globalization.Native.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libz.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libSystem.IO.Compression.Native.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libSystem.IO.Compression.Native.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libSystem.Native.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libSystem.Net.Security.Native.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libSystem.Security.Cryptography.Native.OpenSsl.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libclrgc.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libclrgc.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libclrgc.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libclrjit.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libclrjit.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libclrjit.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libcoreclr.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libcoreclr.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libcoreclr.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib liblttng-ust.so.0 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libcoreclrtraceptprovider.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libcoreclrtraceptprovider.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libcoreclrtraceptprovider.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libcoreclrtraceptprovider.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libhostpolicy.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libhostpolicy.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libhostpolicy.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libmscordaccore.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libmscordaccore.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libmscordaccore.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libmscordbi.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libmscordbi.so arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/shared/Microsoft.NETCore.App/8.0.19/libmscordbi.so arch=aarch64\n2025/09/10 20:51:07 INFO interpreter for swagger =&gt; /lib/ld-musl-aarch64.so.1 arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libstdc++.so.6 for usr/share/dotnet/swagger arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libgcc_s.so.1 for usr/share/dotnet/swagger arch=aarch64\n2025/09/10 20:51:07 INFO   found lib libc.musl-aarch64.so.1 for usr/share/dotnet/swagger arch=aarch64\n2025/09/10 20:51:07 INFO scanning for commands... arch=aarch64\n2025/09/10 20:51:07 INFO scanning for -doc package... arch=aarch64\n2025/09/10 20:51:07 INFO scanning for pkg-config data... arch=aarch64\n2025/09/10 20:51:07 INFO scanning for python modules... arch=aarch64\n2025/09/10 20:51:07 INFO scanning for ruby gems... arch=aarch64\n2025/09/10 20:51:07 INFO scanning for shbang deps... arch=aarch64\n2025/09/10 20:51:07 INFO   runtime: arch=aarch64\n2025/09/10 20:51:07 INFO     gcompat arch=aarch64\n2025/09/10 20:51:07 INFO     icu-libs&gt;=76 arch=aarch64\n2025/09/10 20:51:07 INFO     icu&gt;=76 arch=aarch64\n2025/09/10 20:51:07 INFO     libintl arch=aarch64\n2025/09/10 20:51:07 INFO     lttng-ust-dev=2.12.0-r3 arch=aarch64\n2025/09/10 20:51:07 INFO     lttng-ust=2.12.0-r3 arch=aarch64\n2025/09/10 20:51:07 INFO     musl arch=aarch64\n2025/09/10 20:51:07 INFO     so:libc.musl-aarch64.so.1 arch=aarch64\n2025/09/10 20:51:07 INFO     so:libgcc_s.so.1 arch=aarch64\n2025/09/10 20:51:07 INFO     so:liblttng-ust.so.0 arch=aarch64\n2025/09/10 20:51:07 INFO     so:libstdc++.so.6 arch=aarch64\n2025/09/10 20:51:07 INFO     so:libz.so.1 arch=aarch64\n2025/09/10 20:51:07 INFO     userspace-rcu-dev=0.12.2-r0 arch=aarch64\n2025/09/10 20:51:07 INFO     userspace-rcu=0.12.2-r0 arch=aarch64\n2025/09/10 20:51:08 INFO   installed-size: 701379121 arch=aarch64\n2025/09/10 20:51:10 INFO   data.tar.gz digest: f61022d44fb32ca505204f4b0d60b7e5136bb201fb2b33dd1474f6065838f11d arch=aarch64\n2025/09/10 20:51:26 INFO wrote packages/aarch64/dotnet8-builder-8.0.413-r0.apk arch=aarch64\n2025/09/10 20:51:26 INFO cleaning Workspace by removing 15 file/directories in /home/build arch=aarch64\n2025/09/10 20:51:26 INFO generating apk index from packages in packages/aarch64 arch=aarch64\n2025/09/10 20:51:26 INFO processing package packages/aarch64/dotnet8-builder-8.0.413-r0.apk arch=aarch64\n2025/09/10 20:51:26 INFO loaded 1/1 packages from index packages/aarch64/APKINDEX.tar.gz arch=aarch64\n2025/09/10 20:51:26 INFO updating index at packages/aarch64/APKINDEX.tar.gz with new packages: [dotnet8-builder-8.0.413-r0] arch=aarch64\n2025/09/10 20:51:26 INFO signing apk index at packages/aarch64/APKINDEX.tar.gz arch=aarch64\n2025/09/10 20:51:26 INFO signing index packages/aarch64/APKINDEX.tar.gz with key melange.rsa arch=aarch64\n2025/09/10 20:51:26 INFO appending signature RSA256 to index packages/aarch64/APKINDEX.tar.gz arch=aarch64\n2025/09/10 20:51:26 INFO writing signed index to packages/aarch64/APKINDEX.tar.gz arch=aarch64\n2025/09/10 20:51:26 INFO signed index packages/aarch64/APKINDEX.tar.gz with key melange.rsa arch=aarch64\n</code></pre>","tags":["distroless","melange","supply chain"]},{"location":"blog/2025/09/10/melange_criando_seus_pr%C3%B3prios_pacotes_apk/#como-instalar-o-pacote-gerado","title":"Como instalar o pacote Gerado","text":"<p>Neste caso temos um complicador, alguns pacotes est\u00e3o em outras vers\u00f5es de reposit\u00f3rios, para que num logo a vers\u00e3o 3.15 do repo do alpine, tem que ser adicionado para que a lib de pre-req seja instalado.</p>","tags":["distroless","melange","supply chain"]},{"location":"blog/2025/09/10/melange_criando_seus_pr%C3%B3prios_pacotes_apk/#utilizando-apko","title":"Utilizando APKO","text":"<p>O APKO \u00e9 outra ferramenta da Chainguard, que funciona de forma complementar ao Melange. Enquanto o Melange \u00e9 utilizado para gerar pacotes APK, o APKO pode utilizar esses pacotes assim como qualquer pacote de qualquer reposit\u00f3rio que voc\u00ea informar podendo este, ser p\u00fablico ou privado.</p> APKO Example File<pre><code>contents:\n  keyring:\n    - ./melange.rsa.pub\n  repositories:\n    - '@local /work/packages'\n    - https://dl-cdn.alpinelinux.org/alpine/edge/main\n    - https://dl-cdn.alpinelinux.org/alpine/edge/community\n    # Necess\u00e1rio para pegar 'lttng-ust' lib que s\u00f3 existe nesse repo.\n    - https://dl-cdn.alpinelinux.org/alpine/v3.15/main \n  packages:\n    - bash\n    - ca-certificates-bundle\n    - dotnet8-builder@local\n\naccounts:\n  run-as: 1000\n\nenvironment:\n  DOTNET_ROOT: \"/usr/share/dotnet\"\n  PATH: \"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/share/dotnet\"\n\nentrypoint:\n  command: /entrypoint.sh\n\narchs:\n  - arm64\n  - amd64\n</code></pre> <p>Segue abaixo um exemplo de como instalar com base no arquivo acima</p> Running APKO<pre><code>docker run --rm --workdir /work -v ${PWD}:/work cgr.dev/chainguard/apko build apko.yaml dotnet-sdk-8:test dotnet-sdk-8.tar --arch host\n\ndocker load &lt; ./dotnet-sdk-8.tar\n\ndocker run --rm -it dotnet-sdk-8:test-amd64\n</code></pre>","tags":["distroless","melange","supply chain"]},{"location":"blog/2025/09/10/melange_criando_seus_pr%C3%B3prios_pacotes_apk/#diretamente-num-alpine","title":"Diretamente num Alpine","text":"Dockerfile Alpine<pre><code>FROM alpine\n\n# Necess\u00e1rio para pegar 'lttng-ust' lib que s\u00f3 existe nesse repo.\nRUN echo \"https://dl-cdn.alpinelinux.org/alpine/v3.15/main\" &gt;&gt; /etc/apk/repositories \\\n    &amp;&amp; apk update\n\nCOPY packages/x86_64/dotnet8-builder-8.0.413-r0.apk .\n\nRUN apk add --allow-untrusted ./dotnet8-builder-8.0.413-r0.apk \\\n    &amp;&amp; rm -rf ./dotnet8-builder-8.0.413-r0.apk\n</code></pre> Executando a cria\u00e7\u00e3o da imagem com o nosso pacote via Dockerfile. Dockerfile Alpine<pre><code>docker build -t dotnet-sdk-8:alpine .\n</code></pre>","tags":["distroless","melange","supply chain"]},{"location":"blog/2025/09/10/melange_criando_seus_pr%C3%B3prios_pacotes_apk/#comparacao","title":"Compara\u00e7\u00e3o","text":"<ul> <li>Tamanho</li> </ul> <p>Como pode ser visto no print abaixo, o tamanho da imagem utilizando APKO \u00e9 praticamente metade da outra, mesmo a outra sendo uma imagem base do alpine, que \u00e9 considerada clean.</p> <ul> <li> <p>Pacotes</p> <ul> <li>APKO: Contem apenas 3 pacotes, bash/ca-certificates-bundle/dotnet-sdk-8 que foi os que n\u00f3s declaramos na instala\u00e7\u00e3o.</li> <li>Dockerfile: Contem todos os pacotes nativos do Alpine, mesmo sendo uma imagem enxuta, ainda vem com pacotes \"indesejados\".</li> </ul> </li> </ul>","tags":["distroless","melange","supply chain"]},{"location":"blog/2025/09/10/melange_criando_seus_pr%C3%B3prios_pacotes_apk/#conclusao","title":"Conclus\u00e3o","text":"<p>Caso voc\u00ea queria se manter atualizado ou com controle total das vers\u00f5es instaladas, o melhor caminho \u00e9 voc\u00ea ter o proprio gerenciamento dos seus pacotes. Isso poder\u00e1 ser mais complicado no princ\u00edpio mas te dar\u00e1 mais liberdade de escolher/personalizar as suas imagens base.</p> <p>Segue abaixo alguns links interessantes que podem ser \u00fateis nessa jornada:</p> <ul> <li>examples</li> <li>parameters</li> <li>subcommands</li> </ul> <p>Qualquer d\u00favida, me procura nas minhas redes, que a gente troca uma id\u00e9ia!</p>","tags":["distroless","melange","supply chain"]},{"location":"blog/2025/10/07/apko_criando_suas_imagens_distrolesszero-cve/","title":"APKO: Criando suas Imagens Distroless/Zero-CVE*","text":"","tags":["distroless","apko","chainguard"]},{"location":"blog/2025/10/07/apko_criando_suas_imagens_distrolesszero-cve/#apko-criando-suas-imagens-distrolesszero-cve","title":"APKO: Criando suas Imagens Distroless/Zero-CVE*","text":"<p>Empresas que tratam seguran\u00e7a com seriedade sabem que gerenciar vulnerabilidades pode parecer um trabalho infinito. Dependendo do tamanho do seu workload, pode se tornar invi\u00e1vel corrigir todas as vulnerabilidades existentes. Isso pode fazer com que muitas nunca sejam tratadas \u2014 ou simplesmente sejam ignoradas.</p> <p>E pior do que precisar atualizar softwares e ferramentas vulner\u00e1veis \u00e9 manter pacotes que nem sequer s\u00e3o necess\u00e1rios para a execu\u00e7\u00e3o da sua aplica\u00e7\u00e3o.</p> <p>Agora, imagine se fosse poss\u00edvel \u2014 de forma simples \u2014 ter controle sobre todas as vers\u00f5es de softwares e ferramentas instalados, garantindo que suas imagens estejam, na pr\u00e1tica, Zero-CVE*.</p>","tags":["distroless","apko","chainguard"]},{"location":"blog/2025/10/07/apko_criando_suas_imagens_distrolesszero-cve/#motivacao","title":"Motiva\u00e7\u00e3o","text":"<p>O APKO \u00e9 uma ferramenta para criar Imagens de Container(single-layer) baseadas em pacotes APK. Ele permite que voc\u00ea crie e mantenha suas pr\u00f3prias imagens base de servi\u00e7os, de forma idempotente totalmente reproduz\u00edvel em um \u00fanico arquivo YAML.</p> <p>Abaixo podemos ver uma exemplifica\u00e7\u00e3o simples de como o processo funciona, envolvendo MELANGE e o APKO. Melange gera pacotes APKs, us\u00e1veis em Alpine(Linux minimalista mantido pela comunidade) e Wolfi(Linux undistro mantida ChainGuard). E ent\u00e3o o APKO, consegue usar tanto as imagens personalizadas, quanto as de ambos reposit\u00f3rios e gerar a partir da\u00ed imagens super minimalistas.</p> <p>Os principais ganhos s\u00e3o:</p> <ul> <li>Facilidade de reproduzir as imagens base.</li> <li>Possibilidade de especificar apenas depend\u00eancias NECESS\u00c1RIAS para o correto funcionamento da sua aplica\u00e7\u00e3o.</li> <li>Suporte a SBOMs (Software Bills of Materials), o que facilita a rastreablidade e controle de tudo que est\u00e1 instalado nas suas imagens.</li> <li>Diminui\u00e7\u00e3o dos vetores de ataque existentes no container, pois existir\u00e1 apenas o m\u00ednimo necess\u00e1rio.</li> </ul> <p>Um ponto importante sobre o Zero-CVE* \u00e9 que mesmo que tenha apenas o pacote do seu servi\u00e7o, caso ele tenha vulnerabilidades conhecidas, o APKO n\u00e3o resolver\u00e1 isso, \u00e9 necess\u00e1rio que o seu pacote escolhido TAMBEM n\u00e3o tenha vulnerabilidaes, mas caso isso seja poss\u00edvel de forma simples, garantimos pois nenhum outro pacote ser\u00e1 instalado.</p> <p>A P\u00e1gina de documenta\u00e7\u00e3o da Chainguard \u00e9 bem completa e pode ajudar bastante a entender, utilizando alguns exemplos pr\u00e1ticos. Inclusive nem \u00e9 necess\u00e1rio instalar nada, pois a partir do proprio container do apko (via docker run) \u00e9 poss\u00edvel criar essas imagens.</p>","tags":["distroless","apko","chainguard"]},{"location":"blog/2025/10/07/apko_criando_suas_imagens_distrolesszero-cve/#como-utilizar","title":"Como Utilizar","text":"","tags":["distroless","apko","chainguard"]},{"location":"blog/2025/10/07/apko_criando_suas_imagens_distrolesszero-cve/#pre-requisito","title":"Pr\u00e9-requisito","text":"<ul> <li> <p>Download da imagem: Outro passo de boa pr\u00e1tica mas n\u00e3o 100% necess\u00e1rio, porque indiretamente a imagem ser\u00e1 baixada quando voc\u00ea executar de fato o comando, \u00e9 baixar a ultima imagem dispon\u00edvel na sua m\u00e1quina para que voc\u00ea consiga realizar alguns passos caso queira realizar de forma offline.</p> Downloading APKO image<pre><code>docker pull cgr.dev/chainguard/apko\n</code></pre> </li> <li> <p>Pacotes Customizados j\u00e1 criados: Caso tenha interesse em aumentar o n\u00edvel de personaliza\u00e7\u00e3o da sua image, poder\u00e1 usar pacotes APKs customizados pelo seu time, para atender demandas de alguns DEVs especificamente.</p> </li> </ul>","tags":["distroless","apko","chainguard"]},{"location":"blog/2025/10/07/apko_criando_suas_imagens_distrolesszero-cve/#cenario-hipotetico","title":"Cen\u00e1rio Hipot\u00e9tico","text":"<ul> <li> <p>Situa\u00e7\u00e3o Atual</p> <p>Hoje todos os desenvolvedores utilizam as imagens padr\u00f5es oferecidas pela Microsoft, tendo como base o Debian mais atual. Dockerfile, processo e docker-compose s\u00e3o gerados automaticamente pela IDE com base no SDK escolhido.</p> </li> <li> <p>Objetivo: Mitigar vulnerabilidade das imagens das Aplica\u00e7\u00f5es</p> <p>Imagine que sua empresa possui centenas de APIs expostas pra clientes, e que voc\u00ea tem que manter as imagens base atualizadas/livres de vulnerabilidade de forma a manter o Compliance exigido por seus clientes mais cr\u00edticos. Tudo isso pensando em Multi-Arquitetura, neste caso: X64 e ARM.</p> <p>Vers\u00f5es utilizadas para exemplo:</p> <ul> <li> DotNet ASPNET 8     </li> </ul> </li> </ul>","tags":["distroless","apko","chainguard"]},{"location":"blog/2025/10/07/apko_criando_suas_imagens_distrolesszero-cve/#exemplo-pratico","title":"Exemplo Pr\u00e1tico","text":"","tags":["distroless","apko","chainguard"]},{"location":"blog/2025/10/07/apko_criando_suas_imagens_distrolesszero-cve/#exemplo-de-pacote-melange-para-dotnet-8","title":"Exemplo de pacote Melange, para dotnet 8","text":"<p>Segue abaixo um pacote simplificado para cria\u00e7\u00e3o do dotnet 8 aspnetcor utilizando o Melange, apenas com seus pr\u00e9-requisitos declarados na documenta\u00e7\u00e3o oficial.</p> melange.yaml <pre><code>package:\n  name: dotnet-aspnet-8\n  version: 8.0.20\n  description: \"ASPNET Core 8.0 Runtime\"\n  dependencies:\n    runtime:\n      - ca-certificates-bundle\n      - libgcc \n      - libgdiplus\n      - libssl3\n      - libstdc++ \n      - zlib\n\nenvironment:\n  contents:\n    repositories:\n      - https://dl-cdn.alpinelinux.org/alpine/edge/main\n      - https://dl-cdn.alpinelinux.org/alpine/edge/community\n    packages:\n      - bash\n      - ca-certificates-bundle\n\npipeline:\n  - runs: |\n      mkdir -p ${{targets.destdir}}/usr/share/dotnet\n\n  - assertions:\n      required-steps: 1\n    pipeline:\n      - uses: fetch\n        if: ${{build.arch}} == 'aarch64'\n        with:\n          uri: https://builds.dotnet.microsoft.com/dotnet/aspnetcore/Runtime/${{package.version}}/aspnetcore-runtime-${{package.version}}-linux-musl-arm64.tar.gz\n          directory: ${{targets.destdir}}/usr/share/dotnet/\n          strip-components: 0\n          expected-sha512: f10e19379f76611f376ed19b701dcc2a3407cd83a57d806f9929295a90153fa28fc62740f8e5c34094a955e834a704bf401b0993f2528a0ee2f5d9cf876179bb\n\n      - uses: fetch\n        if: ${{build.arch}} == 'x86_64'\n        with:\n          uri: https://builds.dotnet.microsoft.com/dotnet/aspnetcore/Runtime/${{package.version}}/aspnetcore-runtime-${{package.version}}-linux-musl-x64.tar.gz\n          directory: ${{targets.destdir}}/usr/share/dotnet\n          strip-components: 0\n          expected-sha512: 7458ded8d275499d0192ada896b042501830c2c29859581e2e2db1d36bbc652af22f30029d086620cd1c2a7269ab94d0ebd94e2b4d599096289946ef39035132\n</code></pre>","tags":["distroless","apko","chainguard"]},{"location":"blog/2025/10/07/apko_criando_suas_imagens_distrolesszero-cve/#criar-arquivo-de-configuracao","title":"Criar Arquivo de Configura\u00e7\u00e3o","text":"<p>Segue uma exemplifica\u00e7\u00e3o de um arquivo .yaml que atende todas as necessidades citadas no cen\u00e1rio passado.</p> apko.yaml<pre><code>contents:\n  keyring:\n    - ./melange.rsa.pub\n  repositories:\n    - '@local /work/packages'\n    - https://dl-cdn.alpinelinux.org/alpine/edge/main\n    - https://dl-cdn.alpinelinux.org/alpine/edge/community\n    - https://dl-cdn.alpinelinux.org/alpine/v3.15/main\n  packages:\n    - dotnet-aspnet-8@local\n\nstop-signal: SIGTERM\n\nwork-dir: /app\n\naccounts:\n  groups:\n    - groupname: dotnet\n      gid: 1000\n  users:\n    - username: dotnet\n      uid: 1000\n  run-as: dotnet\n\nenvironment:\n  DOTNET_ROOT: \"/usr/share/dotnet\"\n  DOTNET_RUNNING_IN_CONTAINER: true\n\nentrypoint:\n  command: /usr/share/dotnet/dotnet\n\narchs:\n  - amd64\n  - arm64\n</code></pre>","tags":["distroless","apko","chainguard"]},{"location":"blog/2025/10/07/apko_criando_suas_imagens_distrolesszero-cve/#explicando-as-opcoes-utilizadas","title":"Explicando as op\u00e7\u00f5es utilizadas:","text":"<ul> <li>Sections<ul> <li>contents, Lista de onde o APKO ir\u00e1 buscar os conteudos, ordenado por:     <pre><code>contents:\n  keyring:\n    - ./melange.rsa.pub\n    ..\n</code></pre><ul> <li>keyring, Localiza\u00e7\u00e3o das chaves p\u00fablicas para checagem das assinaturas dos pacotes.     <pre><code>contents:\n  keyring:\n    - ./melange.rsa.pub\n    ..\n</code></pre></li> <li>repositories: Quais reposit\u00f3rios ser\u00e3o utilizados pra buscar os pacotes, podendo ser ambos locais ou remotos.     <pre><code>..\n  repositories:\n    - '@local /work/packages'\n    - https://dl-cdn.alpinelinux.org/alpine/edge/main\n  ..\n</code></pre></li> <li>packages: Lista de pacotes necess\u00e1rios para a sua imagem, n\u00e3o necess\u00e1rio listar as subdependencias, isso ser\u00e1 automaticamente buscado durante instala\u00e7\u00e3o.     <pre><code>..\n    packages:\n      - dotnet-aspnet-8@local\n  ..\n</code></pre></li> </ul> </li> <li>stop-signal: Sinal de desligamento enviado pelo runtime ao processo principal no container. Neste caso o sinal enviado tamb\u00e9 \u00e9 conhecido como 'graceful shutdown', pois o processo vai salvando estado, fechando conex\u00f5es e liberando portas.     <pre><code>..\nstop-signal: SIGTERM\n..\n</code></pre></li> <li>work-dir: Diret\u00f3rio do servi\u00e7o a ser executado.     <pre><code>..\nwork-dir: /app\n..\n</code></pre></li> <li>accounts: \u00c9 uma boa pr\u00e1tica definir um user com pouquissima permiss\u00e3o/acesso para executar servi\u00e7os, evitando o compromentimento do container. Essa config \u00e9 usado para configurar contas de usu\u00e1rio na imagem e pode ser utilizado ao executar processos no container.     <pre><code>..\naccounts:\n  groups:\n    - groupname: dotnet\n      gid: 1000\n  users:\n    - username: dotnet\n      uid: 1000\n  run-as: dotnet\n..\n</code></pre></li> <li>environment: Lista de vari\u00e1veis de ambiente da Imagem.     <pre><code>..\nenvironment:\n  DOTNET_ROOT: \"/usr/share/dotnet\"\n  DOTNET_RUNNING_IN_CONTAINER: true\n  ..\n</code></pre></li> <li>entrypoint: Define o comando ou servi\u00e7o padr\u00e3o que ser\u00e1 executado em runtime.     <pre><code>..\nentrypoint:\n  command: dotnet\n..\n</code></pre></li> <li>archs: Define a lista de arquiteturas que a imagem poder\u00e1 ser buildada.     <pre><code>..\narchs:\n  - amd64\n  - arm64\n</code></pre></li> </ul> </li> </ul>","tags":["distroless","apko","chainguard"]},{"location":"blog/2025/10/07/apko_criando_suas_imagens_distrolesszero-cve/#execucao-e-arquivos-gerados","title":"Execu\u00e7\u00e3o e Arquivos Gerados","text":"<ul> <li> <p>Build das imagens com APKO </p> <p>Ap\u00f3s o build do pacote dotnet8-aspnet ser realizado com sucesso, utilizando Melange, poderemos ent\u00e3o, utiliza-lo na gera\u00e7\u00e3o da imagem. Caso tenha qualquer d\u00favida, pode ser viso no post anterior</p> <p>Para buildar a Imagem, bastaria executar o comando abaixo. Nele podemos ver que est\u00e1 sendo referenciado quais arquiteturas ser\u00e3o utilizadas <code>--arch amd64,arm64</code>. Ap\u00f3s a retag enviaremos a imagem para nosso registry.</p> Building Image dotnet8-aspnet<pre><code>docker run --rm --workdir /work -v ${PWD}:/work \\\n  cgr.dev/chainguard/apko build apko.yaml \\\n  harbor.mycompany.local/base/api-aspnet-8:test dotnet8-aspnet.tar --arch amd64,arm64\n\ndocker load &lt; ./dotnet8-aspnet.tar\n\ndocker image ls\nREPOSITORY                                    TAG        IMAGE ID       CREATED      SIZE\nharbor.mycompany.local/base/api-aspnet-8  test-amd64   24b39b662a3e   4 days ago    129MB\nharbor.mycompany.local/base/api-aspnet-8  test-arm64   dc0badfd60a8   4 days ago    141MB\n\ndocker push --all-tags harbor.mycompany.local/base/api-aspnet-8\n</code></pre> </li> <li> <p>Teste de Valida\u00e7\u00e3o do build realizado em cada uma das imagens geradas. </p> <pre><code>[~]$ docker run --platform linux/arm64 harbor.mycompany.local/base/api-aspnet-8:test-arm64 --info   \n\nHost:\n  Version:      8.0.20\n  Architecture: arm64\n  Commit:       574100b692\n  RID:          linux-musl-arm64\n\n.NET SDKs installed:\n  No SDKs were found.\n\n.NET runtimes installed:\n  Microsoft.AspNetCore.App 8.0.20 [/usr/share/dotnet/shared/Microsoft.AspNetCore.App]\n  Microsoft.NETCore.App 8.0.20 [/usr/share/dotnet/shared/Microsoft.NETCore.App]\n.......\n\n$ docker run harbor.mycompany.local/base/api-aspnet-8:test-amd64 --info \n\nHost:\n  Version:      8.0.20\n  Architecture: x64\n  Commit:       574100b692\n  RID:          linux-musl-x64\n\n.NET SDKs installed:\n  No SDKs were found.\n\n.NET runtimes installed:\n  Microsoft.AspNetCore.App 8.0.20 [/usr/share/dotnet/shared/Microsoft.AspNetCore.App]\n  Microsoft.NETCore.App 8.0.20 [/usr/share/dotnet/shared/Microsoft.NETCore.App]\n.......\n</code></pre> </li> </ul> DICA: Crie e use um Manifesto <p>Uma boa pr\u00e1tica \u00e9, como voc\u00ea ja buildou a imagem e fez o push de ambas, \u00e9 interessante realizar alguns testes de valida\u00e7\u00e3o na mesma pra saber se tudo esta instalado conforme esperado. Como por ex, um <code>dotnet --info</code> e validar algumas infoma\u00e7\u00f5es. Outra dica \u00e9 Ap\u00f3s essa valida\u00e7\u00e3o, voc\u00ea gerar um manifesto latest (ou outro nome que fa\u00e7a sentido, e apontar para ambas arquiteturas criadas). EX:</p> <pre><code>### Create Manifest\ndocker manifest create harbor.mycompany.local/base/api-aspnet-8:latest \\\n    harbor.mycompany.local/base/api-aspnet-8:test-amd64 \\\n    harbor.mycompany.local/base/api-aspnet-8:test-arm64\n\n### Pushing Manifest\ndocker manifest push harbor.mycompany.local/base/api-aspnet-8:latest\n</code></pre> <p>Neste formato, voc\u00ea abstrai essa configura\u00e7\u00e3o para seus times de desenvolvimento, podendo facilitar informando apenas 'latest' como tag nas imagens e deixando para que a arquitetura do runner que for chamado para buildar essa imagem \u00e9 que defina qual imagem ser\u00e1 baixada. Abaixo podemos ver uma exemplifica\u00e7\u00e3o de Dockerfile. O \u00fanico fato relevante \u00e9 que o argumento <code>RUNTIME_ARCH</code> deve ser passado informando qual formato dever\u00e1 ser gerado o publish do dotnet.</p> Multi-Stage Dockerfile base<pre><code># GENERATE PUBLISH\nFROM mcr.microsoft.com/dotnet/sdk:8.0 as builder\nWORKDIR /build\nCOPY ./ .\nARG RUNTIME_ARCH\nRUN dotnet publish -v q -c Release \\\n    --runtime ${RUNTIME_ARCH} \\\n    --self-contained false \\\n    --output publish\n\n# GOLDEN IMAGE\nFROM harbor.mycompany.local/base/api-aspnet-8:latest\nCOPY --from=builder /build/publish /app\n#ENTRYPOINT [\"dotnet\"] implicito pois j\u00e1 \u00e9 mencionado no arquivo apko.\nCMD [\"API.dll\"]\n</code></pre> <ul> <li> <p>Lista de arquivos existentes</p> <p></p><pre><code>$ ls -la\ntotal 111M\n-rw-rw-r-- 1 karlipegomes karlipegomes  628 Oct  7 00:33 apko.yaml\n-rw-r--r-- 1 root         root         111M Oct  7 00:33 dotnet8-aspnet.tar\n-rw-r--r-- 1 root         root         3.2K Oct  7 00:30 melange.rsa\n-rw-r--r-- 1 root         root          800 Oct  7 00:30 melange.rsa.pub\n-rw-rw-r-- 1 karlipegomes karlipegomes 1.6K Oct  7 00:30 melange.yaml\ndrwxr-xr-x 4 root         root         4.0K Oct  7 00:31 packages\n-rw-r--r-- 1 root         root         4.4K Oct  7 00:33 sbom-aarch64.spdx.json\n-rw-r--r-- 1 root         root         4.2K Oct  7 00:33 sbom-index.spdx.json\n-rw-r--r-- 1 root         root         4.4K Oct  7 00:33 sbom-x86_64.spdx.json\n</code></pre> Como pode ser visto temos a lista de todos os keypairs configurados, o tar gerado pelo apko, assim como o diretoio packages, gerado pelo melange.. Mas um fato interessante s\u00e3o os arquivos sbom, que presentam o Software Bill of Materials, que em resumo, representaria a lista de softwares/libs/depend\u00eancias que compoem a sua imagem e como elas se relacionam. Num proximo Post, nos aprofundaremos nesse contexto de supply, como atestar, verificar e garantir um acompanhamento continuo das vulnerabilidades da sua imagem.<p></p> </li> </ul>","tags":["distroless","apko","chainguard"]},{"location":"blog/2025/10/07/apko_criando_suas_imagens_distrolesszero-cve/#comparacao","title":"Compara\u00e7\u00e3o","text":"<p>Segue abaixo a lista de imagens em comparativo para uma melhor an\u00e1lise do conte\u00fado.</p> <p>Descri\u00e7\u00e3o das tags</p> <ul> <li>apko: imagem criada por n\u00f3s durante este processo.</li> <li>mcr-alpine: imagem oficial da microsoft com a distro alpine por \"baixo\".<ul> <li><code>mcr.microsoft.com/dotnet/aspnet:8.0-alpine</code></li> </ul> </li> <li>mcr-default: imagem default oficial da microsoft, quando n\u00e3o informa nada distro.. porem \u00e9 um alias para a imagem bookworm-slim <ul> <li><code>mcr.microsoft.com/dotnet/aspnet:8.0</code></li> <li><code>mcr.microsoft.com/dotnet/aspnet:8.0-bookworm-slim</code></li> </ul> </li> </ul> <ul> <li>Controle</li> </ul> <p>Utilizando Imagens Distroless como a que geramos, temos o controle total de quais libs/tools est\u00e3o instaladas, vers\u00f5es e tudo que \u00e9 necess\u00e1rio e pertinente para o nosso ambiente. J\u00e1 com as imagens padr\u00f5es, sempre ficaremos a merc\u00ea do fabricante. Acreditamos que a Microsoft sempre far\u00e1 o melhor poss\u00edvel para melhorar essas imagens, por\u00e9m quando se \u00e9 necess\u00e1rio ter um nivel de controle muito alto, dificilmente os fabricantes nos atender\u00e3o.</p> Controle de atualiza\u00e7\u00e3o <p>Eventualmente pode ser que voc\u00ea ainda fique a frente da comunidade do alpine em rela\u00e7\u00e3o a atualiza\u00e7\u00e3o dos seus pr\u00f3prios pacotes, segue abaixo evid\u00eancia que existiu uma diferne\u00e7a de 4 dias entre o lan\u00e7amento da vers\u00e3o oficialmente pela Microsoft e a atualiza\u00e7\u00e3o no repo do Alpine.</p> <p>Print do link oficial da microsoft: </p> <p></p> <p>Print do repo oficial: </p> <p></p> <ul> <li>Performance?</li> </ul> <p>Com base em v\u00e1rios testes de bin\u00e1rios que utilizam essas imagens distroless, sempre representam um ganho de seguran\u00e7a, por\u00e9m o ganho de performance geralmente n\u00e3o \u00e9 t\u00e3o simples de medir e ou a diferen\u00e7a \u00e9 muito irris\u00f3ria ou incerta de medir. Por\u00e9m, um ganho que geralmente notamos em muitas aplica\u00e7\u00f5es \u00e9 o de startup do container, geralmente ganhamos alguns milisegundos, no ambiente produtivo da minha empresa, vimos uma melhoria de quase 1 segundo. Isso pode n\u00e3o parecer muito, mas quando se trabalha em escala altamente din\u00e2mica faz muita diferen\u00e7a quando voc\u00ea precisa escalar de  50 para 200 pods.</p> <ul> <li>Tamanho</li> </ul> <p>Como pode ser visto no print acimam, o tamanho da imagem utilizando APKO \u00e9 um pouco menor doque a do alpine e a default. Ent\u00e3o ainda temos vantagem por\u00e9m neste exemplo n\u00e3o \u00e9 o maior foco.</p> <ul> <li>Vulnerabilidade</li> </ul> <p>Neste ponto vimos onde de fato a utiliza\u00e7\u00e3o dessas ferramentas da ChainGuard fazem uma diferen\u00e7a. Geramos uma imagem livre de vulnerabilidades, pois temos o m\u00ednimo de pacotes necess\u00e1rios para correto funcionamento da aplica\u00e7\u00e3o.</p> <p>Caso exista ainda a possibilidade de pensar que talvez fa\u00e7a sentido corrigir as vulnerabilidades do alpine que s\u00e3o poucas, segue sua descri\u00e7\u00e3o.</p> Alpine Vulnerabilities <p>N\u00e3o compensa o esfor\u00e7o de corrigir isso, pois o risco de voc\u00ea quebrar algo no SO por fazer as mudan\u00e7as nessas libs \u00e9 muito alto, fora que, ainda no repo do alpine pra vers\u00e3o especificada dentro dessa imagem ainda n\u00e3o foi lan\u00e7ada essa corre\u00e7\u00e3o. Logo, voc\u00ea teria que fazer isso de uma forma manual, que se for pensar em larga escala e grande quantidade de imagens deixa invi\u00e1vel essa esfor\u00e7o.</p> <p></p> <p></p>","tags":["distroless","apko","chainguard"]},{"location":"blog/2025/10/07/apko_criando_suas_imagens_distrolesszero-cve/#conclusao","title":"Conclus\u00e3o","text":"<p>Caso voc\u00ea queria se manter atualizado ou com controle total das vers\u00f5es instaladas, o melhor caminho \u00e9 voc\u00ea ter o proprio gerenciamento dos seus pacotes. Isso poder\u00e1 parecer mais complicado no princ\u00edpio mas te dar\u00e1 mais liberdade de escolher/personalizar as suas imagens base.</p> <p>Segue abaixo alguns links interessantes que podem ser \u00fateis nessa jornada:</p> <ul> <li>examples</li> <li>file description</li> </ul> <p>Qualquer d\u00favida, me procura nas minhas redes que a gente troca uma id\u00e9ia!</p> <p>ZERO-CVE*</p> <p>Esse ponto tem o asterisco pois mesmo que voc\u00ea instale uma imagem distroless e tome todos os controles sobre as depend\u00eancias. Existe alguns casos que n\u00e3o tem como corrigir ou esfor\u00e7o para corrigir tem que ser reavaliado:</p> <ul> <li>Caso voc\u00ea crie uma imagem base, mas ap\u00f3s colocar o c\u00f3digo da sua aplica\u00e7\u00e3o instale libs vulner\u00e1veis, voc\u00ea ter\u00e1 que entrar em acordo com o seu desenvolvedor, para atualizar/resolver essas pend\u00eancias.</li> <li>Caso exista alguma vulnerabilidade conhecida, no pacote que est\u00e1 gerando/instalando ou alguma depend\u00eancia direta e voc\u00ea n\u00e3o consigue corrigir isso de forma f\u00e1cil, ainda sim depender\u00e1 da comunidade ou precisar\u00e1 medir o esfor\u00e7o para corrigir isso manualmente.</li> </ul>","tags":["distroless","apko","chainguard"]},{"location":"blog/archive/2025/","title":"October 2025","text":""},{"location":"blog/archive/2025/#october-2025","title":"October 2025","text":""},{"location":"blog/archive/2021/","title":"April 2021","text":""},{"location":"blog/archive/2021/#april-2021","title":"April 2021","text":""},{"location":"blog/archive/2020/","title":"July 2020","text":""},{"location":"blog/archive/2020/#july-2020","title":"July 2020","text":""},{"location":"blog/category/cloudnative/","title":"CloudNative","text":""},{"location":"blog/category/cloudnative/#cloudnative","title":"CloudNative","text":""},{"location":"blog/category/sredevops/","title":"SRE/DevOps","text":""},{"location":"blog/category/sredevops/#sredevops","title":"SRE/DevOps","text":""},{"location":"blog/category/tooltip/","title":"ToolTip","text":""},{"location":"blog/category/tooltip/#tooltip","title":"ToolTip","text":""},{"location":"blog/page/2/","title":"Blog","text":""},{"location":"blog/page/2/#blog","title":"Blog","text":""},{"location":"blog/archive/2020/page/2/","title":"July 2020","text":""},{"location":"blog/archive/2020/page/2/#july-2020","title":"July 2020","text":""}]}